{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30bbce7b-a6a3-4ef1-b553-47c2ba082add",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "# Disable autolog to prevent excessive logging during custom CV loops\n",
    "mlflow.autolog(disable=True)\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import Imputer, StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 1. LOAD CUSTOM MODULES (CV & Graph Features)\n",
    "# -------------------------------------------------------------------------\n",
    "# Load cv module directly from file path\n",
    "cv_path = \"/Workspace/Shared/Team 4_2/flight-departure-delay-predictive-modeling/notebooks/Cross Validator/cv.py\"\n",
    "spec = importlib.util.spec_from_file_location(\"cv\", cv_path)\n",
    "cv = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(cv)\n",
    "\n",
    "# Load graph_features module\n",
    "graph_features_path = \"/Workspace/Shared/Team 4_2/flight-departure-delay-predictive-modeling/notebooks/Feature Engineering/graph_features.py\"\n",
    "spec = importlib.util.spec_from_file_location(\"graph_features\", graph_features_path)\n",
    "graph_features = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(graph_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c918d765-f037-48a6-8dd9-371baeb3310b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataloader = cv.FlightDelayDataLoader()\n",
    "dataloader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5087c3f5-5a81-4a7e-9d55-1eb286c5c9ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# 2. FEATURE DEFINITIONS\n",
    "# -------------------------------------------------------------------------\n",
    "categorical_features = [\n",
    "    'day_of_week', 'op_carrier', 'origin', 'origin_state_abr', 'dest', \n",
    "    'dest_state_abr', 'dep_time_blk', 'arr_time_blk', 'day_of_month', 'month'\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    'hourlyprecipitation', 'hourlysealevelpressure', 'hourlyaltimetersetting', \n",
    "    'hourlywetbulbtemperature', 'hourlystationpressure', 'hourlywinddirection', \n",
    "    'hourlyrelativehumidity', 'hourlywindspeed', 'hourlydewpointtemperature', \n",
    "    'hourlydrybulbtemperature', 'hourlyvisibility', 'crs_elapsed_time', \n",
    "    'distance', 'elevation'\n",
    "]\n",
    "\n",
    "lineage_features = [\n",
    "    'crs_elapsed_time', 'distance', 'elevation',\n",
    "]\n",
    "\n",
    "numerical_features_no_lineage = [\n",
    "    col for col in numerical_features if col not in lineage_features\n",
    "]\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 3. HELPER FUNCTION\n",
    "# -------------------------------------------------------------------------\n",
    "def create_feature_pipeline(categorical_cols, numerical_cols, unique_suffix):\n",
    "    \"\"\"\n",
    "    Creates a PySpark ML Pipeline for feature engineering.\n",
    "    Uses a unique suffix to ensure internal column names don't clash.\n",
    "    \"\"\"\n",
    "    indexed_cols = [f\"{col}_INDEX_{unique_suffix}\" for col in categorical_cols]\n",
    "    vector_cols = [f\"{col}_VEC_{unique_suffix}\" for col in categorical_cols]\n",
    "    imputed_cols = [f\"{col}_IMPUTED_{unique_suffix}\" for col in numerical_cols]\n",
    "    \n",
    "    imputer = Imputer(\n",
    "        inputCols=numerical_cols, outputCols=imputed_cols, strategy=\"mean\"\n",
    "    )\n",
    "    indexer = StringIndexer(\n",
    "        inputCols=categorical_cols, outputCols=indexed_cols, handleInvalid=\"keep\"\n",
    "    )\n",
    "    encoder = OneHotEncoder(\n",
    "        inputCols=indexed_cols, outputCols=vector_cols\n",
    "    )\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=vector_cols + imputed_cols, outputCol=\"features\", handleInvalid=\"skip\"\n",
    "    )\n",
    "    \n",
    "    return Pipeline(stages=[imputer, indexer, encoder, assembler])\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 4. VOTING ENSEMBLE ESTIMATOR (Corrected)\n",
    "# -------------------------------------------------------------------------\n",
    "class VotingEnsemble:\n",
    "    def __init__(self):\n",
    "        # We define the regressors here, but we do NOT define the Pipelines here.\n",
    "        self.regressor_lineage = RandomForestRegressor(\n",
    "            featuresCol=\"features\", labelCol=\"DEP_DELAY\", \n",
    "            predictionCol=\"pred_lineage\", numTrees=50, maxDepth=10\n",
    "        )\n",
    "        self.regressor_no_lineage = RandomForestRegressor(\n",
    "            featuresCol=\"features\", labelCol=\"DEP_DELAY\", \n",
    "            predictionCol=\"pred_no_lineage\", numTrees=50, maxDepth=10\n",
    "        )\n",
    "        \n",
    "        # Placeholders for fitted models\n",
    "        self.feature_model_lineage = None\n",
    "        self.feature_model_no_lineage = None\n",
    "        self.model_lineage = None\n",
    "        self.model_no_lineage = None\n",
    "        \n",
    "        # Columns needed to join predictions and labels\n",
    "        self.key_cols = [\n",
    "            'month', 'day_of_month', 'day_of_week', 'op_carrier', \n",
    "            'origin', 'dest', 'dep_time_blk', 'arr_time_blk'\n",
    "        ]\n",
    "        # Labels required by the FlightDelayEvaluator\n",
    "        self.required_labels = ['DEP_DELAY', 'DEP_DEL15', 'SEVERE_DEL60']\n",
    "\n",
    "    def fit(self, df):\n",
    "        \"\"\"\n",
    "        Creates FRESH feature pipelines for this specific fit call (crucial for CV),\n",
    "        fits them, transforms data, and then fits the regressors.\n",
    "        \"\"\"\n",
    "        # --- 1. Create FRESH Pipelines (Fixes IllegalArgumentException) ---\n",
    "        feature_pipe_lineage = create_feature_pipeline(\n",
    "            categorical_features, numerical_features, \"L\"\n",
    "        )\n",
    "        feature_pipe_no_lineage = create_feature_pipeline(\n",
    "            categorical_features, numerical_features_no_lineage, \"NL\"\n",
    "        )\n",
    "\n",
    "        print(\"Fitting feature pipeline (Lineage)...\")\n",
    "        self.feature_model_lineage = feature_pipe_lineage.fit(df)\n",
    "        df_lineage_features = self.feature_model_lineage.transform(df).cache()\n",
    "\n",
    "        print(\"Fitting feature pipeline (No Lineage)...\")\n",
    "        self.feature_model_no_lineage = feature_pipe_no_lineage.fit(df)\n",
    "        df_no_lineage_features = self.feature_model_no_lineage.transform(df).cache()\n",
    "        \n",
    "        # --- 2. Fit Regressors ---\n",
    "        print(\"Fitting Regressor (Lineage)...\")\n",
    "        self.model_lineage = self.regressor_lineage.fit(df_lineage_features)\n",
    "        \n",
    "        print(\"Fitting Regressor (No Lineage)...\")\n",
    "        self.model_no_lineage = self.regressor_no_lineage.fit(df_no_lineage_features)\n",
    "        \n",
    "        # Cleanup memory\n",
    "        df_lineage_features.unpersist()\n",
    "        df_no_lineage_features.unpersist()\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        \"\"\"\n",
    "        Transforms data using both models, averages predictions, and returns\n",
    "        the DataFrame structured exactly as the Evaluator expects.\n",
    "        \"\"\"\n",
    "        if not (self.model_lineage and self.model_no_lineage):\n",
    "            raise Exception(\"VotingEnsemble must be fitted before transforming.\")\n",
    "\n",
    "        # --- Model 1 Prediction ---\n",
    "        df_lineage_feat = self.feature_model_lineage.transform(df)\n",
    "        pred_1 = self.model_lineage.transform(df_lineage_feat)\n",
    "        pred_1_sel = pred_1.select(F.col('pred_lineage'), *self.key_cols)\n",
    "        \n",
    "        # --- Model 2 Prediction ---\n",
    "        df_no_lineage_feat = self.feature_model_no_lineage.transform(df)\n",
    "        pred_2 = self.model_no_lineage.transform(df_no_lineage_feat)\n",
    "        pred_2_sel = pred_2.select(F.col('pred_no_lineage'), *self.key_cols)\n",
    "\n",
    "        # --- Join Predictions ---\n",
    "        df_final = pred_1_sel.join(pred_2_sel, on=self.key_cols, how='inner')\n",
    "        \n",
    "        # --- Join REQUIRED LABELS from original DF (Fixes UNRESOLVED_COLUMN) ---\n",
    "        # We need DEP_DEL15 and SEVERE_DEL60 for the evaluator to work\n",
    "        df_final = df_final.join(\n",
    "            df.select(*self.key_cols, *self.required_labels),\n",
    "            on=self.key_cols,\n",
    "            how='inner'\n",
    "        )\n",
    "\n",
    "        # --- Ensemble Average ---\n",
    "        df_final = df_final.withColumn(\n",
    "            \"prediction\",\n",
    "            (F.col(\"pred_lineage\") + F.col(\"pred_no_lineage\")) / F.lit(2.0)\n",
    "        )\n",
    "        \n",
    "        # Return strict column set to avoid leaking feature columns\n",
    "        return df_final.select(F.col(\"prediction\"), *self.required_labels, *self.key_cols)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 5. EXECUTION\n",
    "# -------------------------------------------------------------------------\n",
    "# 1. Load Data\n",
    "print(\"Loading data...\")\n",
    "data_loader = cv.FlightDelayDataLoader()\n",
    "data_loader.load()\n",
    "\n",
    "# 2. Instantiate Estimator\n",
    "ensemble = VotingEnsemble()\n",
    "\n",
    "# 3. Setup Cross Validator\n",
    "print(\"Initializing Cross Validator...\")\n",
    "cv_ensemble_set = cv.FlightDelayCV(\n",
    "    estimator=ensemble,\n",
    "    dataloader=data_loader,\n",
    "    version=\"3M\"  # Change to \"12M\" or \"60M\" as needed\n",
    ")\n",
    "\n",
    "# 4. Run Fit\n",
    "print(\"Starting CV Fit...\")\n",
    "results_df = cv_ensemble_set.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad7823ad-ebb2-4e26-8ba5-4da44eecdcf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5147d6e0-ee15-47ab-84e3-38579dabedb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cv_ensemble_set = cv.FlightDelayCV(\n",
    "    estimator=ensemble,\n",
    "    dataloader=data_loader,\n",
    "    version=\"12M\"\n",
    ")\n",
    "\n",
    "# 4. Run Fit\n",
    "print(\"Starting CV Fit...\")\n",
    "results_df = cv_ensemble_set.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26adbecd-74bd-459b-9e7a-8c9ef5419ec6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6cbc00b-1bde-4e6d-afed-40ad20e00766",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cv_ensemble_set = cv.FlightDelayCV(\n",
    "    estimator=ensemble,\n",
    "    dataloader=data_loader,\n",
    "    version=\"60M\"\n",
    ")\n",
    "\n",
    "# 4. Run Fit\n",
    "print(\"Starting CV Fit...\")\n",
    "results_df = cv_ensemble_set.fit()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "xgboost-ensemble",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
