{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "f6d3daea-7b87-4ac3-a8aa-dc2e45e8ea74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "cv.py (simplified, CUSTOM-only, no parametrization)\n",
    "\n",
    "Assumptions:\n",
    "- Folds were created from split.py with N_FOLDS = 3 and CREATE_TEST_FOLD = True\n",
    "- Therefore total fold indices written = 4:\n",
    "    FOLD_1_VAL, FOLD_2_VAL, FOLD_3_VAL, FOLD_4_TEST\n",
    "- Files live in:\n",
    "    dbfs:/mnt/mids-w261/student-groups/Group_4_2/processed\n",
    "- File naming:\n",
    "    OTPW_CUSTOM_{VERSION}_FOLD_{i}_{TRAIN|VAL|TEST}.parquet\n",
    "\"\"\"\n",
    "\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "mlflow.autolog(disable=True)\n",
    "\n",
    "# -----------------------------\n",
    "# HARD-CODED GLOBALS\n",
    "# -----------------------------\n",
    "FOLDER_PATH = \"dbfs:/mnt/mids-w261/student-groups/Group_4_2/processed\"\n",
    "SOURCE = \"CUSTOM\"\n",
    "VERSIONS = [\"3M\", \"12M\"]\n",
    "\n",
    "# 3 CV folds + 1 test fold = 4 total fold indices\n",
    "TOTAL_FOLDS = 4\n",
    "\n",
    "\n",
    "class FlightDelayDataLoader:\n",
    "    \"\"\"\n",
    "    CUSTOM-only loader that guarantees all numerical features are cast to double.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.folder_path = \"dbfs:/mnt/mids-w261/student-groups/Group_4_2/processed\"\n",
    "        self.source = \"CUSTOM\"\n",
    "        self.folds = {}\n",
    "        self.versions = [\"3M\", \"12M\"]\n",
    "\n",
    "        self.numerical_features = [\n",
    "            'hourlyprecipitation',\n",
    "            'hourlysealevelpressure',\n",
    "            'hourlyaltimetersetting',\n",
    "            'hourlywetbulbtemperature',\n",
    "            'hourlystationpressure',\n",
    "            'hourlywinddirection',\n",
    "            'hourlyrelativehumidity',\n",
    "            'hourlywindspeed',\n",
    "            'hourlydewpointtemperature',\n",
    "            'hourlydrybulbtemperature',\n",
    "            'hourlyvisibility',\n",
    "            'crs_elapsed_time', # scheduled flight time\n",
    "            'quarter', # inferred from month\n",
    "            'flights', # number of flights? always 1?\n",
    "            'distance', # flight distance, probably important\n",
    "            'year', # excluded bc new predictions will always be in a new year\n",
    "            # latitude and longitude not very useful in linear regression\n",
    "            'origin_station_lat',\n",
    "            'origin_station_lon',\n",
    "            'origin_airport_lat',\n",
    "            'origin_airport_lon',\n",
    "            'origin_station_dis',\n",
    "            'dest_station_lat',\n",
    "            'dest_station_lon',\n",
    "            'dest_airport_lat',\n",
    "            'dest_airport_lon',\n",
    "            'dest_station_dis',\n",
    "            'latitude',\n",
    "            'longitude',\n",
    "            'elevation',\n",
    "        ]\n",
    "\n",
    "    def _cast_numerics(self, df):\n",
    "        \"\"\"\n",
    "        Safely cast all configured numeric columns to doubles.\n",
    "        Handles common bad values like '', 'NA', 'M', 'T', '.', etc.\n",
    "        \"\"\"\n",
    "\n",
    "        # Patterns that should be treated as null\n",
    "        NULL_PAT = r'^(NA|N/A|NULL|null|None|none|\\\\N|\\\\s*|\\\\.|M|T)$'\n",
    "\n",
    "        for colname in self.numerical_features:\n",
    "            if colname in df.columns:\n",
    "                df = df.withColumn(\n",
    "                    colname,\n",
    "                    F.regexp_replace(F.col(colname).cast(\"string\"), NULL_PAT, \"\")\n",
    "                    .cast(\"double\")\n",
    "                )\n",
    "\n",
    "        # Explicitly cast labels to expected numeric types\n",
    "        if \"DEP_DELAY\" in df.columns:\n",
    "            df = df.withColumn(\"DEP_DELAY\", F.col(\"DEP_DELAY\").cast(\"double\"))\n",
    "        if \"DEP_DEL15\" in df.columns:\n",
    "            df = df.withColumn(\"DEP_DEL15\", F.col(\"DEP_DEL15\").cast(\"int\"))\n",
    "        if \"SEVERE_DEL60\" in df.columns:\n",
    "            df = df.withColumn(\"SEVERE_DEL60\", F.col(\"SEVERE_DEL60\").cast(\"int\"))\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _load_parquet(self, name):\n",
    "        spark = SparkSession.builder.getOrCreate()\n",
    "        df = spark.read.parquet(f\"{self.folder_path}/{name}.parquet\")\n",
    "        df = self._cast_numerics(df)\n",
    "        return df\n",
    "\n",
    "    def _load_version(self, version):\n",
    "        folds = []\n",
    "        for fold_idx in range(1, 4 + 1):  # 3 CV folds + 1 test\n",
    "            train_name = f\"OTPW_{self.source}_{version}_FOLD_{fold_idx}_TRAIN\"\n",
    "            train_df = self._load_parquet(train_name)\n",
    "\n",
    "            if fold_idx < 4:\n",
    "                val_name = f\"OTPW_{self.source}_{version}_FOLD_{fold_idx}_VAL\"\n",
    "                val_df = self._load_parquet(val_name)\n",
    "                folds.append((train_df, val_df))\n",
    "            else:\n",
    "                test_name = f\"OTPW_{self.source}_{version}_FOLD_{fold_idx}_TEST\"\n",
    "                test_df = self._load_parquet(test_name)\n",
    "                folds.append((train_df, test_df))\n",
    "\n",
    "        return folds\n",
    "\n",
    "    def load(self):\n",
    "        for version in self.versions:\n",
    "            self.folds[version] = self._load_version(version)\n",
    "\n",
    "    def get_version(self, version):\n",
    "        return self.folds[version]\n",
    "\n",
    "# -----------------------------\n",
    "# EVALUATOR (NULL-SAFE RMSE)\n",
    "# -----------------------------\n",
    "class FlightDelayEvaluator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        prediction_col=\"prediction\",\n",
    "        numeric_label_col=\"DEP_DELAY\",\n",
    "        binary_label_col=\"DEP_DEL15\",\n",
    "        severe_label_col=\"SEVERE_DEL60\",\n",
    "    ):\n",
    "        self.prediction_col = prediction_col\n",
    "        self.numeric_label_col = numeric_label_col\n",
    "        self.binary_label_col = binary_label_col\n",
    "        self.severe_label_col = severe_label_col\n",
    "\n",
    "        self.rmse_evaluator = RegressionEvaluator(\n",
    "            predictionCol=prediction_col,\n",
    "            labelCol=numeric_label_col,\n",
    "            metricName=\"rmse\"\n",
    "        )\n",
    "\n",
    "    def calculate_rmse(self, predictions_df):\n",
    "        # Drop any residual nulls before RegressionEvaluator sees them\n",
    "        clean = predictions_df.dropna(\n",
    "            subset=[self.numeric_label_col, self.prediction_col]\n",
    "        )\n",
    "        return self.rmse_evaluator.evaluate(clean)\n",
    "\n",
    "    def _calculate_classification_metrics(self, predictions_df, threshold, label_col):\n",
    "        # Null-safe for classification too\n",
    "        df = predictions_df.dropna(subset=[self.prediction_col, label_col])\n",
    "\n",
    "        pred_binary_col = f\"pred_binary_{threshold}\"\n",
    "        df = df.withColumn(\n",
    "            pred_binary_col,\n",
    "            F.when(F.col(self.prediction_col) >= threshold, 1).otherwise(0)\n",
    "        )\n",
    "\n",
    "        tp = df.filter((F.col(pred_binary_col) == 1) & (F.col(label_col) == 1)).count()\n",
    "        fp = df.filter((F.col(pred_binary_col) == 1) & (F.col(label_col) == 0)).count()\n",
    "        tn = df.filter((F.col(pred_binary_col) == 0) & (F.col(label_col) == 0)).count()\n",
    "        fn = df.filter((F.col(pred_binary_col) == 0) & (F.col(label_col) == 1)).count()\n",
    "\n",
    "        total = tp + fp + tn + fn\n",
    "        precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0.0\n",
    "        accuracy = (tp + tn) / total if total else 0.0\n",
    "\n",
    "        return dict(tp=tp, fp=fp, tn=tn, fn=fn,\n",
    "                    precision=precision, recall=recall, f1=f1, accuracy=accuracy)\n",
    "\n",
    "    def calculate_otpa_metrics(self, predictions_df):\n",
    "        return self._calculate_classification_metrics(\n",
    "            predictions_df, threshold=15, label_col=self.binary_label_col\n",
    "        )[\"accuracy\"]\n",
    "\n",
    "    def calculate_sddr_metrics(self, predictions_df):\n",
    "        return self._calculate_classification_metrics(\n",
    "            predictions_df, threshold=60, label_col=self.severe_label_col\n",
    "        )[\"recall\"]\n",
    "\n",
    "    def evaluate(self, predictions_df):\n",
    "        return {\n",
    "            \"rmse\": self.calculate_rmse(predictions_df),\n",
    "            \"otpa\": self.calculate_otpa_metrics(predictions_df),\n",
    "            \"sddr\": self.calculate_sddr_metrics(predictions_df),\n",
    "        }\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# CROSS-VALIDATOR (NO PARAMS)\n",
    "# -----------------------------\n",
    "class FlightDelayCV:\n",
    "    def __init__(self, estimator, dataloader, version):\n",
    "        self.estimator = estimator\n",
    "        self.version = version\n",
    "\n",
    "        if dataloader:\n",
    "            self.data_loader = dataloader\n",
    "        else:\n",
    "            self.data_loader = FlightDelayDataLoader()\n",
    "            self.data_loader.load()\n",
    "\n",
    "        self.evaluator = FlightDelayEvaluator()\n",
    "        self.folds = self.data_loader.get_version(version)\n",
    "\n",
    "        self.metrics = []\n",
    "        self.models = []\n",
    "        self.test_metric = None\n",
    "        self.test_model = None\n",
    "\n",
    "    def fit(self):\n",
    "        # CV folds only (exclude last test fold)\n",
    "        for train_df, val_df in self.folds[:-1]:\n",
    "            model = self.estimator.fit(train_df)\n",
    "            preds = model.transform(val_df)\n",
    "\n",
    "            metric = self.evaluator.evaluate(preds)\n",
    "            self.metrics.append(metric)\n",
    "            self.models.append(model)\n",
    "\n",
    "        m = pd.DataFrame(self.metrics)\n",
    "        m.loc[\"mean\"] = m.mean()\n",
    "        m.loc[\"std\"] = m.std()\n",
    "        return m\n",
    "\n",
    "    def evaluate(self):\n",
    "        train_df, test_df = self.folds[-1]\n",
    "        self.test_model = self.estimator.fit(train_df)\n",
    "        preds = self.test_model.transform(test_df)\n",
    "        self.test_metric = self.evaluator.evaluate(preds)\n",
    "        return self.test_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "541a126a-f783-4dc1-8623-7357d74a5b9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class MedianRegressor:\n",
    "    def __init__(self):\n",
    "        self.value = None\n",
    "\n",
    "    def fit(self, df):\n",
    "        self.value = df.approxQuantile(\"DEP_DELAY\", [0.5], 0.01)[0]\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        return df.withColumn(\"prediction\", F.lit(self.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7d86bcd-729e-46c2-aaa3-603e14cc1140",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_loader = FlightDelayDataLoader()\n",
    "data_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b002a4e6-98e1-40ac-adcc-cea5eaf4c813",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "folds = data_loader.get_version(\"3M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cd3d046-ff40-4f49-940f-b6ef7b797964",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cv = FlightDelayCV(\n",
    "    estimator=MedianRegressor(),\n",
    "    dataloader=data_loader,\n",
    "    version=\"12M\"\n",
    ")\n",
    "cv.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef4af7cc-91fb-4405-bc06-edea64ff85d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "outcome_vars = [\n",
    "    'arr_delay', 'arr_delay_new', 'arr_del15', 'arr_delay_group',\n",
    "    'dep_delay', 'dep_delay_new', 'dep_del15', 'dep_delay_group',\n",
    "    'actual_elapsed_time', 'air_time', 'wheels_on', 'taxi_in', \n",
    "    'arr_time', 'taxi_out', 'wheels_off', 'dep_time', 'cancelled', 'diverted'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'day_of_week',\n",
    "    # 'op_unique_carrier', # redundant with op_carrier\n",
    "    'op_carrier',\n",
    "    'origin', # origin airport code\n",
    "    'origin_state_abr', # origin state abbreviation\n",
    "    'dest', # destination airport code\n",
    "    'dest_state_abr', # destination state abbreviation\n",
    "    # 'tail_num', # excluded bc each plane has this code, too many categories\n",
    "    'dep_time_blk', # not outcome var bc this is scheduled departure\n",
    "    'arr_time_blk', # not outcome var bc this is scheduled arrival\n",
    "    # 'report_type' # type of weather report, not super useful\n",
    "    # 'op_carrier_fl_num' # just the flight number\n",
    "    # 'distance_group', # likely important, but already captured in 'distance'\n",
    "\n",
    "    # 'crs_dep_time', # scheduled departure time, already captured in dep_time_blk\n",
    "    # 'crs_arr_time', # scheduled arrival time already captured in arr_time_blk\n",
    "    'day_of_month',\n",
    "    'month', # cyclical patterns\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    'hourlyprecipitation',\n",
    "    'hourlysealevelpressure',\n",
    "    'hourlyaltimetersetting',\n",
    "    'hourlywetbulbtemperature',\n",
    "    'hourlystationpressure',\n",
    "    'hourlywinddirection',\n",
    "    'hourlyrelativehumidity',\n",
    "    'hourlywindspeed',\n",
    "    'hourlydewpointtemperature',\n",
    "    'hourlydrybulbtemperature',\n",
    "    'hourlyvisibility',\n",
    "    'crs_elapsed_time', # scheduled flight time\n",
    "    # 'quarter', # inferred from month\n",
    "    # 'flights', # number of flights? always 1?\n",
    "    'distance', # flight distance, probably important\n",
    "    # 'year', # excluded bc new predictions will always be in a new year\n",
    "    # # latitude and longitude not very useful in linear regression\n",
    "    # 'origin_station_lat',\n",
    "    # 'origin_station_lon',\n",
    "    # 'origin_airport_lat',\n",
    "    # 'origin_airport_lon',\n",
    "    # 'origin_station_dis',\n",
    "    # 'dest_station_lat',\n",
    "    # 'dest_station_lon',\n",
    "    # 'dest_airport_lat',\n",
    "    # 'dest_airport_lon',\n",
    "    # 'dest_station_dis',\n",
    "    # 'latitude',\n",
    "    # 'longitude',\n",
    "    'elevation',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecd5c675-c796-4b7d-a238-fe1cf8170c75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer, StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=numerical_features,\n",
    "    outputCols=[f\"{col}_IMPUTED\" for col in numerical_features],\n",
    "    strategy=\"mean\"\n",
    ")\n",
    "\n",
    "indexer = StringIndexer(\n",
    "    inputCols=categorical_features,\n",
    "    outputCols=[f\"{col}_INDEX\" for col in categorical_features],\n",
    "    handleInvalid=\"keep\"\n",
    ")\n",
    "\n",
    "encoder = OneHotEncoder(\n",
    "    inputCols=[f\"{col}_INDEX\" for col in categorical_features],\n",
    "    outputCols=[f\"{col}_VEC\" for col in categorical_features]\n",
    ")\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[f\"{col}_VEC\" for col in categorical_features] + \n",
    "              [f\"{col}_IMPUTED\" for col in numerical_features],\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\"\n",
    ")\n",
    "\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"features\",\n",
    "    outputCol=\"scaled_features\",\n",
    "    withMean=True,\n",
    "    withStd=True\n",
    ")\n",
    "\n",
    "lr = LinearRegression(\n",
    "    featuresCol=\"scaled_features\", \n",
    "    labelCol=\"DEP_DELAY\",\n",
    "    elasticNetParam=0.0,\n",
    ")\n",
    "\n",
    "lr_pipe = Pipeline(stages=[imputer, indexer, encoder, assembler, scaler, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c36bd984-4ac5-45ea-b830-8b26f671998f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cv = FlightDelayCV(\n",
    "    estimator=lr_pipe,\n",
    "    dataloader=data_loader,\n",
    "    version=\"12M\"\n",
    ")\n",
    "cv.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81ea3775-e2f8-4d65-bb94-5b804fa68cb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer, StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Feature definitions\n",
    "outcome_vars = [\n",
    "    'arr_delay', 'arr_delay_new', 'arr_del15', 'arr_delay_group',\n",
    "    'dep_delay', 'dep_delay_new', 'dep_del15', 'dep_delay_group',\n",
    "    'actual_elapsed_time', 'air_time', 'wheels_on', 'taxi_in', \n",
    "    'arr_time', 'taxi_out', 'wheels_off', 'dep_time', 'cancelled', 'diverted'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'day_of_week',\n",
    "    'op_carrier',\n",
    "    # 'origin',\n",
    "    # 'origin_state_abr',\n",
    "    # 'dest',\n",
    "    # 'dest_state_abr',\n",
    "    'dep_time_blk',\n",
    "    'arr_time_blk',\n",
    "    'day_of_month',\n",
    "    'month',\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    'hourlyprecipitation',\n",
    "    'hourlysealevelpressure',\n",
    "    'hourlyaltimetersetting',\n",
    "    'hourlywetbulbtemperature',\n",
    "    'hourlystationpressure',\n",
    "    'hourlywinddirection',\n",
    "    'hourlyrelativehumidity',\n",
    "    'hourlywindspeed',\n",
    "    'hourlydewpointtemperature',\n",
    "    'hourlydrybulbtemperature',\n",
    "    'hourlyvisibility',\n",
    "    'crs_elapsed_time',\n",
    "    'distance',\n",
    "    'elevation',\n",
    "]\n",
    "\n",
    "# Pipeline stages\n",
    "imputer = Imputer(\n",
    "    inputCols=numerical_features,\n",
    "    outputCols=[f\"{col}_IMPUTED\" for col in numerical_features],\n",
    "    strategy=\"mean\"\n",
    ")\n",
    "\n",
    "indexer = StringIndexer(\n",
    "    inputCols=categorical_features,\n",
    "    outputCols=[f\"{col}_INDEX\" for col in categorical_features],\n",
    "    handleInvalid=\"keep\"\n",
    ")\n",
    "\n",
    "encoder = OneHotEncoder(\n",
    "    inputCols=[f\"{col}_INDEX\" for col in categorical_features],\n",
    "    outputCols=[f\"{col}_VEC\" for col in categorical_features],\n",
    "    dropLast=False  # Keep all categories for Random Forest\n",
    ")\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[f\"{col}_VEC\" for col in categorical_features] + \n",
    "              [f\"{col}_IMPUTED\" for col in numerical_features],\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\"\n",
    ")\n",
    "\n",
    "# Random Forest Regressor\n",
    "# Note: No StandardScaler needed for tree-based models\n",
    "rf = RandomForestRegressor(\n",
    "    featuresCol=\"features\", \n",
    "    labelCol=\"DEP_DELAY\",\n",
    "    numTrees=10,\n",
    "    maxDepth=2,\n",
    ")\n",
    "\n",
    "# Pipeline with all categorical features one-hot encoded\n",
    "rf_pipe = Pipeline(stages=[imputer, indexer, encoder, assembler, rf])\n",
    "\n",
    "# Cross-validation\n",
    "cv = FlightDelayCV(\n",
    "    estimator=rf_pipe,\n",
    "    dataloader=data_loader,\n",
    "    version=\"12M\"\n",
    ")\n",
    "cv.fit()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Cross Validator",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
