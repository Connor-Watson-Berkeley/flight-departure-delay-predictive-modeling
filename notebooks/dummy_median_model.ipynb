{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebc9316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Spark session\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "import pandas as pd\n",
    "\n",
    "# Import the loader & evaluator from this repo\n",
    "from cv import FlightDelayDataLoader, FlightDelayEvaluator\n",
    "\n",
    "# Create / get Spark session (works on Databricks)\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "print('Spark:', spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426245f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure and load folds\n",
    "# Adjust `folder_path` if you saved folds to a different location\n",
    "loader = FlightDelayDataLoader(\n",
    "    folder_path=\"dbfs:/student-groups/Group_4_2\",\n",
    "    n_folds=3,           # matches split.py default (3 CV folds + 1 test)\n",
    "    source=\"CUSTOM\"   # or 'PROVIDED' if you saved OTPW_PROVIDED_* files\n",
    ")\n",
    "loader.load()\n",
    "\n",
    "version = '3M'\n",
    "folds = loader.get_version(version)\n",
    "print(f'Loaded {len(folds)} folds for version={version}')\n",
    "for i, (t, v) in enumerate(folds):\n",
    "    print(f' Fold {i+1}: train={t.count()}, val={v.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab90b122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run median predictor on CV folds (exclude final test fold)\n",
    "evaluator = FlightDelayEvaluator()\n",
    "metrics = []\n",
    "\n",
    "for idx, (train_df, val_df) in enumerate(folds[:-1]):\n",
    "    # Ensure DEP_DELAY is numeric\n",
    "    if 'DEP_DELAY' not in train_df.columns:\n",
    "        raise RuntimeError('DEP_DELAY column missing from training data')\n",
    "\n",
    "    train_df = train_df.withColumn('DEP_DELAY', F.col('DEP_DELAY').cast('double'))\n",
    "    # Compute median using approxQuantile (fast and safe for large datasets)\n",
    "    median = train_df.approxQuantile('DEP_DELAY', [0.5], 0.001)[0]\n",
    "    print(f'Fold {idx+1} train median DEP_DELAY = {median}')\n",
    "\n",
    "    # Create constant prediction on validation set\n",
    "    val_pred = val_df.withColumn('prediction', F.lit(float(median)))\n",
    "\n",
    "    # Evaluate and collect metrics\n",
    "    metric = evaluator.evaluate(val_pred)\n",
    "    metric['fold'] = idx + 1\n",
    "    metrics.append(metric)\n",
    "\n",
    "# Convert to pandas for nicer display\n",
    "metrics_pd = pd.DataFrame(metrics).set_index('fold') if metrics else pd.DataFrame()\n",
    "print('\n",
    "Cross-validation fold metrics (median predictor):')\n",
    "print(metrics_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599cfdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on final test fold (last tuple)\n",
    "train_combined, test_df = folds[-1]\n",
    "train_combined = train_combined.withColumn('DEP_DELAY', F.col('DEP_DELAY').cast('double'))\n",
    "median = train_combined.approxQuantile('DEP_DELAY', [0.5], 0.001)[0]\n",
    "test_pred = test_df.withColumn('prediction', F.lit(float(median)))\n",
    "test_metric = evaluator.evaluate(test_pred)\n",
    "print('\n",
    "Test fold metric (median predictor):')\n",
    "print(test_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dd6f18",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "- Replace the median predictor with a real `Pipeline` (feature assembler + estimator).\n",
    "- Use `FlightDelayCV` wrapper to train Spark ML estimators if you prefer automated fold training.\n",
    "- Add logging or write metrics to a CSV for experiment tracking."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
