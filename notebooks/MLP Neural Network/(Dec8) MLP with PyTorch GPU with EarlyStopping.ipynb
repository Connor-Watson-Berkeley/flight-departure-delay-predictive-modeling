{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97023af5-5e99-4bc5-a86f-4d546db1f541",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "MLP Model using PyTorch + GPU Support\n",
    "====================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c7bfd43-169f-4ea5-be2a-01884b7fcea5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Summary\n",
    "\n",
    "- Here we build Distributed MLP models. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87c9b079-ed49-41dd-a9f5-16bc8878f3f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Spark Settings\n",
    "# to avoid OOM Error\n",
    "\n",
    "spark.catalog.clearCache()\n",
    "\n",
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"16000\") \n",
    "try:\n",
    "    spark.conf.set(\"spark.databricks.io.cache.enabled\", \"false\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Spark cache cleared.\")\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Load cv module directly from file path\n",
    "cv_path = \"/Workspace/Shared/Team 4_2/flight-departure-delay-predictive-modeling/notebooks/Cross Validator/cv.py\"\n",
    "spec = importlib.util.spec_from_file_location(\"cv\", cv_path)\n",
    "cv = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(cv)\n",
    "\n",
    "\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pathlib import Path\n",
    "from pyspark.ml.feature import (\n",
    "    Imputer, StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    ")\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# >>> PYTORCH AND DISTRIBUTOR IMPORTS <<<\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pyspark.ml.torch.distributor import TorchDistributor \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- PYTORCH TRAIN FUNCTION (RUNS ON WORKERS) ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d36d1226-19f4-4016-b5f4-44f46b6f5093",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Training Function on Workers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4796359f-fe45-4a7a-a638-e988bae5f562",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- SHARED MODEL DEFINITION ---\n",
    "class PyTorchMLPRegressor(nn.Module):\n",
    "    \"\"\"\n",
    "    Shared MLP architecture for both Training (Workers) and Inference (Driver/Workers).\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_layers, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_features = input_dim\n",
    "        for units in hidden_layers:\n",
    "            layers.append(nn.Linear(in_features, units))\n",
    "            layers.append(nn.BatchNorm1d(units))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            in_features = units\n",
    "        layers.append(nn.Linear(in_features, 1))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x).squeeze(1)\n",
    "    \n",
    "\n",
    "def train_fn(params):\n",
    "    import os, sys, traceback, glob, random, shutil\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    import torch.distributed as dist\n",
    "    from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "    from torch.utils.data import DataLoader, IterableDataset\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    # --- Early Stopping Helper ---\n",
    "    class EarlyStopping:\n",
    "        def __init__(self, patience=5, min_delta=0.0):\n",
    "            self.patience = patience\n",
    "            self.min_delta = min_delta\n",
    "            self.counter = 0\n",
    "            self.best_loss = None\n",
    "            self.early_stop = False\n",
    "\n",
    "        def __call__(self, val_loss):\n",
    "            if self.best_loss is None:\n",
    "                self.best_loss = val_loss\n",
    "            elif val_loss > self.best_loss - self.min_delta:\n",
    "                self.counter += 1\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_loss = val_loss\n",
    "                self.counter = 0\n",
    "\n",
    "    try:\n",
    "        # --- DDP Init ---\n",
    "        backend = \"nccl\" if params[\"use_gpu\"] and torch.cuda.is_available() else \"gloo\"\n",
    "        dist.init_process_group(backend=backend)\n",
    "\n",
    "        if params[\"use_gpu\"] and torch.cuda.is_available():\n",
    "            local_rank = int(os.environ.get(\"LOCAL_RANK\", 0))\n",
    "            device = torch.device(f\"cuda:{local_rank}\")\n",
    "            torch.cuda.set_device(device)\n",
    "            device_ids = [local_rank]\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "            device_ids = None\n",
    "\n",
    "        rank = dist.get_rank()\n",
    "        world_size = dist.get_world_size()\n",
    "\n",
    "        # Convert dbfs path\n",
    "        path_local = params[\"train_path\"].replace(\"dbfs:/\", \"/dbfs/\") if params[\"train_path\"].startswith(\"dbfs:/\") else params[\"train_path\"]\n",
    "\n",
    "        # --- Data Splitting (Train vs Validation) ---\n",
    "        # We perform a deterministic shuffle so all ranks agree on which files are Train vs Val\n",
    "        all_files = sorted(glob.glob(os.path.join(path_local, \"*.parquet\")))\n",
    "        all_files = [f for f in all_files if not f.endswith(\"_SUCCESS\") and not os.path.basename(f).startswith(\".\")]\n",
    "        \n",
    "        # Deterministic shuffle\n",
    "        random.Random(42).shuffle(all_files)\n",
    "        \n",
    "        # 10% Validation Split\n",
    "        split_idx = int(len(all_files) * 0.9)\n",
    "        train_files_global = all_files[:split_idx]\n",
    "        val_files_global = all_files[split_idx:]\n",
    "\n",
    "        if not val_files_global:\n",
    "            print(\"Warning: Not enough files for validation split. Using training data for validation.\")\n",
    "            val_files_global = train_files_global\n",
    "\n",
    "        # --- Dataset Definition ---\n",
    "        class ParquetFlightIterableDataset(IterableDataset):\n",
    "            def __init__(self, file_list, rank, world_size):\n",
    "                self.file_list = file_list\n",
    "                self.rank = rank\n",
    "                self.world_size = world_size\n",
    "\n",
    "            def __iter__(self):\n",
    "                worker_info = torch.utils.data.get_worker_info()\n",
    "                if worker_info is None:\n",
    "                    my_files = self.file_list[self.rank::self.world_size]\n",
    "                else:\n",
    "                    # Split by GPU Rank then by CPU Worker\n",
    "                    gpu_files = self.file_list[self.rank::self.world_size]\n",
    "                    my_files = gpu_files[worker_info.id::worker_info.num_workers]\n",
    "\n",
    "                random.shuffle(my_files)\n",
    "                for f in my_files:\n",
    "                    try:\n",
    "                        pdf = pd.read_parquet(f, columns=[\"features_arr\", \"DEP_DELAY\"], engine='pyarrow')\n",
    "                        if len(pdf) == 0: continue\n",
    "                        X = np.stack(pdf[\"features_arr\"].values).astype(np.float32, copy=False)\n",
    "                        y = pdf[\"DEP_DELAY\"].values.astype(np.float32, copy=False)\n",
    "                        for i in range(len(y)):\n",
    "                            yield torch.from_numpy(X[i]), torch.tensor(y[i])\n",
    "                    except Exception:\n",
    "                        continue\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_ds = ParquetFlightIterableDataset(train_files_global, rank, world_size)\n",
    "        val_ds = ParquetFlightIterableDataset(val_files_global, rank, world_size)\n",
    "\n",
    "        train_loader = DataLoader(train_ds, batch_size=params[\"batch_size\"], num_workers=4, prefetch_factor=2, pin_memory=True )\n",
    "        val_loader = DataLoader(val_ds, batch_size=params[\"batch_size\"], num_workers=4, prefetch_factor=2, pin_memory=True)\n",
    "\n",
    "        # --- Model Setup ---\n",
    "        # Assuming PyTorchMLPRegressor is defined globally as discussed\n",
    "        model = PyTorchMLPRegressor(params[\"input_dim\"], params[\"hidden_layers\"], params[\"dropout_rate\"]).to(device)\n",
    "        ddp_model = DDP(model, device_ids=device_ids)\n",
    "        optimizer = optim.Adam(ddp_model.parameters(), lr=params[\"learning_rate\"], weight_decay=params[\"weight_decay\"])\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        # Initialize Early Stopping\n",
    "        early_stopper = EarlyStopping(patience=params.get(\"patience\", 5))\n",
    "\n",
    "        # --- Training Loop ---\n",
    "        for epoch in range(params[\"epochs\"]):\n",
    "            # 1. Train\n",
    "            ddp_model.train()\n",
    "            train_loss_sum = 0.0\n",
    "            train_batches = 0\n",
    "            \n",
    "            for xb, yb in train_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                out = ddp_model(xb)\n",
    "                loss = criterion(out, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss_sum += loss.item()\n",
    "                train_batches += 1\n",
    "\n",
    "            # 2. Validation\n",
    "            ddp_model.eval()\n",
    "            val_loss_sum = 0.0\n",
    "            val_batches = 0\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in val_loader:\n",
    "                    xb, yb = xb.to(device), yb.to(device)\n",
    "                    out = ddp_model(xb)\n",
    "                    loss = criterion(out, yb)\n",
    "                    val_loss_sum += loss.item()\n",
    "                    val_batches += 1\n",
    "            \n",
    "            # 3. Aggregate Metrics across GPUs\n",
    "            # We map loss/counts to tensors to reduce them across the cluster\n",
    "            metrics_tensor = torch.tensor([train_loss_sum, train_batches, val_loss_sum, val_batches], device=device)\n",
    "            dist.all_reduce(metrics_tensor, op=dist.ReduceOp.SUM)\n",
    "            \n",
    "            global_train_loss = metrics_tensor[0] / max(metrics_tensor[1], 1)\n",
    "            global_val_loss = metrics_tensor[2] / max(metrics_tensor[3], 1)\n",
    "\n",
    "            if rank == 0:\n",
    "                print(f\"Epoch {epoch+1}/{params['epochs']} | Train Loss: {global_train_loss:.4f} | Val Loss: {global_val_loss:.4f}\")\n",
    "\n",
    "            # 4. Check Early Stopping (On all ranks to ensure synchronization)\n",
    "            # We use global_val_loss (synced) so all ranks make same decision\n",
    "            early_stopper(global_val_loss.item())\n",
    "            \n",
    "            if early_stopper.early_stop:\n",
    "                if rank == 0:\n",
    "                    print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "        # --- Save Model ---\n",
    "        if rank == 0:\n",
    "            torch.save(model.state_dict(), params[\"model_path\"])\n",
    "\n",
    "    except Exception:\n",
    "        print(traceback.format_exc())\n",
    "        sys.exit(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7d86bcd-729e-46c2-aaa3-603e14cc1140",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_loader = cv.FlightDelayDataLoader()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1e7602a-c9c3-4a22-b7ec-cfc50f458da0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Driver Side Code\n",
    "\n",
    "1. PyTorch MLP Regressor\n",
    "2. Spark PyTorch Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59e57e47-b9b7-4ae6-8505-3b5085aea41f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# PYTORCH MLP REGRESSOR INTEGRATED WITH TORCHDISTRIBUTOR\n",
    "# =====================================================\n",
    "\n",
    "\n",
    "# --- DRIVER-SIDE MLP MODEL DEFINITION ---\n",
    "\n",
    "\n",
    "class SparkPyTorchEstimator:\n",
    "    def __init__(self, hidden_layers=None, dropout_rate=0.3, learning_rate=0.001, \n",
    "                 batch_size=256, epochs=30, num_processes=None, infer_batch_size=None, patience=5):\n",
    "        \n",
    "        self.hidden_layers = hidden_layers or [128, 64]\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "\n",
    "        self.infer_batch_size = infer_batch_size or batch_size\n",
    "        self.patience = patience\n",
    "        \n",
    "        self.use_gpu = torch.cuda.is_available()\n",
    "        \n",
    "        if num_processes is None:\n",
    "            if self.use_gpu:\n",
    "                self.num_processes = torch.cuda.device_count()\n",
    "            else:\n",
    "                self.num_processes = 1\n",
    "        else:\n",
    "            self.num_processes = max(1, num_processes)\n",
    "\n",
    "        self.model_path = \"/dbfs/tmp/torch_mlp_state_dict.pth\"\n",
    "        self.input_dim = None\n",
    "        \n",
    "    def fit(self, df):\n",
    "        \"\"\"\n",
    "        Uses TorchDistributor for distributed training, without collecting\n",
    "        the entire dataset to the driver.\n",
    "        \"\"\"\n",
    "        # Optional: clear old Spark caches to avoid leftover 60M stuff\n",
    "        # df.sparkSession.catalog.clearCache()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Determine input_dim from a single row\n",
    "        if self.input_dim is None:\n",
    "            sample = df.select(vector_to_array(\"scaled_features\").alias(\"features_arr\")).limit(1).collect()\n",
    "            if not sample:\n",
    "                raise ValueError(\"No rows in training dataframe.\")\n",
    "            self.input_dim = len(sample[0][\"features_arr\"])\n",
    "\n",
    "        # Prepare train DF (features_arr + label)\n",
    "        df_train = df.select(\n",
    "            vector_to_array(\"scaled_features\").alias(\"features_arr\"),\n",
    "            F.col(\"DEP_DELAY\").cast(DoubleType())\n",
    "        ).dropna(subset=[\"features_arr\", \"DEP_DELAY\"])\n",
    "\n",
    "\n",
    "        unique_id = str(uuid.uuid4())\n",
    "        train_path = f\"dbfs:/tmp/mlp_train_{unique_id}\"\n",
    "        \n",
    "        \n",
    "        # Write training data to sharded parquet; this is streaming and\n",
    "        # does NOT collect everything to the driver.\n",
    "        num_shards = max(self.num_processes * 4, 2000)\n",
    "        num_columns = len(df_train.columns)\n",
    "        print(f\"Number of columns: {num_columns}\")\n",
    "        print(f\"Number of shards: {num_shards}\")\n",
    "\n",
    "        (\n",
    "            df_train\n",
    "            .repartition(num_shards)\n",
    "            .write\n",
    "            .mode(\"overwrite\")\n",
    "            .parquet(train_path)\n",
    "        )\n",
    "\n",
    "        \n",
    "        params = {\n",
    "            \"input_dim\": self.input_dim,\n",
    "            \"hidden_layers\": self.hidden_layers,\n",
    "            \"dropout_rate\": self.dropout_rate,\n",
    "            \"learning_rate\": self.learning_rate,\n",
    "            \"weight_decay\": 0.0001,\n",
    "            \"batch_size\": self.batch_size,\n",
    "            \"epochs\": self.epochs,\n",
    "            \"use_gpu\": self.use_gpu,\n",
    "            \"model_path\": self.model_path,\n",
    "            \"train_path\": train_path,\n",
    "            \"patience\": self.patience if hasattr(self, 'patience') else 5\n",
    "        }\n",
    "\n",
    "        distributor = TorchDistributor(\n",
    "            num_processes=self.num_processes,\n",
    "            local_mode=False,\n",
    "            use_gpu=self.use_gpu,\n",
    "        )\n",
    "\n",
    "        # Ensure model path directory exists\n",
    "        model_path_obj = Path(self.model_path)\n",
    "        model_path_obj.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        print(f\"Starting distributed training. Processes: {self.num_processes}, CUDA: {self.use_gpu}\")\n",
    "        distributor.run(train_fn, params)\n",
    "\n",
    "        # load model on driver\n",
    "        self.trained_model = PyTorchMLPRegressor(\n",
    "            self.input_dim, self.hidden_layers, self.dropout_rate\n",
    "        )\n",
    "        self.trained_model.load_state_dict(torch.load(self.model_path))\n",
    "        self.trained_model.eval()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        \"\"\"\n",
    "        Uses mapInPandas for parallel inference on workers, with explicit batching\n",
    "        to avoid OOM during evaluation.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'trained_model'):\n",
    "            raise ValueError(\"Model not fitted.\")\n",
    "        \n",
    "        # Serialize model weights for broadcast\n",
    "        model_state_dict = self.trained_model.state_dict()\n",
    "        schema = df.schema.add(\"prediction\", DoubleType())\n",
    "\n",
    "        # Determine if workers should use GPU (if driver used GPU)\n",
    "        use_gpu = self.use_gpu\n",
    "        infer_batch_size = self.infer_batch_size\n",
    "\n",
    "        def predict_partition_full(iterator):\n",
    "            # 1. Setup device (GPU for inference if available)\n",
    "            device = torch.device(\"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
    "            \n",
    "            # 2. Initialize and load model ONCE per worker task\n",
    "            worker_model = PyTorchMLPRegressor(\n",
    "                self.input_dim, self.hidden_layers, self.dropout_rate\n",
    "            ).to(device)\n",
    "            worker_model.load_state_dict(model_state_dict)\n",
    "            worker_model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for pdf_batch in iterator:\n",
    "                    # Extract features from this Spark partition batch\n",
    "                    X_np = np.stack(pdf_batch[\"features_arr\"].values)\n",
    "                    n = X_np.shape[0]\n",
    "\n",
    "                    # Pre-allocate predictions on CPU as float64 to match DoubleType\n",
    "                    preds_all = np.empty(n, dtype=np.float64)\n",
    "\n",
    "                    # --- BATCHED INFERENCE TO AVOID OOM ---\n",
    "                    for start in range(0, n, infer_batch_size):\n",
    "                        end = min(start + infer_batch_size, n)\n",
    "                        inputs = torch.from_numpy(X_np[start:end]).float().to(device)\n",
    "                        preds = worker_model(inputs).cpu().numpy().astype(np.float64)\n",
    "                        preds_all[start:end] = preds\n",
    "\n",
    "                    pdf_batch[\"prediction\"] = preds_all\n",
    "                    yield pdf_batch.drop(columns=[\"features_arr\"])\n",
    "\n",
    "        # Add the array column temporarily\n",
    "        df_with_arr = df.withColumn(\"features_arr\", vector_to_array(\"scaled_features\"))\n",
    "        \n",
    "        # Final transform\n",
    "        return df_with_arr.mapInPandas(predict_partition_full, schema=schema)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d44d515f-dd60-4659-9f00-1d1df8fd1863",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### MLP Pipeline Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "738da181-7db7-459d-b4cf-7bcc19a13453",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# =====================================================\n",
    "# 2. MLP PIPELINE WRAPPER\n",
    "# =====================================================\n",
    "\n",
    "class MLPFlightDelayPipeline:\n",
    "    \"\"\"\n",
    "    Wrapper that combines Spark preprocessing + PyTorch MLP into a single estimator.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        categorical_features,\n",
    "        numerical_features,\n",
    "        mlp_params=None,\n",
    "    ):\n",
    "        self.categorical_features = categorical_features\n",
    "        self.numerical_features = numerical_features\n",
    "        self.mlp_params = mlp_params or {}\n",
    "        \n",
    "        self.preprocessing_pipeline = None\n",
    "        self.pytorch_estimator = None\n",
    "        \n",
    "    def _build_preprocessing_pipeline(self):\n",
    "        imputer = Imputer(\n",
    "            inputCols=self.numerical_features,\n",
    "            outputCols=[f\"{col}_IMPUTED\" for col in self.numerical_features],\n",
    "            strategy=\"mean\"\n",
    "        )\n",
    "        \n",
    "        indexer = StringIndexer(\n",
    "            inputCols=self.categorical_features,\n",
    "            outputCols=[f\"{col}_INDEX\" for col in self.categorical_features],\n",
    "            handleInvalid=\"keep\"\n",
    "        )\n",
    "        \n",
    "        encoder = OneHotEncoder(\n",
    "            inputCols=[f\"{col}_INDEX\" for col in self.categorical_features],\n",
    "            outputCols=[f\"{col}_VEC\" for col in self.categorical_features],\n",
    "            dropLast=False\n",
    "        )\n",
    "        \n",
    "        assembler = VectorAssembler(\n",
    "            inputCols=[f\"{col}_VEC\" for col in self.categorical_features] + \n",
    "                      [f\"{col}_IMPUTED\" for col in self.numerical_features],\n",
    "            outputCol=\"features\",\n",
    "            handleInvalid=\"skip\"\n",
    "        )\n",
    "        \n",
    "        scaler = StandardScaler(\n",
    "            inputCol=\"features\",\n",
    "            outputCol=\"scaled_features\",\n",
    "            withMean=True,\n",
    "            withStd=True\n",
    "        )\n",
    "        \n",
    "        self.preprocessing_pipeline = Pipeline(\n",
    "            stages=[imputer, indexer, encoder, assembler, scaler]\n",
    "        )\n",
    "        \n",
    "        return self.preprocessing_pipeline\n",
    "    \n",
    "    def fit(self, df):\n",
    "        # Build and fit preprocessing pipeline\n",
    "        if self.preprocessing_pipeline is None:\n",
    "            self._build_preprocessing_pipeline()\n",
    "            # Ensure numerical columns are DoubleType before fitting the Imputer\n",
    "            temp_df = df\n",
    "            for col_name in self.numerical_features:\n",
    "                temp_df = temp_df.withColumn(col_name, F.col(col_name).cast(DoubleType()))\n",
    "                \n",
    "            self.preprocessing_pipeline = self.preprocessing_pipeline.fit(temp_df)\n",
    "        \n",
    "        # Transform training data\n",
    "        preprocessed = self.preprocessing_pipeline.transform(df)\n",
    "        \n",
    "        # Build and fit PyTorch Estimator\n",
    "        self.pytorch_estimator = SparkPyTorchEstimator(**self.mlp_params)\n",
    "        self.pytorch_estimator.fit(preprocessed)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        if self.preprocessing_pipeline is None or self.pytorch_estimator is None:\n",
    "            raise ValueError(\"Pipeline not fitted yet. Call fit() first.\")\n",
    "        \n",
    "        # Apply preprocessing\n",
    "        preprocessed = self.preprocessing_pipeline.transform(df)\n",
    "        \n",
    "        # Generate predictions\n",
    "        predictions_df = self.pytorch_estimator.transform(preprocessed)\n",
    "        \n",
    "        return predictions_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "615b20c1-3ac7-4f36-999f-90323372f2e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Run for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5e6c473-a4ed-4c31-bcbc-4bc032fec8ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# =====================================================\n",
    "# 4. USAGE WITH FLIGHTDELAYCV\n",
    "# =====================================================\n",
    "\n",
    "# Feature definitions\n",
    "categorical_features = [\n",
    "    'day_of_week', 'op_carrier', 'dep_time_blk', 'arr_time_blk', 'day_of_month', 'month'\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    'hourlyprecipitation', 'hourlysealevelpressure', 'hourlyaltimetersetting',\n",
    "    'hourlywetbulbtemperature', 'hourlystationpressure', 'hourlywinddirection',\n",
    "    'hourlyrelativehumidity', 'hourlywindspeed', 'hourlydewpointtemperature',\n",
    "    'hourlydrybulbtemperature', 'hourlyvisibility', 'crs_elapsed_time', 'distance', 'elevation',\n",
    "\n",
    "\n",
    "    #Flight Lineage Derived Features\n",
    "    # Scheduled time features (data leakage-free)\n",
    "    'scheduled_lineage_rotation_time_minutes',\n",
    "    'scheduled_lineage_turnover_time_minutes',\n",
    "\n",
    "    # Other known features (data leakage-free)\n",
    "    'prev_flight_distance',\n",
    "\n",
    "    # Safe features (intelligent data leakage handling)\n",
    "    'safe_lineage_rotation_time_minutes', # Duration between the known (or suspected) previous actual departure time and the planned departure time\n",
    "\n",
    "    # Other flight lineage features\n",
    "    'lineage_rank', # Number of recorded flights for that airplane\n",
    "]\n",
    "\n",
    "\n",
    "# PyTorch hyperparameters (updated for TorchDistributor)\n",
    "mlp_params = {\n",
    "    'hidden_layers': [512, 256, 128],\n",
    "    'dropout_rate': 0.1,\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 1024,\n",
    "    'epochs': 50,           # Increase epochs so early stopping has room to work\n",
    "    'patience': 10,          # <--- NEW: Stop if val loss doesn't improve for 5 epochs\n",
    "    # OPTIONAL: different batch size for inference to be extra safe\n",
    "    'infer_batch_size': 128,\n",
    "    # Optional: Set num_processes to override automatic GPU/CPU detection\n",
    "    # 'num_processes': 4\n",
    "}\n",
    "\n",
    "# Initialize MLP pipeline\n",
    "mlp_pipeline = MLPFlightDelayPipeline(\n",
    "    categorical_features=categorical_features,\n",
    "    numerical_features=numerical_features,\n",
    "    mlp_params=mlp_params,\n",
    ")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b1bf135-6f71-44b8-bdfa-73c258abe415",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3M "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edd8e232-b08d-4e49-86ea-86af9fabb4b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Your FlightDelayCV usage (assuming cv.FlightDelayCV is defined/imported elsewhere)\n",
    "crossvalidator = cv.FlightDelayCV(\n",
    "    estimator=mlp_pipeline,\n",
    "    version=\"3M\"\n",
    ")\n",
    "\n",
    "# Run cross-validation\n",
    "cv_results = crossvalidator.fit()\n",
    "print(\"Cross-Validation Results:\")\n",
    "print(cv_results)\n",
    "display(cv_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fa6e078-3747-4fc9-a974-0661de5ea02a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cv_eval = crossvalidator.evaluate()\n",
    "display(cv_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd701391-0d71-41c9-a5d8-f19bf30eca4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 12M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a51c1e70-6549-4899-937d-57f408e2cbbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Your FlightDelayCV usage (assuming cv.FlightDelayCV is defined/imported elsewhere)\n",
    "crossvalidator = cv.FlightDelayCV(\n",
    "    estimator=mlp_pipeline,\n",
    "    version=\"12M\"\n",
    ")\n",
    "\n",
    "# Run cross-validation\n",
    "cv_results_12M = crossvalidator.fit()\n",
    "print(\"Cross-Validation Results:\")\n",
    "print(cv_results_12M)\n",
    "display(cv_results_12M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "865cc763-d15e-400d-8e17-6561fe38bf70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cv_eval_12M = crossvalidator.evaluate()\n",
    "print(cv_eval_12M)\n",
    "display(cv_eval_12M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "949f4cbd-7d6b-4c34-b789-b4ab98e7718b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 60M "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1771ad2f-d65a-446b-bfe4-03fae219c2c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Your FlightDelayCV usage (assuming cv.FlightDelayCV is defined/imported elsewhere)\n",
    "crossvalidator = cv.FlightDelayCV(\n",
    "    estimator=mlp_pipeline,\n",
    "    version=\"60M\"\n",
    ")\n",
    "\n",
    "# Run cross-validation\n",
    "cv_results_60M = crossvalidator.fit()\n",
    "print(\"Cross-Validation Results:\")\n",
    "print(cv_results_60M)\n",
    "display(cv_results_60M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c705572-3aa1-4d56-ab8f-5449c2a6b65f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cv_eval_60M = crossvalidator.evaluate()\n",
    "print(cv_eval_60M)\n",
    "display(cv_eval_60M)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "(Dec8) MLP with PyTorch GPU with EarlyStopping",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
