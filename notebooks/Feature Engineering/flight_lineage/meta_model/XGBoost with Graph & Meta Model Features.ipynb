{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94bfc251-318b-4dcf-8fb9-f15db18b8680",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# XGBoost with Graph Features and Meta-Model\n",
    "\n",
    "**Based on top-performing XGBoost pipeline** with additions:\n",
    "- **Graph Features**: PageRank features (weighted and unweighted) for origin and destination airports\n",
    "- **Meta-Models**: Random Forest models predict previous flight components (air_time, taxi_time, total_duration)\n",
    "- **Log Transform**: Handle right-skewed target distribution\n",
    "- **Final Model**: XGBoost (fast, optimized, top leaderboard performer)\n",
    "\n",
    "**Pipeline Order:**\n",
    "1. Graph Features Estimator (builds graph, adds PageRank)\n",
    "2. Imputer (numerical features + graph features - graph features already filled to 0.0 but included for consistency)\n",
    "3. StringIndexer (categorical features)\n",
    "4. OneHotEncoder (categorical features)\n",
    "5. Meta-Model Estimator (uses preprocessed features to predict prev_flight components)\n",
    "6. VectorAssembler (combines processed features + meta-model predictions)\n",
    "7. Log Transform (`SIGN(DEP_DELAY) * LOG(ABS(DEP_DELAY) + 1.0)`)\n",
    "8. XGBoost Regressor\n",
    "9. Inverse Log Transform (convert back and floor to 0)\n",
    "\n",
    "**Delta from Base XGBoost Pipeline:**\n",
    "- ✅ Added: Meta-Model Estimator (predicts prev_flight_air_time, prev_flight_taxi_time, prev_flight_total_duration)\n",
    "- ✅ Added: Log transform (handles skewed target)\n",
    "- ✅ Added: Inverse log transform (converts predictions back)\n",
    "- ✅ Kept: Same optimized structure (graph → impute → index → encode → assemble → model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5dcd36b5-31c8-479b-823f-33622b0653b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d917eac-f8e8-43a3-8f92-a14f45606431",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# Load modules from our Databricks repo\n",
    "import importlib.util\n",
    "\n",
    "# CV module\n",
    "cv_path = \"/Workspace/Shared/Team 4_2/flight-departure-delay-predictive-modeling/notebooks/Cross Validator/cv.py\"\n",
    "spec = importlib.util.spec_from_file_location(\"cv\", cv_path)\n",
    "cv = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(cv)\n",
    "\n",
    "# Graph features\n",
    "graph_features_path = \"/Workspace/Shared/Team 4_2/flight-departure-delay-predictive-modeling/notebooks/Feature Engineering/graph_features.py\"\n",
    "spec = importlib.util.spec_from_file_location(\"graph_features\", graph_features_path)\n",
    "graph_features = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(graph_features)\n",
    "\n",
    "# Meta-model estimator\n",
    "meta_model_path = \"/Workspace/Shared/Team 4_2/flight-departure-delay-predictive-modeling/notebooks/Feature Engineering/meta_model_estimator.py\"\n",
    "spec = importlib.util.spec_from_file_location(\"meta_model_estimator\", meta_model_path)\n",
    "meta_model_estimator = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(meta_model_estimator)\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import Imputer, StringIndexer, OneHotEncoder, VectorAssembler, SQLTransformer\n",
    "from pyspark.ml import Pipeline\n",
    "from xgboost.spark import SparkXGBRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b452cd49-7fe2-4f78-a96b-82de75faf9fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Define Features\n",
    "\n",
    "**Categorical Features**: Includes `origin` and `dest` airports directly (XGBoost handles high cardinality well), plus carrier and temporal features\n",
    "\n",
    "**Numerical Features**: \n",
    "- Flight lineage features (rotation time, turnover time, etc.)\n",
    "- **Graph features** (PageRank scores - added by GraphFeaturesEstimator)\n",
    "- Meta-model predictions (predicted previous flight components - added by MetaModelEstimator)\n",
    "- Weather variables (current origin)\n",
    "- Flight characteristics (distance, scheduled times)\n",
    "- `prev_flight_distance` (from top-performing approach)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7d2293c-4eb5-4ce5-80b5-dc18918e8123",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Categorical features (XGBoost handles high cardinality well, so include origin/dest directly)\n",
    "# Based on top-performing XGBoost approach\n",
    "categorical_features = [\n",
    "    'op_carrier',              # Carrier\n",
    "    'origin',                  # Origin airport code (XGBoost handles ~200 categories well)\n",
    "    'origin_state_abr',        # Origin state\n",
    "    'dest',                    # Destination airport code (XGBoost handles ~200 categories well)\n",
    "    'dest_state_abr',          # Destination state\n",
    "    'day_of_week',             # Day of week\n",
    "    'month',                   # Month\n",
    "    'day_of_month',            # Day of month\n",
    "    'dep_time_blk',            # Departure time block\n",
    "    'arr_time_blk',            # Arrival time block\n",
    "]\n",
    "\n",
    "# Numerical features (graph features will be added by estimator)\n",
    "raw_numerical_features = [\n",
    "    # ============================================================================\n",
    "    # Flight Lineage Features (pre-applied in split.py)\n",
    "    # ============================================================================\n",
    "    'lineage_rank',\n",
    "    'safe_lineage_rotation_time_minutes',\n",
    "    'scheduled_lineage_rotation_time_minutes',\n",
    "    'scheduled_lineage_turnover_time_minutes',\n",
    "    'prev_flight_scheduled_flight_time_minutes',\n",
    "    'safe_required_time_prev_flight_minutes',\n",
    "    'prev_flight_distance',    # From top-performing XGBoost approach\n",
    "    \n",
    "    # ============================================================================\n",
    "    # Graph Features (added by GraphFeaturesEstimator)\n",
    "    # Note: These will be added dynamically, listed here for reference\n",
    "    # 'origin_pagerank_weighted',\n",
    "    # 'origin_pagerank_unweighted',\n",
    "    # 'dest_pagerank_weighted',\n",
    "    # 'dest_pagerank_unweighted',\n",
    "    \n",
    "    # ============================================================================\n",
    "    # Note: Meta-model predictions (predicted_prev_flight_*) are added by MetaModelEstimator\n",
    "    # and do NOT need imputation (they're already predicted values)\n",
    "    # They will be added to final_model_features after meta-models run\n",
    "    # ============================================================================\n",
    "    \n",
    "    # ============================================================================\n",
    "    # Weather Variables (Current Origin)\n",
    "    # ============================================================================\n",
    "    'hourlyprecipitation',\n",
    "    'hourlysealevelpressure',\n",
    "    'hourlyaltimetersetting',\n",
    "    'hourlywetbulbtemperature',\n",
    "    'hourlystationpressure',\n",
    "    'hourlywinddirection',\n",
    "    'hourlyrelativehumidity',\n",
    "    'hourlywindspeed',\n",
    "    'hourlydewpointtemperature',\n",
    "    'hourlydrybulbtemperature',\n",
    "    'hourlyvisibility',\n",
    "    \n",
    "    # ============================================================================\n",
    "    # Flight Characteristics\n",
    "    # ============================================================================\n",
    "    'crs_elapsed_time',        # Scheduled elapsed time\n",
    "    'distance',                # Flight distance\n",
    "    'elevation',               # Airport elevation (if available)\n",
    "]\n",
    "\n",
    "# Graph feature column names (for reference, added by GraphFeaturesEstimator)\n",
    "# Main model uses: origin_*, dest_*, and prev_flight_origin_* graph features\n",
    "# Meta models also need: prev_flight_dest_* (for jumps where prev_flight_dest != origin)\n",
    "graph_feature_cols = [\n",
    "    'origin_pagerank_weighted',\n",
    "    'origin_pagerank_unweighted',\n",
    "    'dest_pagerank_weighted',\n",
    "    'dest_pagerank_unweighted',\n",
    "    'prev_flight_origin_pagerank_weighted',\n",
    "    'prev_flight_origin_pagerank_unweighted',\n",
    "    'prev_flight_dest_pagerank_weighted',  # Needed by meta models (air_time, total_duration) for jumps\n",
    "    'prev_flight_dest_pagerank_unweighted'  # Note: Main model doesn't use this (redundant with origin_* for normal rotations)\n",
    "]\n",
    "\n",
    "numerical_features = raw_numerical_features\n",
    "\n",
    "print(f\"Using {len(categorical_features)} categorical features:\")\n",
    "for i, feat in enumerate(categorical_features, 1):\n",
    "    print(f\"  {i}. {feat}\")\n",
    "\n",
    "print(f\"\\nUsing {len(numerical_features)} base numerical features:\")\n",
    "for i, feat in enumerate(numerical_features, 1):\n",
    "    print(f\"  {i}. {feat}\")\n",
    "\n",
    "print(f\"\\nGraph features (added by estimator): {len(graph_feature_cols)} features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5bf659fd-ff36-4313-b35c-64c1376ef64a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Construct Model Pipeline\n",
    "\n",
    "**Following optimized pipeline structure** with meta-model additions:\n",
    "\n",
    "1. **Graph Features Estimator**: Builds graph, adds PageRank features (already fills NULLs to 0.0)\n",
    "2. **Imputer**: Imputes numerical features + graph features (graph already filled but included for consistency)\n",
    "3. **StringIndexer**: Indexes categorical features\n",
    "4. **OneHotEncoder**: Encodes categorical features\n",
    "5. **Meta-Model Estimator**: Predicts prev_flight components using preprocessed features\n",
    "6. **VectorAssembler**: Combines processed features + meta-model predictions\n",
    "7. **Log Transform**: Transforms DEP_DELAY to handle skew\n",
    "8. **XGBoost Regressor**: Final model\n",
    "9. **Inverse Log Transform**: Converts predictions back\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94377fb4-1550-4de0-9ad1-179e759aef7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Build Pipeline (Optimized Structure)\n",
    "# ============================================================================\n",
    "\n",
    "# Step 1: Graph Features Estimator\n",
    "# Increased max_iter to 30 for better PageRank convergence\n",
    "# GraphFrames PageRank doesn't support tolerance-based convergence, only maxIter\n",
    "# With ~200 airports, PageRank typically converges in 10-30 iterations\n",
    "# Runtime is fast (~10s for 3M with 10 iter), so 30 iter should still be <30s\n",
    "graph_estimator = graph_features.GraphFeaturesEstimator(\n",
    "    origin_col=\"origin\",\n",
    "    dest_col=\"dest\",\n",
    "    reset_probability=0.15,\n",
    "    max_iter=30\n",
    ")\n",
    "\n",
    "# Step 2: Imputer (numerical features + graph features)\n",
    "# Note: Graph features are already filled to 0.0 by GraphFeaturesEstimator,\n",
    "# but including them in Imputer for consistency\n",
    "imputer = Imputer(\n",
    "    inputCols=numerical_features + graph_feature_cols,\n",
    "    outputCols=[f\"{col}_IMPUTED\" for col in numerical_features + graph_feature_cols],\n",
    "    strategy=\"mean\"\n",
    ")\n",
    "\n",
    "# Step 3: StringIndexer (categorical features)\n",
    "indexer = StringIndexer(\n",
    "    inputCols=categorical_features,\n",
    "    outputCols=[f\"{col}_INDEX\" for col in categorical_features],\n",
    "    handleInvalid=\"keep\"\n",
    ")\n",
    "\n",
    "# Step 4: OneHotEncoder (categorical features)\n",
    "encoder = OneHotEncoder(\n",
    "    inputCols=[f\"{col}_INDEX\" for col in categorical_features],\n",
    "    outputCols=[f\"{col}_VEC\" for col in categorical_features]\n",
    ")\n",
    "\n",
    "# Step 5: Meta-Model Estimator (uses preprocessed features)\n",
    "# Note: Meta-models need prev_flight features which will be processed by indexer/encoder above\n",
    "# The meta-model estimator will automatically find and use the preprocessed versions\n",
    "meta_model_est = meta_model_estimator.MetaModelEstimator(\n",
    "    num_trees=50,\n",
    "    max_depth=20,\n",
    "    min_instances_per_node=20,\n",
    "    use_preprocessed_features=True\n",
    ")\n",
    "\n",
    "# Step 6: VectorAssembler (processed current flight features + meta-model predictions)\n",
    "# Final model uses: current flight processed features + 3 meta-model predictions\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[f\"{col}_VEC\" for col in categorical_features] + \n",
    "              [f\"{col}_IMPUTED\" for col in numerical_features + graph_feature_cols] +\n",
    "              ['predicted_prev_flight_air_time', 'predicted_prev_flight_taxi_time', 'predicted_prev_flight_total_duration'],\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\"\n",
    ")\n",
    "\n",
    "# Step 7: Log Transform\n",
    "log_transform = SQLTransformer(\n",
    "    statement=\"\"\"\n",
    "    SELECT *, \n",
    "           SIGN(DEP_DELAY) * LOG(ABS(DEP_DELAY) + 1.0) AS DEP_DELAY_log\n",
    "    FROM __THIS__\n",
    "    WHERE DEP_DELAY IS NOT NULL\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Step 8: XGBoost Regressor (default - NO log transform)\n",
    "xgb = SparkXGBRegressor(\n",
    "    num_workers=sc.defaultParallelism,\n",
    "    label_col=\"DEP_DELAY\",  # Direct target, no log transform\n",
    "    features_col=\"features\",\n",
    "    prediction_col=\"prediction\",  # Direct prediction, no log space\n",
    "    missing=0.0\n",
    ")\n",
    "\n",
    "# Step 8b: XGBoost Regressor (WITH log transform - for comparison)\n",
    "xgb_with_log = SparkXGBRegressor(\n",
    "    num_workers=sc.defaultParallelism,\n",
    "    label_col=\"DEP_DELAY_log\",\n",
    "    features_col=\"features\",\n",
    "    prediction_col=\"prediction_log\",\n",
    "    missing=0.0\n",
    ")\n",
    "\n",
    "# Step 9: Inverse Log Transform\n",
    "exp_transform = SQLTransformer(\n",
    "    statement=\"\"\"\n",
    "    SELECT *, \n",
    "           GREATEST(\n",
    "               CASE \n",
    "                   WHEN prediction_log IS NOT NULL THEN \n",
    "                       SIGN(prediction_log) * (EXP(ABS(prediction_log)) - 1.0)\n",
    "                   ELSE 0.0\n",
    "               END,\n",
    "               0.0\n",
    "           ) AS prediction\n",
    "    FROM __THIS__\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Build pipeline WITHOUT log transform (default)\n",
    "xgb_pipe = Pipeline(stages=[\n",
    "    graph_estimator,    # Step 1: Add graph features\n",
    "    imputer,            # Step 2: Impute numerical + graph features\n",
    "    indexer,            # Step 3: Index categorical features\n",
    "    encoder,            # Step 4: Encode categorical features\n",
    "    meta_model_est,     # Step 5: Meta-models (use preprocessed features)\n",
    "    assembler,          # Step 6: Assemble final features\n",
    "    # No log_transform - train directly on DEP_DELAY\n",
    "    xgb                 # Step 8: XGBoost model (trained on raw target)\n",
    "    # No exp_transform - predictions are already in original scale\n",
    "])\n",
    "\n",
    "# Build pipeline WITH log transform (for comparison)\n",
    "xgb_pipe_with_log = Pipeline(stages=[\n",
    "    graph_estimator,    # Step 1: Add graph features\n",
    "    imputer,            # Step 2: Impute numerical + graph features\n",
    "    indexer,            # Step 3: Index categorical features\n",
    "    encoder,            # Step 4: Encode categorical features\n",
    "    meta_model_est,     # Step 5: Meta-models (use preprocessed features)\n",
    "    assembler,          # Step 6: Assemble final features\n",
    "    log_transform,      # Step 7: Log transform target\n",
    "    xgb_with_log,       # Step 8: XGBoost model (trained on log-transformed target)\n",
    "    exp_transform       # Step 9: Inverse log transform (creates \"prediction\" column)\n",
    "])\n",
    "\n",
    "print(\"✓ Two pipelines built for comparison:\")\n",
    "print(f\"  - xgb_pipe: No log transform (direct prediction)\")\n",
    "print(f\"  - xgb_pipe_with_log: Uses log transform (handles skewed distribution)\")\n",
    "print(f\"\\n  Common features:\")\n",
    "print(f\"  - {len(categorical_features)} categorical features\")\n",
    "print(f\"  - {len(numerical_features)} numerical features\")\n",
    "print(f\"  - {len(graph_feature_cols)} graph features\")\n",
    "print(f\"  - 3 meta-model predictions\")\n",
    "print(f\"\\n  Usage: Train both and compare performance!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70cedf63-3de1-4398-889b-f785169d78a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Run Cross-Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43ca8643-7558-4cf5-a06d-381c753d2acf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # 3M Data\n",
    "# cv_xgb_3M = cv.FlightDelayCV(\n",
    "#     estimator=xgb_pipe,\n",
    "#     version=\"3M\"\n",
    "# )\n",
    "# cv_xgb_3M.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "73f3c316-d9cd-4018-90ec-b0406fb61601",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# cv_xgb_3M.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5419772-39c0-421c-836e-a6589b8ca888",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 12M Data\n",
    "cv_xgb_12M = cv.FlightDelayCV(\n",
    "    estimator=xgb_pipe,\n",
    "    version=\"12M\"\n",
    ")\n",
    "cv_xgb_12M.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15bda775-1758-4683-aa26-97eabf784b85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "cv_xgb_12M.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3907692d-c88a-44d3-9f11-82bbef39e884",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 60M Data\n",
    "cv_xgb_60M = cv.FlightDelayCV(\n",
    "    estimator=xgb_pipe,\n",
    "    version=\"60M\"\n",
    ")\n",
    "cv_xgb_60M.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36998cac-f62e-4001-a6a0-838a31805dc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "cv_xgb_60M.evaluate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a078cf4-ed0b-4e6a-b1e1-73a2210af2c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Benchmarking Training Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0808665-944a-4202-b9d1-b287e979dad5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "benchmark_12M = cv_xgb_12M.benchmark_inference(dataset=\"fold_3_val\")\n",
    "benchmark_12M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be115bd9-205c-4f63-b386-8a1338a2ba94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "benchmark_60M = cv_xgb_60M.benchmark_inference(dataset=\"fold_3_val\")\n",
    "benchmark_60M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "619ae46e-0a9f-4736-9a17-11bd164a5a4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Detailed Evaluation (Optional)\n",
    "\n",
    "Run these cells after the main training is complete for detailed analysis (feature importance, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90f196ca-c970-4813-b893-8a0f87bfb877",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a57ade6a-99a2-4313-8c01-17598ee2562b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example: Detailed evaluation for 12M (modify for 3M or 60M as needed)\n",
    "cv_obj = cv_xgb_12M  # Change to cv_xgb_3M or cv_xgb_60M as needed\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURE IMPORTANCE (by fold)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get feature names (for reference)\n",
    "feature_names = [f\"{col}_VEC\" for col in categorical_features] + \\\n",
    "                [f\"{col}_IMPUTED\" for col in numerical_features + graph_feature_cols] + \\\n",
    "                ['predicted_prev_flight_air_time', 'predicted_prev_flight_taxi_time', 'predicted_prev_flight_total_duration']\n",
    "\n",
    "for i, model in enumerate(cv_obj.models):\n",
    "    print(f\"\\n--- Fold {i+1} ---\")\n",
    "    # XGBoost is second-to-last (exp_transform is last)\n",
    "    xgb_model = model.stages[-2]\n",
    "    \n",
    "    # Get feature importance from XGBoost\n",
    "    try:\n",
    "        feature_importance = xgb_model.getFeatureImportances()\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            feature_importance = xgb_model._xgb_skl_model.feature_importances_\n",
    "        except:\n",
    "            print(\"    ⚠ Warning: Could not extract feature importance for this fold\")\n",
    "            continue\n",
    "    \n",
    "    # Sort by importance\n",
    "    importance_pairs = list(zip(feature_names, feature_importance))\n",
    "    importance_pairs.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"Top 20 Features:\")\n",
    "    for name, importance in importance_pairs[:20]:\n",
    "        print(f\"  {name:50s}: {importance:10.6f}\")\n",
    "\n",
    "# Test set feature importance\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEST MODEL FEATURE IMPORTANCE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_xgb_model = cv_obj.test_model.stages[-2]\n",
    "try:\n",
    "    feature_importance = test_xgb_model.getFeatureImportances()\n",
    "except AttributeError:\n",
    "    try:\n",
    "        feature_importance = test_xgb_model._xgb_skl_model.feature_importances_\n",
    "    except:\n",
    "        print(\"    ⚠ Warning: Could not extract feature importance\")\n",
    "        feature_importance = []\n",
    "\n",
    "importance_pairs = list(zip(feature_names, feature_importance))\n",
    "importance_pairs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nTop 20 Features (Test Model):\")\n",
    "for name, importance in importance_pairs[:20]:\n",
    "    print(f\"  {name:50s}: {importance:10.6f}\")\n",
    "\n",
    "# Test set metrics summary\n",
    "test_results = cv_obj.evaluate()\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Test Model Summary:\")\n",
    "print(f\"  RMSE: {test_results.get('rmse', 'N/A'):.4f}\")\n",
    "print(f\"  MAE: {test_results.get('mae', 'N/A'):.4f}\")\n",
    "print(f\"  R²: {test_results.get('r2', 'N/A'):.4f}\")\n",
    "print(f\"  OTPA: {test_results.get('otpa', 'N/A'):.4f}\")\n",
    "print(f\"  SDDR: {test_results.get('sddr', 'N/A'):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "XGBoost with Graph & Meta Model Features",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
