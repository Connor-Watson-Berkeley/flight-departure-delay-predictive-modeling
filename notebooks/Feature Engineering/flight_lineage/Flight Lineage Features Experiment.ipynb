{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e8d3d1d-29b3-4471-a6a1-36affb9d7412",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Flight Sequence Feature Engineering\n",
    "\n",
    "This notebook engineers features based on the **Flight Sequence** - tracking how delays compound as planes travel through multiple flights in a day.\n",
    "\n",
    "## Graph/Network Representation\n",
    "\n",
    "### Formal Structure:\n",
    "- **Nodes**: Individual flights (each flight is a node with attributes: origin, dest, scheduled/actual times, delays, etc.)\n",
    "- **Edges**: Connect consecutive flights in a **Flight Sequence** (same aircraft/tail_num, same day)\n",
    "  - Edge represents the relationship: \"previous flight → current flight\"\n",
    "  - **Edge Weight**: Air time (actual or expected) of the previous flight\n",
    "- **Flight Sequence**: The ordered sequence of flights an aircraft operates in a day (e.g., A → B → C)\n",
    "\n",
    "### Node Attributes:\n",
    "- `origin`: Origin airport\n",
    "- `dest`: Destination airport  \n",
    "- `scheduled_dep_time`: Scheduled departure time\n",
    "- `scheduled_arr_time`: Scheduled arrival time\n",
    "- `actual_dep_time`: Actual departure time (if available)\n",
    "- `actual_arr_time`: Actual arrival time (if available)\n",
    "- `dep_delay`: Departure delay\n",
    "- `arr_delay`: Arrival delay\n",
    "\n",
    "### Edge Attributes:\n",
    "- `air_time`: Actual or expected flight time (edge weight)\n",
    "- `turn_time`: Time between arrival at destination and next departure\n",
    "\n",
    "## Deterministic Prediction Formula\n",
    "\n",
    "For a **Flight Sequence A → B** where B has not been realized yet:\n",
    "\n",
    "**Expected Departure Time of B** = \n",
    "- **Actual Departure Time of A** (if available >= 2 hours before B's scheduled departure)\n",
    "- **+ Expected Air Time** (conditional on weather, aircraft type, route)\n",
    "- **+ Expected Turn Time at B** (conditional on carrier, airport, time of day)\n",
    "\n",
    "**Impossible On-Time Flag** = 1 if Expected Departure Time of B > Scheduled Departure Time of B, else 0\n",
    "\n",
    "## Key Concepts:\n",
    "\n",
    "1. **Flight Sequence**: Ordered sequence of flights by same aircraft in a day (A → B → C)\n",
    "2. **Previous Flight/Leg**: The flight immediately before the current one in the sequence\n",
    "3. **Cumulative Delay**: Total delay accumulated since first flight of the day (typically since 3 AM)\n",
    "4. **Conditional Dependencies**:\n",
    "   - **Turn Time**: Varies by carrier, airport, time of day, aircraft type\n",
    "   - **Air Time**: Varies by weather (wind speed/direction), aircraft type, route\n",
    "   - **Taxi Time**: Varies by airport, runway configuration, gate position, time of day\n",
    "5. **Data Leakage Prevention**: Only use actual departure times that are >= 2 hours before the current flight's scheduled departure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c782d4ac-31ba-4338-99b5-f0b81e81d88e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Load cv module\n",
    "cv_path = \"/Workspace/Shared/Team 4_2/flight-departure-delay-predictive-modeling/notebooks/Cross Validator/cv.py\"\n",
    "spec = importlib.util.spec_from_file_location(\"cv\", cv_path)\n",
    "cv = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(cv)\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, to_timestamp, when, lag, sum as spark_sum, count, avg, min as spark_min, max as spark_max\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Path for persistent storage\n",
    "FOLDER_PATH = \"dbfs:/mnt/mids-w261/student-groups/Group_4_2/experiments\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a627a5ff-e269-4ab3-9fdd-ec6436264d09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load Data\n",
    "\n",
    "### Column Names (Verified from Dataset)\n",
    "\n",
    "Based on actual data exploration, the following columns are available for Flight Sequence feature engineering:\n",
    "\n",
    "**Flight Identification:**\n",
    "- `tail_num`: Tail number (aircraft identifier) - **used to track Flight Sequences**\n",
    "- `FL_DATE`: Flight date (uppercase, date format)\n",
    "- `op_carrier`: Operating carrier code\n",
    "- `op_carrier_fl_num`: Flight number\n",
    "- `origin`: Origin airport code\n",
    "- `dest`: Destination airport code\n",
    "\n",
    "**Scheduled Times:**\n",
    "- `crs_dep_time`: Scheduled departure time (integer HHMM format, e.g., 1158 = 11:58)\n",
    "- `crs_arr_time`: Scheduled arrival time (integer HHMM format)\n",
    "- `crs_elapsed_time`: Scheduled elapsed time (minutes)\n",
    "- `sched_depart_date_time`: Scheduled departure datetime (if created from `FL_DATE` + `crs_dep_time`)\n",
    "\n",
    "**Actual Times:**\n",
    "- `dep_time`: Actual departure time (integer HHMM format, may be NULL, e.g., 1151 = 11:51)\n",
    "- `arr_time`: Actual arrival time (integer HHMM format, may be NULL)\n",
    "- `actual_elapsed_time`: Actual elapsed time (minutes)\n",
    "- `wheels_off`: Wheels off time (if available)\n",
    "- `wheels_on`: Wheels on time (if available)\n",
    "\n",
    "**Time Components (verify availability):**\n",
    "- `air_time`: Air time (minutes) - flight time in the air\n",
    "- `taxi_out`: Taxi-out time (minutes) - from gate to wheels off\n",
    "- `taxi_in`: Taxi-in time (minutes) - from wheels on to gate\n",
    "\n",
    "**Delays:**\n",
    "- `DEP_DELAY`: Departure delay (minutes, uppercase - likely the label column)\n",
    "- `dep_delay_new`: Alternative departure delay calculation\n",
    "- `ARR_DELAY`: Arrival delay (minutes, uppercase)\n",
    "- `arr_delay`: Arrival delay (minutes, lowercase)\n",
    "- `arr_delay_new`: Alternative arrival delay calculation\n",
    "\n",
    "**Other:**\n",
    "- `distance`: Flight distance (miles, if available)\n",
    "- `cancelled`: Cancellation indicator (if available)\n",
    "- `diverted`: Diversion indicator (if available)\n",
    "\n",
    "**Note:** Column names are a mix of uppercase and lowercase. Use exact case when referencing columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "436cfca0-23c6-4b33-ad58-ac215ed916cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load data for lineage feature engineering\n",
    "# We need tail_num to track planes, and scheduled/actual times\n",
    "lineage_data_path = f\"{FOLDER_PATH}/lineage_data_snapshot.parquet\"\n",
    "\n",
    "print(\"Loading data for lineage feature engineering...\")\n",
    "start = time.time()\n",
    "data_loader = cv.FlightDelayDataLoader()\n",
    "data_loader.load()\n",
    "folds = data_loader.get_version(\"3M\")  # Start with 3M for faster iteration\n",
    "\n",
    "# Use first fold for now\n",
    "train_df, val_df = folds[0]\n",
    "lineage_data = train_df\n",
    "\n",
    "# Check partition count and repartition if needed\n",
    "num_partitions = lineage_data.rdd.getNumPartitions()\n",
    "if num_partitions > 500:\n",
    "    lineage_data = lineage_data.coalesce(200)\n",
    "elif num_partitions < 10:\n",
    "    lineage_data = lineage_data.repartition(50)\n",
    "\n",
    "# Save snapshot\n",
    "lineage_data.write.mode(\"overwrite\").parquet(lineage_data_path)\n",
    "print(f\"Saved snapshot in {time.time() - start:.2f} seconds\")\n",
    "\n",
    "print(f\"\\nLineage data: {lineage_data.count():,} flights\")\n",
    "print(f\"Date range: {lineage_data.agg(F.min('FL_DATE'), F.max('FL_DATE')).collect()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1dabb6dc-bdfb-405f-89fc-04274afd1f0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load from saved snapshot (run this on subsequent runs)\n",
    "lineage_data_path = f\"{FOLDER_PATH}/lineage_data_snapshot.parquet\"\n",
    "\n",
    "print(f\"Loading lineage data from {lineage_data_path}...\")\n",
    "start = time.time()\n",
    "lineage_data = spark.read.parquet(lineage_data_path)\n",
    "lineage_data.count()  # Materialize\n",
    "print(f\"Loaded in {time.time() - start:.2f} seconds\")\n",
    "\n",
    "print(f\"\\nLineage data: {lineage_data.count():,} flights\")\n",
    "print(f\"Date range: {lineage_data.agg(F.min('FL_DATE'), F.max('FL_DATE')).collect()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2bb2bdc9-7e83-4d7b-a660-3ce54c4c19b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Prepare Data for Lineage Analysis\n",
    "\n",
    "We need:\n",
    "- `tail_num`: To track the same plane across flights\n",
    "- `FL_DATE`: To group flights by day\n",
    "- Scheduled and actual departure/arrival times\n",
    "- Flight duration information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "118a06fe-0fea-42d1-a6ae-d73625cad049",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check what columns are available\n",
    "print(\"Checking available columns for lineage analysis...\")\n",
    "print(f\"Total columns: {len(lineage_data.columns)}\")\n",
    "\n",
    "# Look for tail number and time columns\n",
    "tail_cols = [c for c in lineage_data.columns if 'tail' in c.lower()]\n",
    "time_cols = [c for c in lineage_data.columns if any(term in c.lower() for term in ['time', 'dep', 'arr', 'crs', 'sched'])]\n",
    "\n",
    "print(f\"\\nTail number columns: {tail_cols}\")\n",
    "print(f\"\\nTime-related columns (first 20): {time_cols[:20]}\")\n",
    "\n",
    "# Check for specific time component columns needed for feature engineering\n",
    "time_component_cols = ['air_time', 'taxi_in', 'taxi_out', 'wheels_off', 'wheels_on']\n",
    "available_time_components = [c for c in time_component_cols if c in lineage_data.columns]\n",
    "missing_time_components = [c for c in time_component_cols if c not in lineage_data.columns]\n",
    "\n",
    "print(f\"\\nTime component columns:\")\n",
    "print(f\"  Available: {available_time_components}\")\n",
    "if missing_time_components:\n",
    "    print(f\"  Missing: {missing_time_components}\")\n",
    "\n",
    "# Sample data to see structure\n",
    "print(\"\\nSample row:\")\n",
    "display_cols = tail_cols + ['FL_DATE', 'origin', 'dest', 'crs_dep_time', 'dep_time', \n",
    "                            'crs_arr_time', 'arr_time', 'DEP_DELAY', 'ARR_DELAY']\n",
    "# Add available time components\n",
    "display_cols.extend(available_time_components)\n",
    "# Filter to only columns that exist\n",
    "display_cols = [c for c in display_cols if c in lineage_data.columns]\n",
    "lineage_data.select(display_cols).limit(5).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd59aae7-55c4-4bb1-a172-c1c88a21f87a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Feature Engineering: Flight Sequence Features\n",
    "\n",
    "### Features to Create:\n",
    "\n",
    "#### 1. Previous Flight/Leg Information\n",
    "- `prev_flight_arr_delay`: Previous flight arrival delay\n",
    "- `prev_flight_dep_delay`: Previous flight departure delay\n",
    "- `prev_flight_actual_dep_time`: Previous flight actual departure time (if >= 2 hours before current scheduled departure)\n",
    "- `prev_flight_actual_arr_time`: Previous flight actual arrival time (if available)\n",
    "- `prev_flight_origin`: Origin airport of previous flight\n",
    "- `prev_flight_dest`: Destination airport of previous flight (should match current origin)\n",
    "\n",
    "#### 2. Cumulative Delay Features\n",
    "- `cumulative_delay_since_3am`: Total delay accumulated by the plane's previous flights in the day\n",
    "- `num_previous_flights_today`: Number of flights the plane has already completed today\n",
    "- `avg_delay_per_previous_flight`: Mean delay across previous flights\n",
    "- `max_delay_previous_flights`: Maximum delay in previous flights\n",
    "\n",
    "#### 3. Conditional Turn Time Features\n",
    "- `expected_turn_time_carrier_airport`: Average time between arrival and departure for this carrier at this airport\n",
    "- `expected_turn_time_carrier_airport_time`: Conditional on time of day (morning/afternoon/evening)\n",
    "- `expected_turn_time_carrier_airport_aircraft`: Conditional on aircraft type\n",
    "- `actual_turn_time`: Actual time between previous flight arrival and current scheduled departure (if previous flight has arrived)\n",
    "\n",
    "#### 4. Conditional Air Time Features (Edge Weights)\n",
    "- `expected_air_time_route`: Average air time for this origin-destination pair\n",
    "- `expected_air_time_route_weather`: Conditional on wind speed, wind direction, weather conditions\n",
    "- `expected_air_time_route_aircraft`: Conditional on aircraft type\n",
    "- `expected_air_time_route_time_of_day`: Conditional on time of day (affects air traffic, congestion)\n",
    "- `expected_air_time_route_time_of_year`: Conditional on time of year (affects seasonal wind patterns, jet streams)\n",
    "- `expected_air_time_route_weather_time`: Conditional on weather AND time of day/year (combined effects)\n",
    "- `prev_flight_actual_air_time`: Actual air time of previous flight (if completed)\n",
    "\n",
    "#### 5. Deterministic \"Impossible On-Time\" Features\n",
    "- `expected_arrival_time_prev_flight`: Previous actual departure (or scheduled if not available) + expected air time\n",
    "- `expected_departure_time_current`: Expected arrival time of previous flight + expected turn time at current airport\n",
    "- `time_buffer`: Scheduled departure time - Expected departure time (can be negative)\n",
    "- `impossible_on_time_flag`: Binary (1 if Expected departure time > Scheduled departure time, else 0)\n",
    "- `minutes_until_departure`: Minutes between expected arrival and scheduled departure (can be negative)\n",
    "\n",
    "#### 6. Taxi Time Features\n",
    "- `expected_taxi_in_time_airport`: Average taxi time from landing to gate at destination airport\n",
    "- `expected_taxi_out_time_airport`: Average taxi time from gate to takeoff at origin airport\n",
    "- `expected_taxi_time_airport_time`: Conditional on time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "678a376b-0b9a-4456-9ad7-aad24f370a55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation: Pre-Compute Lineage Features\n",
    "\n",
    "### Step 1: Create Unique Flight Key\n",
    "\n",
    "We need a unique identifier to join lineage features back to the main dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique flight key for joining lineage features back to main dataset\n",
    "# This key uniquely identifies each flight and can be used for efficient joins\n",
    "\n",
    "def create_flight_key(df, tail_col='tail_num'):\n",
    "    \"\"\"\n",
    "    Create a unique flight identifier.\n",
    "    \n",
    "    Options:\n",
    "    1. Composite key: {tail_num}_{FL_DATE}_{crs_dep_time}_{op_carrier_fl_num}_{origin}_{dest}\n",
    "       - Readable, debuggable\n",
    "       - Includes flight number for uniqueness\n",
    "       - Longer strings, but Spark handles this well\n",
    "    \n",
    "    2. Hash key: SHA2 hash of composite fields\n",
    "       - Shorter, more efficient\n",
    "       - Not human-readable\n",
    "    \n",
    "    Recommendation: Use composite key with flight number for uniqueness and debuggability.\n",
    "    \"\"\"\n",
    "    # Composite key approach (recommended)\n",
    "    # Include op_carrier_fl_num for uniqueness (same tail_num can have multiple flights at same time)\n",
    "    if 'op_carrier_fl_num' in df.columns:\n",
    "        flight_key = (\n",
    "            df\n",
    "            .withColumn(\n",
    "                'flight_key',\n",
    "                F.concat(\n",
    "                    col(tail_col), F.lit('_'),\n",
    "                    col('FL_DATE'), F.lit('_'),\n",
    "                    col('crs_dep_time').cast('string'), F.lit('_'),\n",
    "                    col('op_carrier_fl_num').cast('string'), F.lit('_'),\n",
    "                    col('origin'), F.lit('_'),\n",
    "                    col('dest')\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        # Fallback if flight number not available\n",
    "        flight_key = (\n",
    "            df\n",
    "            .withColumn(\n",
    "                'flight_key',\n",
    "                F.concat(\n",
    "                    col(tail_col), F.lit('_'),\n",
    "                    col('FL_DATE'), F.lit('_'),\n",
    "                    col('crs_dep_time').cast('string'), F.lit('_'),\n",
    "                    col('origin'), F.lit('_'),\n",
    "                    col('dest')\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Alternative: Hash-based key (uncomment if needed)\n",
    "    # if 'op_carrier_fl_num' in df.columns:\n",
    "    #     flight_key = (\n",
    "    #         df\n",
    "    #         .withColumn(\n",
    "    #             'flight_key',\n",
    "    #             F.sha2(\n",
    "    #                 F.concat(\n",
    "    #                     col(tail_col), col('FL_DATE'),\n",
    "    #                     col('crs_dep_time').cast('string'),\n",
    "    #                     col('op_carrier_fl_num').cast('string'),\n",
    "    #                     col('origin'), col('dest')\n",
    "    #                 ),\n",
    "    #                 256\n",
    "    #             )\n",
    "    #         )\n",
    "    #     )\n",
    "    # else:\n",
    "    #     flight_key = (\n",
    "    #         df\n",
    "    #         .withColumn(\n",
    "    #             'flight_key',\n",
    "    #             F.sha2(\n",
    "    #                 F.concat(\n",
    "    #                     col(tail_col), col('FL_DATE'),\n",
    "    #                     col('crs_dep_time').cast('string'),\n",
    "    #                     col('origin'), col('dest')\n",
    "    #                 ),\n",
    "    #                 256\n",
    "    #             )\n",
    "    #         )\n",
    "    #     )\n",
    "    \n",
    "    return flight_key\n",
    "\n",
    "# Test on sample data\n",
    "if 'lineage_data' in locals():\n",
    "    print(\"Creating flight keys for lineage data...\")\n",
    "    tail_cols = [c for c in lineage_data.columns if 'tail' in c.lower()]\n",
    "    if tail_cols:\n",
    "        tail_col = tail_cols[0]\n",
    "        lineage_with_keys = create_flight_key(lineage_data, tail_col)\n",
    "        \n",
    "        print(f\"\\nSample flight keys:\")\n",
    "        display(lineage_with_keys.select('flight_key', tail_col, 'FL_DATE', 'crs_dep_time', \n",
    "                                         'origin', 'dest').limit(10))\n",
    "        \n",
    "        # Check for uniqueness\n",
    "        total_flights = lineage_with_keys.count()\n",
    "        unique_keys = lineage_with_keys.select('flight_key').distinct().count()\n",
    "        print(f\"\\nUniqueness check:\")\n",
    "        print(f\"  Total flights: {total_flights:,}\")\n",
    "        print(f\"  Unique flight keys: {unique_keys:,}\")\n",
    "        if total_flights == unique_keys:\n",
    "            print(\"  ✓ All flight keys are unique!\")\n",
    "        else:\n",
    "            print(f\"  ⚠ Warning: {total_flights - unique_keys} duplicate keys found\")\n",
    "            print(\"    May need to add more fields to flight_key (e.g., op_carrier_fl_num)\")\n",
    "    else:\n",
    "        print(\"tail_num column not found.\")\n",
    "else:\n",
    "    print(\"lineage_data not available. Load data first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Compute All Lineage Features (One-Time Computation)\n",
    "\n",
    "This is the expensive operation - compute ONCE, save as materialized table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute all lineage features using window functions\n",
    "# This should be run ONCE after the custom join, then saved as a materialized table\n",
    "\n",
    "if 'lineage_data' in locals():\n",
    "    print(\"Computing lineage features (one-time computation)...\")\n",
    "    print(\"This may take a while - will save as materialized table for future use.\\n\")\n",
    "    \n",
    "    tail_cols = [c for c in lineage_data.columns if 'tail' in c.lower()]\n",
    "    if tail_cols:\n",
    "        tail_col = tail_cols[0]\n",
    "        \n",
    "        # Create flight key first\n",
    "        df = create_flight_key(lineage_data, tail_col)\n",
    "        \n",
    "        # Filter to flights with required columns\n",
    "        df = df.filter(\n",
    "            col(tail_col).isNotNull() & \n",
    "            col('FL_DATE').isNotNull() &\n",
    "            col('origin').isNotNull() & \n",
    "            col('dest').isNotNull() &\n",
    "            col('crs_dep_time').isNotNull()\n",
    "        )\n",
    "        \n",
    "        # Window specification: partition by tail_num and date, order by scheduled departure time\n",
    "        window_spec = Window.partitionBy(tail_col, 'FL_DATE').orderBy('crs_dep_time')\n",
    "        \n",
    "        print(\"Pass 1: Sequence numbers and previous flight raw values...\")\n",
    "        # Sequence number\n",
    "        df = df.withColumn('seq_num', F.row_number().over(window_spec))\n",
    "        \n",
    "        # Previous flight raw values\n",
    "        df = df.withColumn('prev_flight_dest', F.lag('dest', 1).over(window_spec))\n",
    "        df = df.withColumn('prev_flight_origin', F.lag('origin', 1).over(window_spec))\n",
    "        df = df.withColumn('prev_flight_actual_dep_time', F.lag('dep_time', 1).over(window_spec))\n",
    "        df = df.withColumn('prev_flight_actual_arr_time', F.lag('arr_time', 1).over(window_spec))\n",
    "        df = df.withColumn('prev_flight_dep_delay', F.lag('DEP_DELAY', 1).over(window_spec))\n",
    "        df = df.withColumn('prev_flight_arr_delay', F.lag('ARR_DELAY', 1).over(window_spec))\n",
    "        df = df.withColumn('prev_flight_air_time', F.lag('air_time', 1).over(window_spec))\n",
    "        \n",
    "        print(\"Pass 2: Jump detection and cumulative features...\")\n",
    "        # Jump detection\n",
    "        df = df.withColumn(\n",
    "            'is_jump',\n",
    "            when(col('seq_num') == 1, F.lit(False))\n",
    "            .when(col('prev_flight_dest').isNull(), F.lit(True))\n",
    "            .otherwise(col('prev_flight_dest') != col('origin'))\n",
    "        )\n",
    "        \n",
    "        # Cumulative delay features\n",
    "        df = df.withColumn(\n",
    "            'cumulative_delay_since_3am',\n",
    "            F.sum('DEP_DELAY').over(\n",
    "                window_spec.rowsBetween(Window.unboundedPreceding, -1)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        df = df.withColumn(\n",
    "            'num_previous_flights_today',\n",
    "            F.count('*').over(\n",
    "                window_spec.rowsBetween(Window.unboundedPreceding, -1)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        df = df.withColumn(\n",
    "            'avg_delay_per_previous_flight',\n",
    "            F.avg('DEP_DELAY').over(\n",
    "                window_spec.rowsBetween(Window.unboundedPreceding, -1)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        df = df.withColumn(\n",
    "            'max_delay_previous_flights',\n",
    "            F.max('DEP_DELAY').over(\n",
    "                window_spec.rowsBetween(Window.unboundedPreceding, -1)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        print(\"Pass 3: Join with conditional expected values...\")\n",
    "        print(\"  IMPORTANT: For previous flight's route, join on (prev_flight_origin, prev_flight_dest)\")\n",
    "        print(\"             For current flight's airport, join on (op_carrier, origin)\\n\")\n",
    "        \n",
    "        # Load conditional expected value tables (from Time-Series Features Experiment)\n",
    "        # These should be pre-computed and saved as parquet files\n",
    "        \n",
    "        # Join expected air time for PREVIOUS flight's route\n",
    "        # CRITICAL: Join on prev_flight_origin → prev_flight_dest, not origin → dest!\n",
    "        expected_air_time_route_path = f\"{FOLDER_PATH}/expected_values_route.parquet\"\n",
    "        try:\n",
    "            expected_air_time_route = spark.read.parquet(expected_air_time_route_path)\n",
    "            \n",
    "            # Join on previous flight's route\n",
    "            df = df.join(\n",
    "                expected_air_time_route.alias('prev_route'),\n",
    "                (col('prev_flight_origin') == col('prev_route.origin')) &\n",
    "                (col('prev_flight_dest') == col('prev_route.dest')),\n",
    "                'left'\n",
    "            ).select(\n",
    "                [col(c) for c in df.columns] +  # Keep all original columns\n",
    "                [col('prev_route.expected_air_time_route').alias('prev_expected_air_time_route')]\n",
    "            )\n",
    "            print(\"  ✓ Joined expected_air_time_route for previous flight's route\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠ Could not load expected_air_time_route: {e}\")\n",
    "            print(\"    Run Time-Series Features Experiment to generate this table\")\n",
    "            # Add placeholder column\n",
    "            df = df.withColumn('prev_expected_air_time_route', F.lit(None).cast('double'))\n",
    "        \n",
    "        # Join expected turn time for CURRENT flight's airport\n",
    "        expected_turn_time_path = f\"{FOLDER_PATH}/expected_values_carrier_airport.parquet\"\n",
    "        try:\n",
    "            expected_turn_time = spark.read.parquet(expected_turn_time_path)\n",
    "            # Rename columns to avoid conflicts\n",
    "            expected_turn_time_renamed = expected_turn_time.select(\n",
    "                col('carrier').alias('turn_carrier'),\n",
    "                col('origin').alias('turn_origin'),\n",
    "                col('expected_taxi_out_carrier_airport'),\n",
    "                col('expected_taxi_in_carrier_airport')\n",
    "            )\n",
    "            df = df.join(\n",
    "                expected_turn_time_renamed,\n",
    "                (col('op_carrier') == col('turn_carrier')) & \n",
    "                (col('origin') == col('turn_origin')),\n",
    "                'left'\n",
    "            ).drop('turn_carrier', 'turn_origin')  # Drop temporary join columns\n",
    "            print(\"  ✓ Joined expected_turn_time for current flight's airport\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠ Could not load expected_turn_time: {e}\")\n",
    "            print(\"    Run Time-Series Features Experiment to generate this table\")\n",
    "            # Add placeholder columns\n",
    "            df = df.withColumn('expected_taxi_out_carrier_airport', F.lit(None).cast('double'))\n",
    "            df = df.withColumn('expected_taxi_in_carrier_airport', F.lit(None).cast('double'))\n",
    "        \n",
    "        print(\"\\nPass 4: Deterministic features (using previous flight's values)...\")\n",
    "        # Compute expected arrival time of previous flight\n",
    "        df = df.withColumn(\n",
    "            'expected_arrival_time_prev_flight',\n",
    "            when(\n",
    "                (col('prev_actual_dep_time').isNotNull()) &\n",
    "                (col('prev_expected_air_time_route').isNotNull()),\n",
    "                col('prev_actual_dep_time') + col('prev_expected_air_time_route')\n",
    "            )\n",
    "            .otherwise(None)\n",
    "        )\n",
    "        \n",
    "        # Pull previous flight's expected arrival time for use in current flight calculations\n",
    "        df = df.withColumn(\n",
    "            'prev_expected_arrival_time',\n",
    "            F.lag('expected_arrival_time_prev_flight', 1).over(window_spec)\n",
    "        )\n",
    "        \n",
    "        # Compute expected departure time for CURRENT flight\n",
    "        # Uses previous flight's expected arrival + expected turn time at current airport\n",
    "        df = df.withColumn(\n",
    "            'expected_departure_time_current',\n",
    "            when(\n",
    "                (col('prev_expected_arrival_time').isNotNull()) &\n",
    "                (col('expected_taxi_out_carrier_airport').isNotNull()),\n",
    "                col('prev_expected_arrival_time') + col('expected_taxi_out_carrier_airport')\n",
    "            )\n",
    "            .otherwise(None)\n",
    "        )\n",
    "        \n",
    "        # Compute time buffer and impossible on-time flag\n",
    "        # Convert crs_dep_time to minutes for comparison (HHMM format)\n",
    "        df = df.withColumn(\n",
    "            'crs_dep_time_minutes',\n",
    "            (F.floor(col('crs_dep_time') / 100) * 60 + (col('crs_dep_time') % 100))\n",
    "        )\n",
    "        \n",
    "        df = df.withColumn(\n",
    "            'time_buffer',\n",
    "            when(\n",
    "                (col('expected_departure_time_current').isNotNull()) &\n",
    "                (col('crs_dep_time_minutes').isNotNull()),\n",
    "                col('crs_dep_time_minutes') - col('expected_departure_time_current')\n",
    "            )\n",
    "            .otherwise(None)\n",
    "        )\n",
    "        \n",
    "        df = df.withColumn(\n",
    "            'impossible_on_time_flag',\n",
    "            when(col('time_buffer').isNotNull(),\n",
    "                 when(col('time_buffer') < 0, 1).otherwise(0))\n",
    "            .otherwise(None)\n",
    "        )\n",
    "        \n",
    "        print(\"  ✓ Computed deterministic features\")\n",
    "        \n",
    "        print(\"\\n✓ Lineage features computed!\")\n",
    "        print(f\"Total flights with lineage features: {df.count():,}\")\n",
    "        \n",
    "        # Show sample\n",
    "        display_cols = [\n",
    "            'flight_key', tail_col, 'FL_DATE', 'seq_num', 'origin', 'dest',\n",
    "            'prev_flight_dest', 'is_jump', 'cumulative_delay_since_3am',\n",
    "            'num_previous_flights_today'\n",
    "        ]\n",
    "        print(\"\\nSample lineage features:\")\n",
    "        display(df.select(display_cols).limit(10))\n",
    "        \n",
    "        # Save as materialized table\n",
    "        lineage_features_path = f\"{FOLDER_PATH}/lineage_features_materialized.parquet\"\n",
    "        print(f\"\\nSaving materialized lineage features to: {lineage_features_path}\")\n",
    "        print(\"This table can be joined back to main dataset using flight_key\")\n",
    "        \n",
    "        # Partition by date for efficient joins\n",
    "        df.write.mode(\"overwrite\").partitionBy(\"FL_DATE\").parquet(lineage_features_path)\n",
    "        print(\"✓ Saved! Can now join back to main dataset using flight_key\")\n",
    "        \n",
    "    else:\n",
    "        print(\"tail_num column not found.\")\n",
    "else:\n",
    "    print(\"lineage_data not available. Load data first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Join Lineage Features Back to Main Dataset\n",
    "\n",
    "Example of how to use the materialized table in model training/prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Join lineage features back to main dataset\n",
    "# This is fast - just a simple join operation\n",
    "\n",
    "lineage_features_path = f\"{FOLDER_PATH}/lineage_features_materialized.parquet\"\n",
    "\n",
    "try:\n",
    "    # Load materialized lineage features\n",
    "    lineage_features = spark.read.parquet(lineage_features_path)\n",
    "    \n",
    "    print(f\"Loaded materialized lineage features: {lineage_features.count():,} flights\")\n",
    "    print(f\"Date range: {lineage_features.agg(F.min('FL_DATE'), F.max('FL_DATE')).collect()}\")\n",
    "    \n",
    "    # Example: Join to main dataset\n",
    "    # In production, this would be your main flight dataset after custom join\n",
    "    if 'lineage_data' in locals():\n",
    "        print(\"\\nExample: Joining lineage features back to main dataset...\")\n",
    "        \n",
    "        # Create flight_key on main dataset\n",
    "        tail_cols = [c for c in lineage_data.columns if 'tail' in c.lower()]\n",
    "        if tail_cols:\n",
    "            tail_col = tail_cols[0]\n",
    "            main_with_keys = create_flight_key(lineage_data, tail_col)\n",
    "            \n",
    "            # Join lineage features\n",
    "            main_with_lineage = main_with_keys.join(\n",
    "                lineage_features.select('flight_key', \n",
    "                    'seq_num', 'is_jump', 'prev_flight_dest',\n",
    "                    'cumulative_delay_since_3am', 'num_previous_flights_today',\n",
    "                    'prev_flight_dep_delay', 'prev_flight_arr_delay'\n",
    "                    # Add other lineage feature columns as needed\n",
    "                ),\n",
    "                'flight_key',\n",
    "                'left'\n",
    "            )\n",
    "            \n",
    "            print(f\"\\n✓ Joined lineage features to main dataset\")\n",
    "            print(f\"Total flights: {main_with_lineage.count():,}\")\n",
    "            print(f\"Flights with lineage features: {main_with_lineage.filter(col('seq_num').isNotNull()).count():,}\")\n",
    "            \n",
    "            print(\"\\nSample joined data:\")\n",
    "            display(main_with_lineage.select(\n",
    "                'flight_key', tail_col, 'FL_DATE', 'origin', 'dest',\n",
    "                'seq_num', 'is_jump', 'cumulative_delay_since_3am'\n",
    "            ).limit(10))\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"Performance Benefits:\")\n",
    "            print(\"=\"*60)\n",
    "            print(\"1. Window functions computed ONCE (not on every model run)\")\n",
    "            print(\"2. Simple join operation (fast, efficient)\")\n",
    "            print(\"3. Can partition lineage table by date for even faster joins\")\n",
    "            print(\"4. Clear separation: feature computation vs model training\")\n",
    "        else:\n",
    "            print(\"tail_num column not found in main dataset.\")\n",
    "    else:\n",
    "        print(\"Main dataset not available. This is just an example.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Could not load materialized lineage features: {e}\")\n",
    "    print(\"Run the previous cell to compute and save them first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual example: How LAG works to get previous flight data\n",
    "# This demonstrates that LAG is NOT a join - it's a window function\n",
    "\n",
    "if 'lineage_data' in locals():\n",
    "    print(\"Demonstrating how LAG works to get previous flight data...\\n\")\n",
    "    \n",
    "    tail_cols = [c for c in lineage_data.columns if 'tail' in c.lower()]\n",
    "    if tail_cols:\n",
    "        tail_col = tail_cols[0]\n",
    "        \n",
    "        # Get a sample aircraft with multiple flights on the same day\n",
    "        sample_flights = (\n",
    "            lineage_data\n",
    "            .filter(col(tail_col).isNotNull() & col('FL_DATE').isNotNull())\n",
    "            .select(tail_col, 'FL_DATE', 'origin', 'dest', 'crs_dep_time', 'DEP_DELAY')\n",
    "            .orderBy(tail_col, 'FL_DATE', 'crs_dep_time')\n",
    "            .limit(1000)  # Get enough to find a good example\n",
    "        )\n",
    "        \n",
    "        # Find an aircraft with multiple flights on same day\n",
    "        multi_flight_aircraft = (\n",
    "            sample_flights\n",
    "            .groupBy(tail_col, 'FL_DATE')\n",
    "            .count()\n",
    "            .filter(col('count') > 2)\n",
    "            .orderBy(F.desc('count'))\n",
    "            .limit(1)\n",
    "        )\n",
    "        \n",
    "        if multi_flight_aircraft.count() > 0:\n",
    "            example = multi_flight_aircraft.collect()[0]\n",
    "            example_tail = example[tail_col]\n",
    "            example_date = example['FL_DATE']\n",
    "            \n",
    "            print(f\"Example aircraft: {example_tail} on {example_date}\")\n",
    "            print(f\"Number of flights: {example['count']}\\n\")\n",
    "            \n",
    "            # Get flights for this aircraft on this day\n",
    "            example_flights = (\n",
    "                sample_flights\n",
    "                .filter(\n",
    "                    (col(tail_col) == example_tail) & \n",
    "                    (col('FL_DATE') == example_date)\n",
    "                )\n",
    "                .orderBy('crs_dep_time')\n",
    "            )\n",
    "            \n",
    "            print(\"BEFORE LAG (original data):\")\n",
    "            display(example_flights.select(tail_col, 'FL_DATE', 'crs_dep_time', 'origin', 'dest', 'DEP_DELAY'))\n",
    "            \n",
    "            # Apply LAG to get previous flight's destination\n",
    "            window_spec = Window.partitionBy(tail_col, 'FL_DATE').orderBy('crs_dep_time')\n",
    "            \n",
    "            example_with_lag = example_flights.withColumn(\n",
    "                'prev_flight_dest',\n",
    "                F.lag('dest', 1).over(window_spec)\n",
    "            ).withColumn(\n",
    "                'prev_flight_dep_delay',\n",
    "                F.lag('DEP_DELAY', 1).over(window_spec)\n",
    "            ).withColumn(\n",
    "                'seq_num',\n",
    "                F.row_number().over(window_spec)\n",
    "            )\n",
    "            \n",
    "            print(\"\\nAFTER LAG (with previous flight data):\")\n",
    "            print(\"Notice how prev_flight_dest and prev_flight_dep_delay are automatically\")\n",
    "            print(\"filled from the previous row in the sequence!\\n\")\n",
    "            display(example_with_lag.select(\n",
    "                'seq_num', tail_col, 'FL_DATE', 'crs_dep_time', \n",
    "                'origin', 'dest', 'DEP_DELAY',\n",
    "                'prev_flight_dest', 'prev_flight_dep_delay'\n",
    "            ))\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"Key Points:\")\n",
    "            print(\"=\"*60)\n",
    "            print(\"1. LAG is a WINDOW FUNCTION, not a join\")\n",
    "            print(\"2. It operates on the SAME DataFrame (no separate table needed)\")\n",
    "            print(\"3. Window partitions by (tail_num, FL_DATE) and orders by crs_dep_time\")\n",
    "            print(\"4. LAG(column, 1) gets the value from 1 row before in the partition\")\n",
    "            print(\"5. No primary key or join needed - the window function handles sequencing\")\n",
    "            print(\"6. Much more efficient than self-joining the DataFrame\")\n",
    "        else:\n",
    "            print(\"No aircraft with multiple flights found in sample.\")\n",
    "            print(\"LAG still works, but example would be clearer with multi-flight sequences.\")\n",
    "    else:\n",
    "        print(\"tail_num column not found.\")\n",
    "else:\n",
    "    print(\"lineage_data not available. Load data first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding LAG: How We Get Previous Flight Data\n",
    "\n",
    "### What is LAG?\n",
    "\n",
    "**LAG is NOT a primary key or join operation.** It's a **window function** that gets the value from the previous row within the same DataFrame.\n",
    "\n",
    "### How LAG Works\n",
    "\n",
    "LAG operates on a **window** (partition + ordering):\n",
    "- **Partition**: Groups rows by `(tail_num, FL_DATE)` - all flights by same plane on same day\n",
    "- **Order**: Orders by `crs_dep_time` - earliest to latest\n",
    "- **LAG(column, 1)**: Gets the value from 1 row before in the ordered partition\n",
    "\n",
    "**Example**:\n",
    "```\n",
    "Window: Partition by (tail_num='N12345', FL_DATE='2023-01-15'), Order by crs_dep_time\n",
    "\n",
    "Row 1: Flight 1 (crs_dep_time=800, origin='LAX', dest='JFK')\n",
    "Row 2: Flight 2 (crs_dep_time=1200, origin='JFK', dest='LAX')\n",
    "Row 3: Flight 3 (crs_dep_time=1500, origin='LAX', dest='SFO')\n",
    "\n",
    "After LAG('dest', 1):\n",
    "Row 1: prev_flight_dest = NULL (no previous flight)\n",
    "Row 2: prev_flight_dest = 'JFK' (from Flight 1)\n",
    "Row 3: prev_flight_dest = 'LAX' (from Flight 2)\n",
    "```\n",
    "\n",
    "### Why LAG Instead of Join?\n",
    "\n",
    "**LAG is more efficient** because:\n",
    "1. **No join needed**: All data is in the same DataFrame\n",
    "2. **Automatic ordering**: Window function handles the sequence automatically\n",
    "3. **Single pass**: Computes all previous flight values in one operation\n",
    "4. **No key matching**: No need to create join keys\n",
    "\n",
    "**Join would require**:\n",
    "- Creating a join key for each flight\n",
    "- Self-joining the DataFrame on that key\n",
    "- More complex and less efficient\n",
    "\n",
    "### Join Logic for Expected Values\n",
    "\n",
    "**Important**: When joining expected values for the **previous flight**, you must join on `(prev_flight_origin, prev_flight_dest)`, NOT `(origin, dest)`.\n",
    "\n",
    "**Example**:\n",
    "- Flight 1: LAX → JFK\n",
    "- Flight 2: JFK → LAX  \n",
    "- Flight 3: LAX → SFO\n",
    "\n",
    "For Flight 3:\n",
    "- To get expected air time for Flight 2's route: Join on `(prev_flight_origin='JFK', prev_flight_dest='LAX')`\n",
    "- To get expected turn time for Flight 3's airport: Join on `(op_carrier, origin='LAX')`\n",
    "\n",
    "**Wrong**: `df.join(expected_air_time_route, ['origin', 'dest'], 'left')` \n",
    "- This joins on Flight 3's route (LAX→SFO), not Flight 2's route (JFK→LAX)!\n",
    "\n",
    "**Correct**: `df.join(expected_air_time_route, (prev_flight_origin == origin) & (prev_flight_dest == dest), 'left')`\n",
    "- This joins on Flight 2's route (JFK→LAX) ✓\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Flight Lineage Features Experiment",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
