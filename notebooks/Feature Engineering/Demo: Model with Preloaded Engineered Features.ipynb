{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf27951a-133d-4d05-883e-ff8dfba4e7c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Demo: Model with **Preloaded** Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5732347f-77bc-4fb5-af9e-5dc8c16be827",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# Load modules from our Databricks repo\n",
    "import importlib.util\n",
    "cv_path = \"/Workspace/Shared/Team 4_2/flight-departure-delay-predictive-modeling/notebooks/Cross Validator/cv.py\"\n",
    "spec = importlib.util.spec_from_file_location(\"cv\", cv_path)\n",
    "cv = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(cv)\n",
    "\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import Imputer, StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler, SQLTransformer\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f973d56-0bdc-4343-9372-a7f304651681",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Run Data Loader (REQUIRED)\n",
    "FlightDelayDataLoader(suffix=\"_with_graph\") MUST be ran and the data_loader passed to your cross validator\n",
    "\n",
    "```\n",
    "cv_obj = cv.FlightDelayCV(\n",
    "    estimator=lr_pipe,\n",
    "    dataloader = data_loader,\n",
    "    version=\"3M\"\n",
    ")\n",
    "cv_obj.fit()\n",
    "```\n",
    "\n",
    "**Note**: Preloaded graph features are currently only available for 3M & 60M , not yet for 12M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17942033-4d6f-4eca-90e7-5a1001fc5333",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run Data Loader\n",
    "\n",
    "data_loader = cv.FlightDelayDataLoader(suffix=\"_with_graph\")\n",
    "data_loader.load()  # Must call load() manually when providing dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec224eda-24d3-4dd7-873e-dc0347800dca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Define Features\n",
    "\n",
    "Just include graph features in your numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d7bdf71-77ae-478a-b5d8-e083bfd4bca8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    # 'op_carrier',\n",
    "    # 'origin', # origin airport code\n",
    "    # 'origin_state_abr', # origin state abbreviation\n",
    "    # 'dest', # destination airport code\n",
    "    # 'dest_state_abr', # destination state abbreviation\n",
    "    # 'dep_time_blk', # not outcome var bc this is scheduled departure\n",
    "    # 'arr_time_blk', # not outcome var bc this is scheduled arrival\n",
    "    'month', # cyclical patterns\n",
    "]\n",
    "\n",
    "# Numerical features (graph features will be added by estimator)\n",
    "numerical_features = [\n",
    "    # ============================================================================\n",
    "    # Flight Lineage Features (pre-applied in split.py)\n",
    "    # ============================================================================\n",
    "    'lineage_rank',\n",
    "    'scheduled_lineage_rotation_time_minutes',\n",
    "    'scheduled_lineage_turnover_time_minutes',\n",
    "    'prev_flight_scheduled_flight_time_minutes',\n",
    "    # Data Leakage Free Prior Flight Duration & Delay Features\n",
    "    'safe_lineage_rotation_time_minutes',\n",
    "    'safe_required_time_prev_flight_minutes',\n",
    "    'safe_prev_departure_delay',  # NEW\n",
    "    'safe_prev_arrival_delay',  # NEW\n",
    "    'safe_time_since_prev_arrival', # NEW\n",
    "    'prev_flight_distance',    # From top-performing XGBoost approach\n",
    "    \n",
    "    \n",
    "    # ============================================================================\n",
    "    # Note: Meta-model predictions (predicted_prev_flight_*) \n",
    "    # ============================================================================\n",
    "    \n",
    "    # ============================================================================\n",
    "    # Weather Variables (Current Origin)\n",
    "    # ============================================================================\n",
    "    'hourlyprecipitation',\n",
    "    'hourlysealevelpressure',\n",
    "    'hourlyaltimetersetting',\n",
    "    'hourlywetbulbtemperature',\n",
    "    'hourlystationpressure',\n",
    "    'hourlywinddirection',\n",
    "    'hourlyrelativehumidity',\n",
    "    'hourlywindspeed',\n",
    "    'hourlydewpointtemperature',\n",
    "    'hourlydrybulbtemperature',\n",
    "    'hourlyvisibility',\n",
    "    \n",
    "    'crs_elapsed_time',        # Scheduled elapsed time\n",
    "    'distance',                # Flight distance\n",
    "    'elevation',               # Airport elevation (if available)\n",
    "\n",
    "\n",
    "    # ============================================================================\n",
    "    # Graph Features\n",
    "    # ============================================================================\n",
    "\n",
    "    'prev_flight_origin_pagerank_weighted', # New!\n",
    "    'prev_flight_origin_pagerank_unweighted', # New!\n",
    "    'origin_pagerank_weighted',\n",
    "    'origin_pagerank_unweighted',\n",
    "    'dest_pagerank_weighted',\n",
    "    'dest_pagerank_unweighted'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d985d1e4-0aae-4b8d-b612-3d04d673f467",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Construct Model Pipeline\n",
    "\n",
    "No need to include the graph_features.py module, all graph features have been pre-computed on training folds and applied to cross validation / test folds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d03f950-57c1-47ee-8107-0e83c0181b40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=numerical_features,\n",
    "    outputCols=[f\"{col}_IMPUTED\" for col in numerical_features],\n",
    "    strategy=\"mean\"\n",
    ")\n",
    "\n",
    "indexer = StringIndexer(\n",
    "    inputCols=categorical_features,\n",
    "    outputCols=[f\"{col}_INDEX\" for col in categorical_features],\n",
    "    handleInvalid=\"keep\"\n",
    ")\n",
    "\n",
    "encoder = OneHotEncoder(\n",
    "    inputCols=[f\"{col}_INDEX\" for col in categorical_features],\n",
    "    outputCols=[f\"{col}_VEC\" for col in categorical_features]\n",
    ")\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[f\"{col}_VEC\" for col in categorical_features] + \n",
    "              [f\"{col}_IMPUTED\" for col in numerical_features],\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\"\n",
    ")\n",
    "\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"features\",\n",
    "    outputCol=\"scaled_features\",\n",
    "    withMean=True,\n",
    "    withStd=True\n",
    ")\n",
    "\n",
    "lr = LinearRegression(\n",
    "    featuresCol=\"scaled_features\", \n",
    "    labelCol=\"DEP_DELAY\",\n",
    "    elasticNetParam=0.0,\n",
    ")\n",
    "\n",
    "# Pipeline with graph features, time-series features, and log/exp transforms\n",
    "lr_pipe = Pipeline(stages=[imputer, indexer, encoder, assembler, scaler, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "087927ab-83e9-417d-bac5-a6c54576ba0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Run Cross-Validation with Graph Features\n",
    "\n",
    "**REMEMBER**: You **must** pass the data_loader to `cv.FlightDelayCV()` \n",
    "\n",
    "Recall the data loader is ran loaded with graph features using the following:\n",
    "\n",
    "```\n",
    "data_loader = cv.FlightDelayDataLoader(suffix=\"_with_graph\")\n",
    "data_loader.load() \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94ea4be2-79bf-4772-9da5-6debcaa5483f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cv_obj = cv.FlightDelayCV(\n",
    "    estimator=lr_pipe,\n",
    "    dataloader = data_loader,\n",
    "    version=\"3M\"\n",
    ")\n",
    "cv_obj.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b378c825-11ea-43d0-b7e7-57d65301199d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(cv_obj.evaluate())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "619ac5f0-b16b-43e0-8a4a-3c61597ef66f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 60M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86501fa2-8df6-4ae7-841c-fe87445d189d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cv_obj_60m = cv.FlightDelayCV(\n",
    "    estimator=lr_pipe,\n",
    "    dataloader = data_loader,\n",
    "    version=\"60M\"\n",
    ")\n",
    "cv_obj_60m.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef9df379-33ec-4cc3-aa96-b13f85c49dbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cv_obj_60m.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40342654-af02-4403-973d-aa0ff0ebe802",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# END OF DEMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f16ec127-be8a-4c12-b09d-a394903d3428",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Bonus: Add log transform to pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34e900b3-fda7-4485-a6f5-17aecf2aed00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Graph Features Estimator (builds graph and adds PageRank features)\n",
    "graph_estimator = graph_features.GraphFeaturesEstimator(\n",
    "    origin_col=\"origin\",\n",
    "    dest_col=\"dest\",\n",
    "    reset_probability=0.15,\n",
    "    max_iter=10\n",
    ")\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=numerical_features + graph_feature_cols,\n",
    "    outputCols=[f\"{col}_IMPUTED\" for col in numerical_features + graph_feature_cols],\n",
    "    strategy=\"mean\"\n",
    ")\n",
    "\n",
    "indexer = StringIndexer(\n",
    "    inputCols=categorical_features,\n",
    "    outputCols=[f\"{col}_INDEX\" for col in categorical_features],\n",
    "    handleInvalid=\"keep\"\n",
    ")\n",
    "\n",
    "encoder = OneHotEncoder(\n",
    "    inputCols=[f\"{col}_INDEX\" for col in categorical_features],\n",
    "    outputCols=[f\"{col}_VEC\" for col in categorical_features]\n",
    ")\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[f\"{col}_VEC\" for col in categorical_features] + \n",
    "              [f\"{col}_IMPUTED\" for col in numerical_features + graph_feature_cols],\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\"\n",
    ")\n",
    "\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"features\",\n",
    "    outputCol=\"scaled_features\",\n",
    "    withMean=True,\n",
    "    withStd=True\n",
    ")\n",
    "\n",
    "# Log transform target BEFORE model (handles negatives and zeros)\n",
    "# For negative delays, we use signed log: SIGN(y) * LOG(ABS(y) + 1)\n",
    "# This preserves the sign while applying log transform\n",
    "# Note: Filters out NULL DEP_DELAY values (required for LinearRegression)\n",
    "log_transform = SQLTransformer(\n",
    "    statement=\"\"\"\n",
    "    SELECT *, \n",
    "           SIGN(DEP_DELAY) * LOG(ABS(DEP_DELAY) + 1.0) AS DEP_DELAY_log\n",
    "    FROM __THIS__\n",
    "    WHERE DEP_DELAY IS NOT NULL\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "lr = LinearRegression(\n",
    "    featuresCol=\"scaled_features\", \n",
    "    labelCol=\"DEP_DELAY_log\",  # Use log-transformed target\n",
    "    predictionCol=\"prediction_log\",  # Predictions in log space\n",
    "    solver=\"normal\",  # Required for p-values and standard errors\n",
    "    regParam=0.0,  # Required for statistical significance measures\n",
    "    elasticNetParam=0.0,\n",
    ")\n",
    "\n",
    "# Inverse transform AFTER model (inverse of signed log transform)\n",
    "# Inverse of SIGN(y) * LOG(ABS(y) + 1) is SIGN(y) * (EXP(ABS(y)) - 1)\n",
    "exp_transform = SQLTransformer(\n",
    "    statement=\"\"\"\n",
    "    SELECT *, \n",
    "           CASE \n",
    "               WHEN prediction_log IS NOT NULL THEN \n",
    "                   SIGN(prediction_log) * (EXP(ABS(prediction_log)) - 1.0)\n",
    "               ELSE NULL \n",
    "           END AS prediction\n",
    "    FROM __THIS__\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Pipeline with graph features, time-series features, and log/exp transforms\n",
    "lr_pipe_w_log = Pipeline(stages=[graph_estimator, imputer, indexer, encoder, assembler, scaler, log_transform, lr, exp_transform])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c8a3eff-2f92-40c3-8065-8cf0a086eda2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cv_lr_log = cv.FlightDelayCV(\n",
    "    estimator=lr_pipe_w_log,\n",
    "    dataloader = data_loader,\n",
    "    version=\"3M\"\n",
    ")\n",
    "cv_lr_log.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68711748-337b-4ca2-a98f-fbd868a08565",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cv_lr_log.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23944ab9-c630-4650-ae2e-e9ccedd79bda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Augment Flight Dataframe with Flight Lineage Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23f84f2a-5b42-4f6a-bfb0-90c711de0c9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Validate Flight Lineage Data Features are in Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf8e3855-6115-4b06-bd1d-77942c4cf16c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load a dataframe\n",
    "data_loader = cv.FlightDelayDataLoader()\n",
    "data_loader.load()\n",
    "folds = data_loader.get_version(\"3M\")\n",
    "train_fold, text_fold = folds[0]\n",
    "\n",
    "# Display results\n",
    "display(train_fold.limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cca47629-d8e2-4861-808f-d3e4c4bbdbc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Verify Graph & Time-Series Features Ran Successfully\n",
    "Access pipeline and model objects to validate graph features loaded correctly and were used in the model (Kudos Claude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32e693d9-451b-42ae-a9fa-b862e22abe45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verify graph and time-series features were used in the model\n",
    "print(\"=== Graph and Time-Series Features Verification ===\\n\")\n",
    "\n",
    "# Check pipeline stages to confirm estimators are present\n",
    "print(\"Pipeline stages:\")\n",
    "graph_stage_idx = None\n",
    "time_series_stage_idx = None\n",
    "for i, stage in enumerate(cv_obj.models[0].stages):\n",
    "    stage_name = type(stage).__name__\n",
    "    print(f\"  {i}: {stage_name}\")\n",
    "    if 'Graph' in stage_name:\n",
    "        print(f\"      ✓ Graph features estimator found!\")\n",
    "        graph_stage_idx = i\n",
    "    if 'TimeSeries' in stage_name:\n",
    "        print(f\"      ✓ Time-series features estimator found!\")\n",
    "        time_series_stage_idx = i\n",
    "\n",
    "# Check if features are in transformed data\n",
    "print(\"\\nChecking transformed validation data for features...\")\n",
    "sample_val_df = cv_obj.models[0].transform(cv_obj.folds[0][1])  # First fold's validation data\n",
    "\n",
    "# Graph features\n",
    "graph_cols = [col for col in sample_val_df.columns if 'pagerank' in col.lower()]\n",
    "print(f\"\\nGraph feature columns found: {graph_cols}\")\n",
    "\n",
    "# Time-series features\n",
    "time_series_cols = [col for col in sample_val_df.columns if 'prophet' in col.lower()]\n",
    "print(f\"Time-series feature columns found: {len(time_series_cols)} columns\")\n",
    "print(f\"  Sample: {time_series_cols[:5]}...\")\n",
    "\n",
    "# Show sample of graph features\n",
    "print(\"\\n=== Sample Graph Feature Values ===\")\n",
    "sample_val_df.select(\"origin\", \"dest\", *graph_cols).show(5)\n",
    "\n",
    "# Show sample of time-series features\n",
    "print(\"\\n=== Sample Time-Series Feature Values ===\")\n",
    "sample_val_df.select(\"FL_DATE\", \"op_carrier\", \"origin\", *time_series_cols[:5]).show(5)\n",
    "\n",
    "# Get Linear Regression model and coefficients\n",
    "print(\"\\n=== Feature Coefficients ===\")\n",
    "lr_model = cv_obj.models[0].stages[-1]  # Last stage is LinearRegression\n",
    "coefficients = lr_model.coefficients.toArray()\n",
    "\n",
    "# Get assembler to find feature order\n",
    "assembler = cv_obj.models[0].stages[4]  # VectorAssembler\n",
    "input_cols = assembler.getInputCols()\n",
    "\n",
    "# Count categorical features (one-hot encoded vectors)\n",
    "sample_row = cv_obj.folds[0][1].limit(1)\n",
    "transformed_before_assembler = cv_obj.models[0].stages[3].transform(  # OneHotEncoder\n",
    "    cv_obj.models[0].stages[2].transform(  # StringIndexer\n",
    "        cv_obj.models[0].stages[1].transform(  # Imputer\n",
    "            cv_obj.models[0].stages[0].transform(sample_row)  # GraphFeatures/TimeSeriesFeatures\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "categorical_vec_cols = [col for col in input_cols if col.endswith(\"_VEC\")]\n",
    "categorical_feature_count = 0\n",
    "for col in categorical_vec_cols:\n",
    "    if col in transformed_before_assembler.columns:\n",
    "        vec = transformed_before_assembler.select(col).first()[0]\n",
    "        if vec:\n",
    "            categorical_feature_count += len(vec.toArray())\n",
    "\n",
    "# Numerical features (including graph and time-series) start after categorical\n",
    "numerical_start_idx = categorical_feature_count\n",
    "all_numerical_imputed = [f\"{col}_IMPUTED\" for col in numerical_features + graph_feature_cols + time_series_feature_cols]\n",
    "\n",
    "print(f\"Total categorical features: {categorical_feature_count}\")\n",
    "print(f\"Numerical features start at index: {numerical_start_idx}\")\n",
    "\n",
    "# Graph feature coefficients\n",
    "print(f\"\\n=== Graph Feature Coefficients ===\")\n",
    "print(f\"{'Feature':<40} {'Coefficient':<15}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "graph_coefs = {}\n",
    "for feat_name in graph_feature_cols:\n",
    "    feat_imputed = f\"{feat_name}_IMPUTED\"\n",
    "    if feat_imputed in all_numerical_imputed:\n",
    "        coef_idx = numerical_start_idx + all_numerical_imputed.index(feat_imputed)\n",
    "        if coef_idx < len(coefficients):\n",
    "            coef = coefficients[coef_idx]\n",
    "            graph_coefs[feat_name] = coef\n",
    "            print(f\"{feat_name:<40} {coef:>14.6f}\")\n",
    "        else:\n",
    "            print(f\"{feat_name:<40} {'Index out of range':<15}\")\n",
    "    else:\n",
    "        print(f\"{feat_name:<40} {'Not found':<15}\")\n",
    "\n",
    "# Time-series feature coefficients\n",
    "print(f\"\\n=== Time-Series Feature Coefficients ===\")\n",
    "print(f\"{'Feature':<50} {'Coefficient':<15}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "time_series_coefs = {}\n",
    "for feat_name in time_series_feature_cols:\n",
    "    feat_imputed = f\"{feat_name}_IMPUTED\"\n",
    "    if feat_imputed in all_numerical_imputed:\n",
    "        coef_idx = numerical_start_idx + all_numerical_imputed.index(feat_imputed)\n",
    "        if coef_idx < len(coefficients):\n",
    "            coef = coefficients[coef_idx]\n",
    "            time_series_coefs[feat_name] = coef\n",
    "            print(f\"{feat_name:<50} {coef:>14.6f}\")\n",
    "        else:\n",
    "            print(f\"{feat_name:<50} {'Index out of range':<15}\")\n",
    "    else:\n",
    "        print(f\"{feat_name:<50} {'Not found':<15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fcf2a60a-80a2-4649-8108-491e82fad7f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Graph Feature & Time-Series Statistical Significance (Simplified Model)\n",
    "Simple model with only graph featues to determine statistical signifance of these features (Kudos Claude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7a2b467-50cd-4314-9358-f34e2eab9c3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Workaround: Fit simplified models with just graph features and just time-series features to get statistics\n",
    "print(\"=== Workaround: Simplified Models for Feature Significance ===\\n\")\n",
    "\n",
    "# Get transformed training data with all features\n",
    "train_df_with_features = cv_obj.models[0].stages[0].transform(cv_obj.folds[0][0])  # GraphFeaturesModel\n",
    "train_df_with_features = cv_obj.models[0].stages[1].transform(train_df_with_features)  # TimeSeriesFeaturesModel\n",
    "train_df_with_features = cv_obj.models[0].stages[2].transform(train_df_with_features)  # Imputer\n",
    "\n",
    "# ===== Graph Features Simplified Model =====\n",
    "print(\"=== Graph Features Simplified Model ===\\n\")\n",
    "\n",
    "# Select only graph features + label for simplified model\n",
    "graph_features_imputed = [f\"{col}_IMPUTED\" for col in graph_feature_cols]\n",
    "graph_simplified_features = graph_features_imputed + [\"DEP_DELAY\"]\n",
    "\n",
    "# Create simplified dataset\n",
    "graph_simplified_df = train_df_with_features.select(*graph_simplified_features).dropna()\n",
    "\n",
    "print(f\"Graph features: {graph_feature_cols}\")\n",
    "print(f\"Graph simplified dataset size: {graph_simplified_df.count():,} rows\\n\")\n",
    "\n",
    "# Fit simplified LinearRegression model for graph features\n",
    "from pyspark.ml.feature import VectorAssembler as VA\n",
    "from pyspark.ml.regression import LinearRegression as LR\n",
    "\n",
    "# Assemble graph features\n",
    "va_graph = VA(inputCols=graph_features_imputed, outputCol=\"features\", handleInvalid=\"skip\")\n",
    "lr_graph = LR(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"DEP_DELAY\",\n",
    "    solver=\"normal\",\n",
    "    regParam=0.0,\n",
    "    elasticNetParam=0.0\n",
    ")\n",
    "\n",
    "# Fit graph model\n",
    "graph_assembled_df = va_graph.transform(graph_simplified_df)\n",
    "graph_simple_model = lr_graph.fit(graph_assembled_df)\n",
    "\n",
    "# ===== Time-Series Features Simplified Model =====\n",
    "print(\"\\n=== Time-Series Features Simplified Model ===\\n\")\n",
    "\n",
    "# Select only time-series features + label for simplified model\n",
    "time_series_features_imputed = [f\"{col}_IMPUTED\" for col in time_series_feature_cols]\n",
    "time_series_simplified_features = time_series_features_imputed + [\"DEP_DELAY\"]\n",
    "\n",
    "# Create simplified dataset\n",
    "time_series_simplified_df = train_df_with_features.select(*time_series_simplified_features).dropna()\n",
    "\n",
    "print(f\"Time-series features: {len(time_series_feature_cols)} features\")\n",
    "print(f\"  Sample: {time_series_feature_cols[:3]}...\")\n",
    "print(f\"Time-series simplified dataset size: {time_series_simplified_df.count():,} rows\\n\")\n",
    "\n",
    "# Assemble time-series features\n",
    "va_time_series = VA(inputCols=time_series_features_imputed, outputCol=\"features\", handleInvalid=\"skip\")\n",
    "lr_time_series = LR(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"DEP_DELAY\",\n",
    "    solver=\"normal\",\n",
    "    regParam=0.0,\n",
    "    elasticNetParam=0.0\n",
    ")\n",
    "\n",
    "# Fit time-series model\n",
    "time_series_assembled_df = va_time_series.transform(time_series_simplified_df)\n",
    "time_series_simple_model = lr_time_series.fit(time_series_assembled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fca0a7b5-6671-49eb-95f8-7cd8a9a6d65d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ===== Graph Features Statistics =====\n",
    "graph_summary = graph_simple_model.summary\n",
    "\n",
    "print(\"=== Graph Features Simplified Model Summary Statistics ===\")\n",
    "print(f\"RMSE: {graph_summary.rootMeanSquaredError:.6f}\")\n",
    "print(f\"R²: {graph_summary.r2:.6f}\")\n",
    "print(f\"Mean Absolute Error: {graph_summary.meanAbsoluteError:.6f}\")\n",
    "print(f\"Total iterations: {graph_summary.totalIterations}\")\n",
    "print(f\"Objective history: {graph_summary.objectiveHistory[-5:] if len(graph_summary.objectiveHistory) >= 5 else graph_summary.objectiveHistory}\\n\")\n",
    "\n",
    "# Get statistics from graph simplified model\n",
    "graph_p_values = graph_summary.pValues\n",
    "graph_std_errors = graph_summary.coefficientStandardErrors\n",
    "graph_t_values = graph_summary.tValues\n",
    "\n",
    "print(\"✓ Statistical measures available for graph features simplified model!\\n\")\n",
    "print(f\"{'Feature':<40} {'Coefficient':<15} {'Std Error':<15} {'T-stat':<12} {'P-value':<15} {'Significant':<10}\")\n",
    "print(\"-\" * 107)\n",
    "\n",
    "for i, feat_name in enumerate(graph_feature_cols):\n",
    "    coef = graph_simple_model.coefficients[i]\n",
    "    std_err = graph_std_errors[i] if i < len(graph_std_errors) else None\n",
    "    t_stat = graph_t_values[i] if i < len(graph_t_values) else None\n",
    "    pval = graph_p_values[i] if i < len(graph_p_values) else None\n",
    "    \n",
    "    # Determine significance: use p-value if available, otherwise use t-statistic\n",
    "    if pval is not None:\n",
    "        sig = \"***\" if pval < 0.001 else \"**\" if pval < 0.01 else \"*\" if pval < 0.05 else \"\"\n",
    "    elif t_stat is not None:\n",
    "        # Use t-statistic thresholds: |t| > 2.576 (p<0.01), |t| > 1.96 (p<0.05), |t| > 1.645 (p<0.10)\n",
    "        abs_t = abs(t_stat)\n",
    "        sig = \"***\" if abs_t > 2.576 else \"**\" if abs_t > 1.96 else \"*\" if abs_t > 1.645 else \"\"\n",
    "    else:\n",
    "        sig = \"\"\n",
    "    \n",
    "    std_err_str = f\"{std_err:>14.6f}\" if std_err else \"N/A\"\n",
    "    t_stat_str = f\"{t_stat:>12.4f}\" if t_stat else \"N/A\"\n",
    "    \n",
    "    # Format p-value: show 0.000000 for very small values or N/A\n",
    "    if pval is not None:\n",
    "        if pval < 2.2e-15:  # Machine epsilon threshold\n",
    "            pval_str = \"< 2.2e-15\"\n",
    "        else:\n",
    "            pval_str = f\"{pval:>14.6f}\"\n",
    "    else:\n",
    "        pval_str = \"0.000000\"  # Show 0 instead of N/A for missing p-values\n",
    "    \n",
    "    print(f\"{feat_name:<40} {coef:>14.6f} {std_err_str:>15} {t_stat_str:>12} {pval_str:>15} {sig:>10}\")\n",
    "\n",
    "print(f\"\\nSignificance levels: *** p<0.001, ** p<0.01, * p<0.05\")\n",
    "print(f\"\\nNote: These statistics are from a simplified model with only graph features.\")\n",
    "print(f\"      They show the significance of graph features in isolation.\")\n",
    "\n",
    "# ===== Time-Series Features Statistics =====\n",
    "time_series_summary = time_series_simple_model.summary\n",
    "\n",
    "print(\"\\n\" + \"=\"*107)\n",
    "print(\"=== Time-Series Features Simplified Model Summary Statistics ===\")\n",
    "print(f\"RMSE: {time_series_summary.rootMeanSquaredError:.6f}\")\n",
    "print(f\"R²: {time_series_summary.r2:.6f}\")\n",
    "print(f\"Mean Absolute Error: {time_series_summary.meanAbsoluteError:.6f}\")\n",
    "print(f\"Total iterations: {time_series_summary.totalIterations}\")\n",
    "print(f\"Objective history: {time_series_summary.objectiveHistory[-5:] if len(time_series_summary.objectiveHistory) >= 5 else time_series_summary.objectiveHistory}\\n\")\n",
    "\n",
    "# Get statistics from time-series simplified model\n",
    "time_series_p_values = time_series_summary.pValues\n",
    "time_series_std_errors = time_series_summary.coefficientStandardErrors\n",
    "time_series_t_values = time_series_summary.tValues\n",
    "\n",
    "print(\"✓ Statistical measures available for time-series features simplified model!\\n\")\n",
    "print(f\"{'Feature':<50} {'Coefficient':<15} {'Std Error':<15} {'T-stat':<12} {'P-value':<15} {'Significant':<10}\")\n",
    "print(\"-\" * 117)\n",
    "\n",
    "for i, feat_name in enumerate(time_series_feature_cols):\n",
    "    coef = time_series_simple_model.coefficients[i]\n",
    "    std_err = time_series_std_errors[i] if i < len(time_series_std_errors) else None\n",
    "    t_stat = time_series_t_values[i] if i < len(time_series_t_values) else None\n",
    "    pval = time_series_p_values[i] if i < len(time_series_p_values) else None\n",
    "    \n",
    "    # Determine significance: use p-value if available, otherwise use t-statistic\n",
    "    if pval is not None:\n",
    "        sig = \"***\" if pval < 0.001 else \"**\" if pval < 0.01 else \"*\" if pval < 0.05 else \"\"\n",
    "    elif t_stat is not None:\n",
    "        # Use t-statistic thresholds: |t| > 2.576 (p<0.01), |t| > 1.96 (p<0.05), |t| > 1.645 (p<0.10)\n",
    "        abs_t = abs(t_stat)\n",
    "        sig = \"***\" if abs_t > 2.576 else \"**\" if abs_t > 1.96 else \"*\" if abs_t > 1.645 else \"\"\n",
    "    else:\n",
    "        sig = \"\"\n",
    "    \n",
    "    std_err_str = f\"{std_err:>14.6f}\" if std_err else \"N/A\"\n",
    "    t_stat_str = f\"{t_stat:>12.4f}\" if t_stat else \"N/A\"\n",
    "    \n",
    "    # Format p-value: show 0.000000 for very small values or N/A\n",
    "    if pval is not None:\n",
    "        if pval < 2.2e-15:  # Machine epsilon threshold\n",
    "            pval_str = \"< 2.2e-15\"\n",
    "        else:\n",
    "            pval_str = f\"{pval:>14.6f}\"\n",
    "    else:\n",
    "        pval_str = \"0.000000\"  # Show 0 instead of N/A for missing p-values\n",
    "    \n",
    "    print(f\"{feat_name:<50} {coef:>14.6f} {std_err_str:>15} {t_stat_str:>12} {pval_str:>15} {sig:>10}\")\n",
    "\n",
    "print(f\"\\nSignificance levels: *** p<0.001, ** p<0.01, * p<0.05\")\n",
    "print(f\"\\nNote: These statistics are from a simplified model with only time-series features.\")\n",
    "print(f\"      They show the significance of time-series features in isolation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e791f357-eb97-4cdc-8e36-7383c6cda1c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Test flight_lineage_features module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14261fb5-fcbb-4124-8fd0-103148339af7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f05ac2f3-ea3e-4fa8-b9cf-81496b7c8230",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc2a4c23-78e8-42df-a25a-bdc908a37264",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Demo: Model with Preloaded Engineered Features",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
