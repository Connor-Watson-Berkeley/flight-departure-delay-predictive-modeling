{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5732347f-77bc-4fb5-af9e-5dc8c16be827",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import importlib.util\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# Load modules\n",
    "cv_path = \"/Workspace/Shared/Team 4_2/flight-departure-delay-predictive-modeling/notebooks/Cross Validator/cv.py\"\n",
    "spec = importlib.util.spec_from_file_location(\"cv\", cv_path)\n",
    "cv = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(cv)\n",
    "\n",
    "graph_features_path = \"/Workspace/Shared/Team 4_2/flight-departure-delay-predictive-modeling/notebooks/Feature Engineering/graph_features.py\"\n",
    "spec = importlib.util.spec_from_file_location(\"graph_features\", graph_features_path)\n",
    "graph_features = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(graph_features)\n",
    "\n",
    "time_series_features_path = \"/Workspace/Shared/Team 4_2/flight-departure-delay-predictive-modeling/notebooks/Feature Engineering/time_series_features.py\"\n",
    "spec = importlib.util.spec_from_file_location(\"time_series_features\", time_series_features_path)\n",
    "time_series_features = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(time_series_features)\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import Imputer, StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec224eda-24d3-4dd7-873e-dc0347800dca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Define Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d7bdf71-77ae-478a-b5d8-e083bfd4bca8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    'day_of_week',\n",
    "    'op_carrier',\n",
    "    'origin', # origin airport code\n",
    "    'origin_state_abr', # origin state abbreviation\n",
    "    'dest', # destination airport code\n",
    "    'dest_state_abr', # destination state abbreviation\n",
    "    'dep_time_blk', # not outcome var bc this is scheduled departure\n",
    "    'arr_time_blk', # not outcome var bc this is scheduled arrival\n",
    "    'day_of_month',\n",
    "    'month', # cyclical patterns\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    'hourlyprecipitation',\n",
    "    'hourlysealevelpressure',\n",
    "    'hourlyaltimetersetting',\n",
    "    'hourlywetbulbtemperature',\n",
    "    'hourlystationpressure',\n",
    "    'hourlywinddirection',\n",
    "    'hourlyrelativehumidity',\n",
    "    'hourlywindspeed',\n",
    "    'hourlydewpointtemperature',\n",
    "    'hourlydrybulbtemperature',\n",
    "    'hourlyvisibility',\n",
    "    'crs_elapsed_time',\n",
    "    'distance',\n",
    "    'elevation',\n",
    "]\n",
    "\n",
    "# Graph features that will be added by GraphFeaturesEstimator\n",
    "graph_feature_cols = [\n",
    "    'origin_pagerank_weighted',\n",
    "    'origin_pagerank_unweighted',\n",
    "    'dest_pagerank_weighted',\n",
    "    'dest_pagerank_unweighted'\n",
    "]\n",
    "\n",
    "# Time-series features that will be added by TimeSeriesFeaturesEstimator\n",
    "# Note: yearly_seasonality features are only added if >=365 days of data available\n",
    "time_series_feature_cols = [\n",
    "    # Global features (guaranteed)\n",
    "    'prophet_forecast_dep_delay_global',\n",
    "    'prophet_trend_global',\n",
    "    'prophet_weekly_seasonality_global',\n",
    "    # Carrier features (guaranteed if carrier has >=14 days)\n",
    "    'prophet_forecast_dep_delay_carrier',\n",
    "    'prophet_trend_carrier',\n",
    "    'prophet_weekly_seasonality_carrier',\n",
    "    # Airport features (guaranteed if airport has >=14 days)\n",
    "    'prophet_forecast_dep_delay_airport',\n",
    "    'prophet_trend_airport',\n",
    "    'prophet_weekly_seasonality_airport',\n",
    "    # Optional yearly seasonality features (only if >=365 days of data)\n",
    "    # These may not exist for all carriers/airports, so handle gracefully\n",
    "    'prophet_yearly_seasonality_global',\n",
    "    'prophet_yearly_seasonality_carrier',\n",
    "    'prophet_yearly_seasonality_airport',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d985d1e4-0aae-4b8d-b612-3d04d673f467",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Construct Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d03f950-57c1-47ee-8107-0e83c0181b40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Graph Features Estimator (builds graph and adds PageRank features)\n",
    "graph_estimator = graph_features.GraphFeaturesEstimator(\n",
    "    origin_col=\"origin\",\n",
    "    dest_col=\"dest\",\n",
    "    reset_probability=0.15,\n",
    "    max_iter=10\n",
    ")\n",
    "\n",
    "# Time-Series Features Estimator (generates Prophet-based time-series features)\n",
    "time_series_estimator = time_series_features.TimeSeriesFeaturesEstimator(\n",
    "    date_col=\"FL_DATE\",\n",
    "    carrier_col=\"op_carrier\",\n",
    "    origin_col=\"origin\",\n",
    "    delay_col=\"DEP_DELAY\",\n",
    "    min_days_required=14,\n",
    "    changepoint_prior_scale=0.05\n",
    ")\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=numerical_features + graph_feature_cols + time_series_feature_cols,\n",
    "    outputCols=[f\"{col}_IMPUTED\" for col in numerical_features + graph_feature_cols + time_series_feature_cols],\n",
    "    strategy=\"mean\"\n",
    ")\n",
    "\n",
    "indexer = StringIndexer(\n",
    "    inputCols=categorical_features,\n",
    "    outputCols=[f\"{col}_INDEX\" for col in categorical_features],\n",
    "    handleInvalid=\"keep\"\n",
    ")\n",
    "\n",
    "encoder = OneHotEncoder(\n",
    "    inputCols=[f\"{col}_INDEX\" for col in categorical_features],\n",
    "    outputCols=[f\"{col}_VEC\" for col in categorical_features]\n",
    ")\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[f\"{col}_VEC\" for col in categorical_features] + \n",
    "              [f\"{col}_IMPUTED\" for col in numerical_features + graph_feature_cols + time_series_feature_cols],\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\"\n",
    ")\n",
    "\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"features\",\n",
    "    outputCol=\"scaled_features\",\n",
    "    withMean=True,\n",
    "    withStd=True\n",
    ")\n",
    "\n",
    "lr = LinearRegression(\n",
    "    featuresCol=\"scaled_features\", \n",
    "    labelCol=\"DEP_DELAY\",\n",
    "    solver=\"normal\",  # Required for p-values and standard errors\n",
    "    regParam=0.0,  # Required for statistical significance measures\n",
    "    elasticNetParam=0.0,\n",
    ")\n",
    "\n",
    "# Pipeline with graph features and time-series features\n",
    "lr_pipe = Pipeline(stages=[graph_estimator, time_series_estimator, imputer, indexer, encoder, assembler, scaler, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "087927ab-83e9-417d-bac5-a6c54576ba0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Run Cross-Validation with Graph Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94ea4be2-79bf-4772-9da5-6debcaa5483f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cv_obj = cv.FlightDelayCV(\n",
    "    estimator=lr_pipe,\n",
    "    version=\"3M\"\n",
    ")\n",
    "cv_obj.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c51b8e1-c738-4915-bb7c-c9454620fa30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Train on overlapping folds\n",
    "cv_obj_overlapping = cv.FlightDelayCV(\n",
    "    estimator=lr_pipe,\n",
    "    version=\"3M\",\n",
    "    fold_strategy=\"overlapping\",\n",
    "    n_folds=3, \n",
    "    train_window_sections=2,\n",
    "    n_sections=5\n",
    ")\n",
    "cv_obj_overlapping.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eecac01b-b1cc-4565-9bbd-ec56c15730eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## View Cross-Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9fe1ecc-231c-4b38-ba30-73e6be927ff3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Cross-Validation Results:\")\n",
    "print(cv_obj.metrics)\n",
    "print(\"\\nMean metrics across folds:\")\n",
    "print(pd.DataFrame(cv_obj.metrics).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba831cd9-e48f-4613-a5fd-c3d5ca8f76a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Cross-Validation Results:\")\n",
    "print(cv_obj_overlapping.metrics)\n",
    "print(\"\\nMean metrics across folds:\")\n",
    "print(pd.DataFrame(cv_obj_overlapping.metrics).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8caccc4-c99a-425d-a51b-2e168fd7b80e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# END OF DEMO\n",
    "Below validates the model pipeline works with graph features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3acb041-e50c-4e81-8591-42bfd7270678",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Verify Graph Features Ran Successfully\n",
    "Access pipeline and model objects to validate graph features loaded correctly and were used in the model (Kudos Claude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0914442-0929-453a-8d29-ade86e7f23ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verify graph features were used in the model\n",
    "print(\"=== Graph Features Verification ===\\n\")\n",
    "\n",
    "# Check pipeline stages to confirm graph estimator is present\n",
    "print(\"Pipeline stages:\")\n",
    "for i, stage in enumerate(cv_obj.models[0].stages):\n",
    "    stage_name = type(stage).__name__\n",
    "    print(f\"  {i}: {stage_name}\")\n",
    "    if 'Graph' in stage_name:\n",
    "        print(f\"      ✓ Graph features estimator found!\")\n",
    "\n",
    "# Check if graph features are in transformed data\n",
    "print(\"\\nChecking transformed validation data for graph features...\")\n",
    "sample_val_df = cv_obj.models[0].transform(cv_obj.folds[0][1])  # First fold's validation data\n",
    "graph_cols = [col for col in sample_val_df.columns if 'pagerank' in col.lower()]\n",
    "print(f\"Graph feature columns found: {graph_cols}\")\n",
    "\n",
    "# Show sample of graph features\n",
    "print(\"\\nSample graph feature values:\")\n",
    "sample_val_df.select(\"origin\", \"dest\", *graph_cols).show(5)\n",
    "\n",
    "# Get Linear Regression model and coefficients\n",
    "print(\"\\n=== Graph Feature Coefficients ===\")\n",
    "lr_model = cv_obj.models[0].stages[-1]  # Last stage is LinearRegression\n",
    "coefficients = lr_model.coefficients.toArray()\n",
    "\n",
    "# Get assembler to find feature order\n",
    "assembler = cv_obj.models[0].stages[4]  # VectorAssembler\n",
    "input_cols = assembler.getInputCols()\n",
    "\n",
    "# Count categorical features (one-hot encoded vectors)\n",
    "sample_row = cv_obj.folds[0][1].limit(1)\n",
    "transformed_before_assembler = cv_obj.models[0].stages[3].transform(  # OneHotEncoder\n",
    "    cv_obj.models[0].stages[2].transform(  # StringIndexer\n",
    "        cv_obj.models[0].stages[1].transform(  # Imputer\n",
    "            cv_obj.models[0].stages[0].transform(sample_row)  # GraphFeatures\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "categorical_vec_cols = [col for col in input_cols if col.endswith(\"_VEC\")]\n",
    "categorical_feature_count = 0\n",
    "for col in categorical_vec_cols:\n",
    "    if col in transformed_before_assembler.columns:\n",
    "        vec = transformed_before_assembler.select(col).first()[0]\n",
    "        if vec:\n",
    "            categorical_feature_count += len(vec.toArray())\n",
    "\n",
    "# Numerical features (including graph) start after categorical\n",
    "numerical_start_idx = categorical_feature_count\n",
    "all_numerical_imputed = [f\"{col}_IMPUTED\" for col in numerical_features + graph_feature_cols]\n",
    "\n",
    "print(f\"Total categorical features: {categorical_feature_count}\")\n",
    "print(f\"Numerical features start at index: {numerical_start_idx}\")\n",
    "print(f\"\\nGraph feature coefficients:\")\n",
    "print(f\"{'Feature':<40} {'Coefficient':<15}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "graph_coefs = {}\n",
    "for feat_name in graph_feature_cols:\n",
    "    feat_imputed = f\"{feat_name}_IMPUTED\"\n",
    "    if feat_imputed in all_numerical_imputed:\n",
    "        coef_idx = numerical_start_idx + all_numerical_imputed.index(feat_imputed)\n",
    "        if coef_idx < len(coefficients):\n",
    "            coef = coefficients[coef_idx]\n",
    "            graph_coefs[feat_name] = coef\n",
    "            print(f\"{feat_name:<40} {coef:>14.6f}\")\n",
    "        else:\n",
    "            print(f\"{feat_name:<40} {'Index out of range':<15}\")\n",
    "    else:\n",
    "        print(f\"{feat_name:<40} {'Not found':<15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fcf2a60a-80a2-4649-8108-491e82fad7f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Graph Feature Statistical Significance (Simplified Model)\n",
    "Simple model with only graph featues to determine statistical signifance of these features (Kudos Claude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7a2b467-50cd-4314-9358-f34e2eab9c3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Workaround: Fit a simplified model with just graph features to get statistics\n",
    "print(\"=== Workaround: Simplified Model for Graph Feature Significance ===\\n\")\n",
    "\n",
    "# Get transformed training data with graph features\n",
    "train_df_with_graph = cv_obj.models[0].stages[0].transform(cv_obj.folds[0][0])  # GraphFeaturesModel\n",
    "train_df_with_graph = cv_obj.models[0].stages[1].transform(train_df_with_graph)  # Imputer\n",
    "\n",
    "# Select only graph features + label for simplified model\n",
    "graph_features_imputed = [f\"{col}_IMPUTED\" for col in graph_feature_cols]\n",
    "simplified_features = graph_features_imputed + [\"DEP_DELAY\"]\n",
    "\n",
    "# Create simplified dataset\n",
    "simplified_df = train_df_with_graph.select(*simplified_features).dropna()\n",
    "\n",
    "print(f\"Simplified model features: {graph_feature_cols}\")\n",
    "print(f\"Simplified dataset size: {simplified_df.count():,} rows\\n\")\n",
    "\n",
    "# Fit simplified LinearRegression model\n",
    "from pyspark.ml.feature import VectorAssembler as VA\n",
    "from pyspark.ml.regression import LinearRegression as LR\n",
    "\n",
    "# Assemble features\n",
    "va_simple = VA(inputCols=graph_features_imputed, outputCol=\"features\", handleInvalid=\"skip\")\n",
    "lr_simple = LR(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"DEP_DELAY\",\n",
    "    solver=\"normal\",\n",
    "    regParam=0.0,\n",
    "    elasticNetParam=0.0\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "assembled_df = va_simple.transform(simplified_df)\n",
    "simple_model = lr_simple.fit(assembled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "57cf37ea-a047-4a24-aceb-15f34d470833",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get model summary statistics\n",
    "simple_summary = simple_model.summary\n",
    "\n",
    "print(\"=== Simplified Model Summary Statistics ===\")\n",
    "print(f\"RMSE: {simple_summary.rootMeanSquaredError:.6f}\")\n",
    "print(f\"R²: {simple_summary.r2:.6f}\")\n",
    "print(f\"Mean Absolute Error: {simple_summary.meanAbsoluteError:.6f}\")\n",
    "print(f\"Total iterations: {simple_summary.totalIterations}\")\n",
    "print(f\"Objective history: {simple_summary.objectiveHistory[-5:] if len(simple_summary.objectiveHistory) >= 5 else simple_summary.objectiveHistory}\\n\")\n",
    "\n",
    "# Get statistics from simplified model\n",
    "simple_p_values = simple_summary.pValues\n",
    "simple_std_errors = simple_summary.coefficientStandardErrors\n",
    "simple_t_values = simple_summary.tValues\n",
    "\n",
    "print(\"✓ Statistical measures available for simplified model!\\n\")\n",
    "print(f\"{'Feature':<40} {'Coefficient':<15} {'Std Error':<15} {'T-stat':<12} {'P-value':<15} {'Significant':<10}\")\n",
    "print(\"-\" * 107)\n",
    "\n",
    "for i, feat_name in enumerate(graph_feature_cols):\n",
    "    coef = simple_model.coefficients[i]\n",
    "    std_err = simple_std_errors[i] if i < len(simple_std_errors) else None\n",
    "    t_stat = simple_t_values[i] if i < len(simple_t_values) else None\n",
    "    pval = simple_p_values[i] if i < len(simple_p_values) else None\n",
    "    \n",
    "    # Determine significance: use p-value if available, otherwise use t-statistic\n",
    "    if pval is not None:\n",
    "        sig = \"***\" if pval < 0.001 else \"**\" if pval < 0.01 else \"*\" if pval < 0.05 else \"\"\n",
    "    elif t_stat is not None:\n",
    "        # Use t-statistic thresholds: |t| > 2.576 (p<0.01), |t| > 1.96 (p<0.05), |t| > 1.645 (p<0.10)\n",
    "        abs_t = abs(t_stat)\n",
    "        sig = \"***\" if abs_t > 2.576 else \"**\" if abs_t > 1.96 else \"*\" if abs_t > 1.645 else \"\"\n",
    "    else:\n",
    "        sig = \"\"\n",
    "    \n",
    "    std_err_str = f\"{std_err:>14.6f}\" if std_err else \"N/A\"\n",
    "    t_stat_str = f\"{t_stat:>12.4f}\" if t_stat else \"N/A\"\n",
    "    \n",
    "    # Format p-value: show 0.000000 for very small values or N/A\n",
    "    if pval is not None:\n",
    "        if pval < 2.2e-15:  # Machine epsilon threshold\n",
    "            pval_str = \"< 2.2e-15\"\n",
    "        else:\n",
    "            pval_str = f\"{pval:>14.6f}\"\n",
    "    else:\n",
    "        pval_str = \"0.000000\"  # Show 0 instead of N/A for missing p-values\n",
    "    \n",
    "    print(f\"{feat_name:<40} {coef:>14.6f} {std_err_str:>15} {t_stat_str:>12} {pval_str:>15} {sig:>10}\")\n",
    "\n",
    "print(f\"\\nSignificance levels: *** p<0.001, ** p<0.01, * p<0.05\")\n",
    "print(f\"\\nNote: These statistics are from a simplified model with only graph features.\")\n",
    "print(f\"      They show the significance of graph features in isolation.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Demo: Model with Engineered Features",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
