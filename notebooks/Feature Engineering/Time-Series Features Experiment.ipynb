{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15979228-d1cf-4741-9990-b01d6ac0b88e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dependencies to load moduels from this repo\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Load cv module directly from file path\n",
    "cv_path = \"/Workspace/Shared/Team 4_2/flight-departure-delay-predictive-modeling/notebooks/Cross Validator/cv.py\"\n",
    "spec = importlib.util.spec_from_file_location(\"cv\", cv_path)\n",
    "cv = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(cv)\n",
    "\n",
    "# Dependencies for time series features\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, to_timestamp, date_format\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "\n",
    "# Dependencies for EDA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.stattools import adfuller, kpss, coint\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "# Other Dependencies\n",
    "import time\n",
    "\n",
    "# Path for persistent storage\n",
    "FOLDER_PATH = \"dbfs:/mnt/mids-w261/student-groups/Group_4_2/experiments\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "174bb191-62e7-4352-b30e-97ad120b58b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad72abbd-ddb5-498b-94cf-b2760cafee51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load from data_loader and save snapshot (run once)\n",
    "ts_data_path = f\"{FOLDER_PATH}/timeseries_data_snapshot.parquet\"\n",
    "\n",
    "print(\"Loading from data_loader and saving snapshot...\")\n",
    "start = time.time()\n",
    "data_loader = cv.FlightDelayDataLoader()\n",
    "data_loader.load()\n",
    "folds = data_loader.get_version(\"12M\")\n",
    "\n",
    "# Use final fold (test fold) which has 4 years of data for time series analysis\n",
    "# This allows us to learn yearly seasonality without data leakage\n",
    "train_df, test_df = folds[-1]\n",
    "ts_data = train_df\n",
    "\n",
    "# Check partition count and repartition if needed\n",
    "num_partitions = ts_data.rdd.getNumPartitions()\n",
    "if num_partitions > 500:\n",
    "    ts_data = ts_data.coalesce(200)\n",
    "elif num_partitions < 10:\n",
    "    ts_data = ts_data.repartition(50)\n",
    "\n",
    "# Save snapshot\n",
    "ts_data.write.mode(\"overwrite\").parquet(ts_data_path)\n",
    "print(f\"Saved snapshot in {time.time() - start:.2f} seconds\")\n",
    "\n",
    "print(f\"\\nTime series data: {ts_data.count():,} flights\")\n",
    "print(f\"Date range: {ts_data.agg(F.min('FL_DATE'), F.max('FL_DATE')).collect()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f127858-178a-4f9a-8294-77313575d12e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load from saved snapshot (run this on subsequent runs, skip above cell\n",
    "ts_data_path = f\"{FOLDER_PATH}/timeseries_data_snapshot.parquet\"\n",
    "\n",
    "print(f\"Loading timeseries data from {ts_data_path}...\")\n",
    "start = time.time()\n",
    "ts_data = spark.read.parquet(ts_data_path)\n",
    "ts_data.count()  # Materialize\n",
    "print(f\"Loaded in {time.time() - start:.2f} seconds\")\n",
    "\n",
    "print(f\"\\nTime series data: {ts_data.count():,} flights\")\n",
    "print(f\"Date range: {ts_data.agg(F.min('FL_DATE'), F.max('FL_DATE')).collect()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94a649d5-4f96-487a-a20e-cbd70ea143cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Generate Time-Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b7faf18-4a34-4ba0-8be7-c05640fee61b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Prepare date column for aggregation\n",
    "# Convert FL_DATE to date type and filter valid data\n",
    "ts_data_prep = ts_data.withColumn(\n",
    "    \"date\", \n",
    "    to_timestamp(col(\"FL_DATE\"), \"yyyy-MM-dd\").cast(\"date\")\n",
    ").filter(\n",
    "    col(\"date\").isNotNull() & \n",
    "    col(\"DEP_DELAY\").isNotNull()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc847c23-58b9-40e1-b291-3f83a2d562a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Global Time-Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6175ffd0-6e57-4f1f-b34e-0be9438554e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# lobal time series: Average departure delay by date\n",
    "global_dep_delays_spark = (\n",
    "    ts_data_prep\n",
    "    .groupBy(\"date\")\n",
    "    .agg(\n",
    "        F.avg(\"DEP_DELAY\").alias(\"avg_dep_delay\"),\n",
    "        F.count(\"*\").alias(\"flight_count\")\n",
    "    )\n",
    "    .orderBy(\"date\")\n",
    ")\n",
    "\n",
    "# Convert to pandas for Prophet\n",
    "global_dep_delays = global_dep_delays_spark.toPandas()\n",
    "global_dep_delays['ds'] = pd.to_datetime(global_dep_delays['date'])\n",
    "global_dep_delays = global_dep_delays.rename(columns={'avg_dep_delay': 'y'})\n",
    "\n",
    "print(\"Global time series (first 10 days):\")\n",
    "print(global_dep_delays[['ds', 'y', 'flight_count']].head(10))\n",
    "print(f\"\\nTotal days: {len(global_dep_delays)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6fc34acb-db47-43a3-9b61-03c442345bf8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Per Airport Time-Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cd9ccf4-c140-42f1-82aa-549f56b5871f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Per-airport time series: Departure delays, arrival delays, and flight counts\n",
    "# Aggregate by airport and date\n",
    "per_airport_ts_spark = (\n",
    "    ts_data_prep\n",
    "    .groupBy(\"origin\", \"date\")\n",
    "    .agg(\n",
    "        F.avg(\"DEP_DELAY\").alias(\"avg_dep_delay\"),\n",
    "        F.avg(\"ARR_DELAY\").alias(\"avg_arr_delay\"),\n",
    "        F.count(\"*\").alias(\"flight_count\")\n",
    "    )\n",
    "    .orderBy(\"origin\", \"date\")\n",
    ")\n",
    "\n",
    "# Convert to pandas\n",
    "per_airport_ts = per_airport_ts_spark.toPandas()\n",
    "per_airport_ts['ds'] = pd.to_datetime(per_airport_ts['date'])\n",
    "\n",
    "print(f\"Per-airport time series: {len(per_airport_ts):,} rows\")\n",
    "print(f\"Number of airports: {per_airport_ts['origin'].nunique()}\")\n",
    "print(f\"Average days per airport: {len(per_airport_ts) / per_airport_ts['origin'].nunique():.1f}\")\n",
    "print(\"\\nSample (first airport):\")\n",
    "first_airport = per_airport_ts['origin'].iloc[0]\n",
    "print(per_airport_ts[per_airport_ts['origin'] == first_airport][['origin', 'ds', 'avg_dep_delay', 'avg_arr_delay', 'flight_count']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fbce5264-0345-40dc-9d00-b00114b82650",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Time-Series EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3586a85c-68ec-426f-a506-7e3b142fdf60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "### 1. Raw Time Series Plots\n",
    "\n",
    "\n",
    "# Global departure delays\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Full time series\n",
    "axes[0].plot(global_dep_delays['ds'], global_dep_delays['y'], linewidth=0.5, alpha=0.7)\n",
    "axes[0].set_title('Global Average Departure Delay Over Time (Full Series)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Average Departure Delay (minutes)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Zoomed view (last 6 months)\n",
    "last_6mo = global_dep_delays.tail(180)\n",
    "axes[1].plot(last_6mo['ds'], last_6mo['y'], linewidth=1, marker='o', markersize=2)\n",
    "axes[1].set_title('Global Average Departure Delay (Last 6 Months)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_ylabel('Average Departure Delay (minutes)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n=== Global Departure Delay Summary Statistics ===\")\n",
    "print(global_dep_delays['y'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3242be0c-2e7f-454b-b2a5-e97b33ea0512",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### 2. Distribution and Box Plots\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Histogram\n",
    "axes[0, 0].hist(global_dep_delays['y'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_title('Distribution of Daily Average Departure Delays', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Average Departure Delay (minutes)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].axvline(global_dep_delays['y'].mean(), color='r', linestyle='--', label=f'Mean: {global_dep_delays[\"y\"].mean():.2f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Box plot by year\n",
    "global_dep_delays['year'] = global_dep_delays['ds'].dt.year\n",
    "sns.boxplot(data=global_dep_delays, x='year', y='y', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Departure Delays by Year', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Year')\n",
    "axes[0, 1].set_ylabel('Average Departure Delay (minutes)')\n",
    "\n",
    "# Box plot by month\n",
    "global_dep_delays['month'] = global_dep_delays['ds'].dt.month\n",
    "sns.boxplot(data=global_dep_delays, x='month', y='y', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Departure Delays by Month', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Month')\n",
    "axes[1, 0].set_ylabel('Average Departure Delay (minutes)')\n",
    "\n",
    "# Box plot by day of week\n",
    "global_dep_delays['day_of_week'] = global_dep_delays['ds'].dt.dayofweek\n",
    "sns.boxplot(data=global_dep_delays, x='day_of_week', y='y', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Departure Delays by Day of Week', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Day of Week (0=Monday)')\n",
    "axes[1, 1].set_ylabel('Average Departure Delay (minutes)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b75bb967-0e41-4ddc-acbe-6b4f8479f99b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### 3. Stationarity Tests\n",
    "\n",
    "# Set up time series for testing (remove NaN values)\n",
    "\n",
    "ts_values = global_dep_delays['y'].dropna().values\n",
    "\n",
    "print(\"=== Stationarity Tests ===\\n\")\n",
    "\n",
    "# Augmented Dickey-Fuller Test (ADF)\n",
    "print(\"1. Augmented Dickey-Fuller Test (ADF):\")\n",
    "print(\"   H0: Series has a unit root (non-stationary)\")\n",
    "print(\"   H1: Series is stationary\\n\")\n",
    "adf_result = adfuller(ts_values)\n",
    "print(f\"   ADF Statistic: {adf_result[0]:.4f}\")\n",
    "print(f\"   p-value: {adf_result[1]:.4f}\")\n",
    "print(f\"   Critical Values:\")\n",
    "for key, value in adf_result[4].items():\n",
    "    print(f\"      {key}: {value:.4f}\")\n",
    "if adf_result[1] <= 0.05:\n",
    "    print(\"   ✓ Series is STATIONARY (reject H0, p < 0.05)\")\n",
    "else:\n",
    "    print(\"   ✗ Series is NON-STATIONARY (fail to reject H0, p >= 0.05)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# KPSS Test\n",
    "print(\"2. KPSS Test:\")\n",
    "print(\"   H0: Series is stationary\")\n",
    "print(\"   H1: Series has a unit root (non-stationary)\\n\")\n",
    "kpss_result = kpss(ts_values, regression='ct')  # 'ct' = constant and trend\n",
    "print(f\"   KPSS Statistic: {kpss_result[0]:.4f}\")\n",
    "print(f\"   p-value: {kpss_result[1]:.4f}\")\n",
    "print(f\"   Critical Values:\")\n",
    "for key, value in kpss_result[3].items():\n",
    "    print(f\"      {key}: {value:.4f}\")\n",
    "if kpss_result[1] >= 0.05:\n",
    "    print(\"   ✓ Series is STATIONARY (fail to reject H0, p >= 0.05)\")\n",
    "else:\n",
    "    print(\"   ✗ Series is NON-STATIONARY (reject H0, p < 0.05)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f192c56-4a5d-4411-a8ad-8021348ab372",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### 4. Autocorrelation Analysis\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# ACF (Autocorrelation Function)\n",
    "plot_acf(global_dep_delays['y'].dropna(), lags=50, ax=axes[0], alpha=0.05)\n",
    "axes[0].set_title('Autocorrelation Function (ACF)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Lag')\n",
    "axes[0].set_ylabel('Autocorrelation')\n",
    "\n",
    "# PACF (Partial Autocorrelation Function)\n",
    "plot_pacf(global_dep_delays['y'].dropna(), lags=50, ax=axes[1], alpha=0.05)\n",
    "axes[1].set_title('Partial Autocorrelation Function (PACF)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Lag')\n",
    "axes[1].set_ylabel('Partial Autocorrelation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Ljung-Box Test for autocorrelation\n",
    "print(\"\\n=== Ljung-Box Test for Autocorrelation ===\")\n",
    "print(\"H0: No autocorrelation\")\n",
    "print(\"H1: Autocorrelation exists\\n\")\n",
    "lb_result = acorr_ljungbox(global_dep_delays['y'].dropna(), lags=10, return_df=True)\n",
    "print(lb_result)\n",
    "if (lb_result['lb_pvalue'] < 0.05).any():\n",
    "    print(\"\\n✗ Significant autocorrelation detected (p < 0.05)\")\n",
    "else:\n",
    "    print(\"\\n✓ No significant autocorrelation (p >= 0.05)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0c0d27e-1daf-4ba3-a71c-531a7b3fac75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### 5. STL Decomposition (Seasonal and Trend decomposition using Loess)\n",
    "\n",
    "# Set date as index for STL\n",
    "ts_indexed = global_dep_delays.set_index('ds')['y'].dropna()\n",
    "\n",
    "# STL Decomposition\n",
    "# period=365 for yearly seasonality, but we can also try weekly (period=7)\n",
    "stl = STL(ts_indexed, seasonal=365, trend=None, robust=True)\n",
    "decomposition = stl.fit()\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 12))\n",
    "\n",
    "# Original\n",
    "axes[0].plot(ts_indexed.index, ts_indexed.values, linewidth=0.5, alpha=0.7)\n",
    "axes[0].set_title('Original Time Series', fontweight='bold')\n",
    "axes[0].set_ylabel('Departure Delay')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Trend\n",
    "axes[1].plot(decomposition.trend.index, decomposition.trend.values, linewidth=1, color='blue')\n",
    "axes[1].set_title('Trend Component', fontweight='bold')\n",
    "axes[1].set_ylabel('Trend')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Seasonal\n",
    "axes[2].plot(decomposition.seasonal.index, decomposition.seasonal.values, linewidth=0.5, alpha=0.7, color='green')\n",
    "axes[2].set_title('Seasonal Component', fontweight='bold')\n",
    "axes[2].set_ylabel('Seasonal')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# Residual\n",
    "axes[3].plot(decomposition.resid.index, decomposition.resid.values, linewidth=0.5, alpha=0.7, color='red')\n",
    "axes[3].set_title('Residual Component', fontweight='bold')\n",
    "axes[3].set_ylabel('Residual')\n",
    "axes[3].set_xlabel('Date')\n",
    "axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary of decomposition\n",
    "print(\"\\n=== STL Decomposition Summary ===\")\n",
    "print(f\"Trend variance: {decomposition.trend.var():.4f}\")\n",
    "print(f\"Seasonal variance: {decomposition.seasonal.var():.4f}\")\n",
    "print(f\"Residual variance: {decomposition.resid.var():.4f}\")\n",
    "print(f\"\\nResidual statistics:\")\n",
    "print(decomposition.resid.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75fedf4d-4186-45f3-9846-ac2a7883cfe0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### 6. Additional Statistical Analysis\n",
    "\n",
    "# Monthly averages\n",
    "monthly_avg = global_dep_delays.groupby('month')['y'].mean()\n",
    "print(\"=== Monthly Average Departure Delays ===\")\n",
    "for month, avg in monthly_avg.items():\n",
    "    month_name = pd.Timestamp(2020, month, 1).strftime('%B')\n",
    "    print(f\"{month_name:12s}: {avg:6.2f} minutes\")\n",
    "\n",
    "# Day of week averages\n",
    "dow_avg = global_dep_delays.groupby('day_of_week')['y'].mean()\n",
    "dow_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "print(\"\\n=== Day of Week Average Departure Delays ===\")\n",
    "for dow, avg in dow_avg.items():\n",
    "    print(f\"{dow_names[dow]:12s}: {avg:6.2f} minutes\")\n",
    "\n",
    "# Year-over-year comparison\n",
    "print(\"\\n=== Year-over-Year Comparison ===\")\n",
    "yearly_avg = global_dep_delays.groupby('year')['y'].agg(['mean', 'std', 'min', 'max'])\n",
    "print(yearly_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31202c97-2810-47d4-89a6-4ef44099c68d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**TODO**: Additional Time Series Analysis\n",
    "\n",
    "- [ ] **Delays by Airplane Model**: Time series of average departure delays by aircraft model (e.g., Boeing 737, Airbus A320)\n",
    "- [ ] **Delays by Carrier**: Time series of average departure delays by airline carrier\n",
    "- [ ] Apply same EDA (stationarity tests, STL decomposition, etc.) to these additional time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b0c4948-9be5-4f2a-8305-2e4f49370de6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### 7. Cointegration Test: Flight Count vs Average Delay\n",
    "\n",
    "# Test if number of flights and average delay are cointegrated\n",
    "# Cointegration means they have a long-term equilibrium relationship\n",
    "# even if individually non-stationary\n",
    "\n",
    "# Align the series (same dates)\n",
    "flight_count_series = global_dep_delays['flight_count'].dropna().values\n",
    "delay_series = global_dep_delays['y'].dropna().values\n",
    "\n",
    "# Ensure same length\n",
    "min_len = min(len(flight_count_series), len(delay_series))\n",
    "flight_count_series = flight_count_series[:min_len]\n",
    "delay_series = delay_series[:min_len]\n",
    "\n",
    "print(\"=== Cointegration Test: Flight Count vs Average Delay ===\\n\")\n",
    "print(\"H0: No cointegration (series are not in long-term equilibrium)\")\n",
    "print(\"H1: Cointegration exists (series have long-term relationship)\\n\")\n",
    "\n",
    "# Engle-Granger cointegration test\n",
    "coint_result = coint(delay_series, flight_count_series)\n",
    "\n",
    "print(f\"Cointegration Test Statistic: {coint_result[0]:.4f}\")\n",
    "print(f\"p-value: {coint_result[1]:.4f}\")\n",
    "print(f\"Critical Values:\")\n",
    "for key, value in coint_result[2].items():\n",
    "    print(f\"   {key}: {value:.4f}\")\n",
    "\n",
    "if coint_result[1] <= 0.05:\n",
    "    print(\"\\n✓ COINTEGRATION DETECTED (p < 0.05)\")\n",
    "    print(\"  → Flight count and delay have a long-term equilibrium relationship\")\n",
    "    print(\"  → They move together over time despite short-term deviations\")\n",
    "else:\n",
    "    print(\"\\n✗ No cointegration (p >= 0.05)\")\n",
    "    print(\"  → Flight count and delay do not have a stable long-term relationship\")\n",
    "\n",
    "# Visualize the relationship\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Plot both series\n",
    "ax1 = axes[0]\n",
    "ax1_twin = ax1.twinx()\n",
    "ax1.plot(global_dep_delays['ds'].iloc[:min_len], delay_series, 'b-', label='Avg Delay', linewidth=1, alpha=0.7)\n",
    "ax1_twin.plot(global_dep_delays['ds'].iloc[:min_len], flight_count_series, 'r-', label='Flight Count', linewidth=1, alpha=0.7)\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Average Delay (minutes)', color='b')\n",
    "ax1_twin.set_ylabel('Flight Count', color='r')\n",
    "ax1.set_title('Flight Count vs Average Delay Over Time', fontweight='bold')\n",
    "ax1.tick_params(axis='y', labelcolor='b')\n",
    "ax1_twin.tick_params(axis='y', labelcolor='r')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Scatter plot\n",
    "axes[1].scatter(flight_count_series, delay_series, alpha=0.3, s=10)\n",
    "axes[1].set_xlabel('Flight Count')\n",
    "axes[1].set_ylabel('Average Departure Delay (minutes)')\n",
    "axes[1].set_title('Flight Count vs Average Delay (Scatter)', fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add correlation\n",
    "correlation = np.corrcoef(flight_count_series, delay_series)[0, 1]\n",
    "axes[1].text(0.05, 0.95, f'Correlation: {correlation:.3f}', \n",
    "             transform=axes[1].transAxes, fontsize=12,\n",
    "             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f817f82e-9138-4c77-80c2-b3e62b7b8689",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Prophet Feature Generation\n",
    "\n",
    "Use Prophet to extract time-series features (trend, seasonality, forecasts) that can be used as features in ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88c567da-209e-43d1-8f21-72256de22a1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fit Prophet model on global time series\n",
    "print(\"Fitting Prophet model on global departure delays...\")\n",
    "\n",
    "# Prepare data for Prophet (requires 'ds' and 'y' columns)\n",
    "prophet_data = global_dep_delays[['ds', 'y']].copy()\n",
    "prophet_data = prophet_data.dropna()\n",
    "\n",
    "# Initialize and fit Prophet model\n",
    "# Enable yearly and weekly seasonality\n",
    "prophet_model_global = Prophet(\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    daily_seasonality=False,  # Daily doesn't make sense for daily aggregated data\n",
    "    seasonality_mode='multiplicative',  # or 'additive'\n",
    "    interval_width=0.95,  # 95% confidence intervals\n",
    "    changepoint_prior_scale=0.05  # Controls flexibility of trend changes\n",
    ")\n",
    "\n",
    "prophet_model_global.fit(prophet_data)\n",
    "\n",
    "# Generate forecast for all dates in the training data (and potentially future dates)\n",
    "# This gives us trend, seasonality components, and forecast values\n",
    "forecast_global = prophet_model_global.predict(prophet_data[['ds']])\n",
    "\n",
    "print(f\"Prophet forecast generated for {len(forecast_global)} dates\")\n",
    "print(\"\\nForecast columns:\")\n",
    "print(forecast_global.columns.tolist())\n",
    "print(\"\\nSample forecast:\")\n",
    "print(forecast_global[['ds', 'yhat', 'trend', 'yearly', 'weekly']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "785e8ccb-2770-4857-bcac-c8db64bc3c86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Extract Prophet features for joining back to flight data\n",
    "# These features can be used in ML models\n",
    "\n",
    "prophet_features_global = forecast_global[[\n",
    "    'ds',\n",
    "    'trend',              # Long-term trend component\n",
    "    'yearly',             # Yearly seasonality component\n",
    "    'weekly',             # Weekly seasonality component\n",
    "    'yhat',               # Forecasted value (trend + seasonality)\n",
    "    'yhat_lower',         # Lower bound of forecast interval\n",
    "    'yhat_upper',         # Upper bound of forecast interval\n",
    "]].copy()\n",
    "\n",
    "# Rename for clarity when joining\n",
    "prophet_features_global = prophet_features_global.rename(columns={\n",
    "    'trend': 'prophet_trend_global',\n",
    "    'yearly': 'prophet_yearly_seasonality_global',\n",
    "    'weekly': 'prophet_weekly_seasonality_global',\n",
    "    'yhat': 'prophet_forecast_global',\n",
    "    'yhat_lower': 'prophet_forecast_lower_global',\n",
    "    'yhat_upper': 'prophet_forecast_upper_global'\n",
    "})\n",
    "\n",
    "# Convert date to string format matching FL_DATE\n",
    "prophet_features_global['date_str'] = prophet_features_global['ds'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "print(\"Global Prophet features (sample):\")\n",
    "print(prophet_features_global.head(10))\n",
    "print(f\"\\nTotal feature rows: {len(prophet_features_global)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75f5efdd-6894-455a-b4c0-9611d7118b98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Per-Airport Prophet Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7aaca66c-06ce-4e7b-acb4-ed778376e883",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fit Prophet models for each airport\n",
    "# This will take longer but provides airport-specific trend and seasonality features\n",
    "\n",
    "print(\"Fitting Prophet models for each airport...\")\n",
    "print(f\"Total airports: {per_airport_ts['origin'].nunique()}\")\n",
    "\n",
    "# Check data availability per airport\n",
    "airport_day_counts = per_airport_ts.groupby('origin')['ds'].count().sort_values(ascending=False)\n",
    "print(f\"\\nData availability statistics:\")\n",
    "print(f\"  Min days: {airport_day_counts.min()}\")\n",
    "print(f\"  Max days: {airport_day_counts.max()}\")\n",
    "print(f\"  Mean days: {airport_day_counts.mean():.1f}\")\n",
    "print(f\"  Median days: {airport_day_counts.median():.1f}\")\n",
    "\n",
    "# Use a lower threshold - need at least 14 days for weekly seasonality\n",
    "# With only 3 quarters (~270 days), we can't do yearly seasonality, but we can get trend and weekly patterns\n",
    "min_days_required = 14  # At least 2 weeks for weekly seasonality\n",
    "airports_with_sufficient_data = airport_day_counts[airport_day_counts >= min_days_required].index.tolist()\n",
    "\n",
    "print(f\"\\nAirports with >= {min_days_required} days of data: {len(airports_with_sufficient_data)}\")\n",
    "\n",
    "# Fit Prophet for a subset of airports first (for testing)\n",
    "# In production, fit for all airports\n",
    "top_airports = airports_with_sufficient_data[:20]  # Start with top 20 airports\n",
    "print(f\"\\nFitting Prophet models for {len(top_airports)} airports (sample)...\")\n",
    "\n",
    "prophet_features_per_airport = []\n",
    "\n",
    "for airport in top_airports:\n",
    "    airport_data = per_airport_ts[per_airport_ts['origin'] == airport].sort_values('ds')\n",
    "    airport_prophet_data = airport_data[['ds', 'avg_dep_delay']].copy()\n",
    "    airport_prophet_data = airport_prophet_data.rename(columns={'avg_dep_delay': 'y'})\n",
    "    airport_prophet_data = airport_prophet_data.dropna()\n",
    "    \n",
    "    if len(airport_prophet_data) < min_days_required:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Determine seasonality based on data availability\n",
    "        has_enough_for_yearly = len(airport_prophet_data) >= 365\n",
    "        has_enough_for_weekly = len(airport_prophet_data) >= 14\n",
    "        \n",
    "        # Fit Prophet model with appropriate seasonality\n",
    "        prophet_model = Prophet(\n",
    "            yearly_seasonality=has_enough_for_yearly,  # Only if >=365 days\n",
    "            weekly_seasonality=has_enough_for_weekly,  # Only if >=14 days\n",
    "            daily_seasonality=False,\n",
    "            seasonality_mode='multiplicative',\n",
    "            interval_width=0.95,\n",
    "            changepoint_prior_scale=0.05\n",
    "        )\n",
    "        prophet_model.fit(airport_prophet_data)\n",
    "        \n",
    "        # Generate forecast\n",
    "        forecast = prophet_model.predict(airport_prophet_data[['ds']])\n",
    "        \n",
    "        # Extract features (yearly may not exist if not enough data)\n",
    "        feature_cols = ['ds', 'trend', 'weekly', 'yhat', 'yhat_lower', 'yhat_upper']\n",
    "        if 'yearly' in forecast.columns:\n",
    "            feature_cols.insert(2, 'yearly')  # Insert after 'trend'\n",
    "        \n",
    "        features = forecast[feature_cols].copy()\n",
    "        features['origin'] = airport\n",
    "        \n",
    "        # Rename columns\n",
    "        rename_dict = {\n",
    "            'trend': 'prophet_trend_origin',\n",
    "            'weekly': 'prophet_weekly_seasonality_origin',\n",
    "            'yhat': 'prophet_forecast_origin',\n",
    "            'yhat_lower': 'prophet_forecast_lower_origin',\n",
    "            'yhat_upper': 'prophet_forecast_upper_origin'\n",
    "        }\n",
    "        if 'yearly' in features.columns:\n",
    "            rename_dict['yearly'] = 'prophet_yearly_seasonality_origin'\n",
    "        \n",
    "        features = features.rename(columns=rename_dict)\n",
    "        features['date_str'] = features['ds'].dt.strftime('%Y-%m-%d')\n",
    "        \n",
    "        prophet_features_per_airport.append(features)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fitting Prophet for airport {airport}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Combine all airport features\n",
    "if prophet_features_per_airport:\n",
    "    prophet_features_airport_df = pd.concat(prophet_features_per_airport, ignore_index=True)\n",
    "    print(f\"\\n✓ Generated Prophet features for {prophet_features_airport_df['origin'].nunique()} airports\")\n",
    "    print(f\"Total feature rows: {len(prophet_features_airport_df)}\")\n",
    "    print(\"\\nSample features:\")\n",
    "    print(prophet_features_airport_df.head(10))\n",
    "else:\n",
    "    print(\"\\nNo Prophet features generated for airports\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Time-Series Features Experiment",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
