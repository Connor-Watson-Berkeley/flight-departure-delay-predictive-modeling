{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7dfa2621-e737-483f-84c1-8625091d1e82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "cv.py (simplified, CUSTOM-only, no parametrization)\n",
    "\n",
    "Assumptions:\n",
    "- Folds were created from split.py with N_FOLDS = 3 and CREATE_TEST_FOLD = True\n",
    "- Therefore total fold indices written = 4:\n",
    "    FOLD_1_VAL, FOLD_2_VAL, FOLD_3_VAL, FOLD_4_TEST\n",
    "- Files live in:\n",
    "    dbfs:/mnt/mids-w261/student-groups/Group_4_2/processed\n",
    "- File naming:\n",
    "    OTPW_CUSTOM_{VERSION}_FOLD_{i}_{TRAIN|VAL|TEST}.parquet\n",
    "\"\"\"\n",
    "\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "mlflow.autolog(disable=True)\n",
    "\n",
    "# -----------------------------\n",
    "# HARD-CODED GLOBALS\n",
    "# -----------------------------\n",
    "FOLDER_PATH = \"dbfs:/mnt/mids-w261/student-groups/Group_4_2/processed\"\n",
    "SOURCE = \"CUSTOM\"\n",
    "VERSIONS = [\"3M\", \"12M\"]\n",
    "\n",
    "# 3 CV folds + 1 test fold = 4 total fold indices\n",
    "TOTAL_FOLDS = 4\n",
    "\n",
    "\n",
    "class FlightDelayDataLoader:\n",
    "    \"\"\"\n",
    "    CUSTOM-only loader that guarantees all numerical features are cast to double.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.folder_path = \"dbfs:/mnt/mids-w261/student-groups/Group_4_2/processed\"\n",
    "        self.source = \"CUSTOM\"\n",
    "        self.folds = {}\n",
    "        self.versions = [\"3M\", \"12M\"]\n",
    "\n",
    "        self.numerical_features = [\n",
    "            'hourlyprecipitation',\n",
    "            'hourlysealevelpressure',\n",
    "            'hourlyaltimetersetting',\n",
    "            'hourlywetbulbtemperature',\n",
    "            'hourlystationpressure',\n",
    "            'hourlywinddirection',\n",
    "            'hourlyrelativehumidity',\n",
    "            'hourlywindspeed',\n",
    "            'hourlydewpointtemperature',\n",
    "            'hourlydrybulbtemperature',\n",
    "            'hourlyvisibility',\n",
    "            'crs_elapsed_time', # scheduled flight time\n",
    "            'quarter', # inferred from month\n",
    "            'flights', # number of flights? always 1?\n",
    "            'distance', # flight distance, probably important\n",
    "            'year', # excluded bc new predictions will always be in a new year\n",
    "            # latitude and longitude not very useful in linear regression\n",
    "            'origin_station_lat',\n",
    "            'origin_station_lon',\n",
    "            'origin_airport_lat',\n",
    "            'origin_airport_lon',\n",
    "            'origin_station_dis',\n",
    "            'dest_station_lat',\n",
    "            'dest_station_lon',\n",
    "            'dest_airport_lat',\n",
    "            'dest_airport_lon',\n",
    "            'dest_station_dis',\n",
    "            'latitude',\n",
    "            'longitude',\n",
    "            'elevation',\n",
    "        ]\n",
    "\n",
    "    def _cast_numerics(self, df):\n",
    "        \"\"\"\n",
    "        Safely cast all configured numeric columns to doubles.\n",
    "        Handles common bad values like '', 'NA', 'M', 'T', '.', etc.\n",
    "        \"\"\"\n",
    "\n",
    "        # Patterns that should be treated as null\n",
    "        NULL_PAT = r'^(NA|N/A|NULL|null|None|none|\\\\N|\\\\s*|\\\\.|M|T)$'\n",
    "\n",
    "        for colname in self.numerical_features:\n",
    "            if colname in df.columns:\n",
    "                df = df.withColumn(\n",
    "                    colname,\n",
    "                    F.regexp_replace(F.col(colname).cast(\"string\"), NULL_PAT, \"\")\n",
    "                    .cast(\"double\")\n",
    "                )\n",
    "\n",
    "        # Explicitly cast labels to expected numeric types\n",
    "        if \"DEP_DELAY\" in df.columns:\n",
    "            df = df.withColumn(\"DEP_DELAY\", F.col(\"DEP_DELAY\").cast(\"double\"))\n",
    "        if \"DEP_DEL15\" in df.columns:\n",
    "            df = df.withColumn(\"DEP_DEL15\", F.col(\"DEP_DEL15\").cast(\"int\"))\n",
    "        if \"SEVERE_DEL60\" in df.columns:\n",
    "            df = df.withColumn(\"SEVERE_DEL60\", F.col(\"SEVERE_DEL60\").cast(\"int\"))\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _load_parquet(self, name):\n",
    "        spark = SparkSession.builder.getOrCreate()\n",
    "        df = spark.read.parquet(f\"{self.folder_path}/{name}.parquet\")\n",
    "        df = self._cast_numerics(df)\n",
    "        return df\n",
    "\n",
    "    def _load_version(self, version):\n",
    "        folds = []\n",
    "        for fold_idx in range(1, 4 + 1):  # 3 CV folds + 1 test\n",
    "            train_name = f\"OTPW_{self.source}_{version}_FOLD_{fold_idx}_TRAIN\"\n",
    "            train_df = self._load_parquet(train_name)\n",
    "\n",
    "            if fold_idx < 4:\n",
    "                val_name = f\"OTPW_{self.source}_{version}_FOLD_{fold_idx}_VAL\"\n",
    "                val_df = self._load_parquet(val_name)\n",
    "                folds.append((train_df, val_df))\n",
    "            else:\n",
    "                test_name = f\"OTPW_{self.source}_{version}_FOLD_{fold_idx}_TEST\"\n",
    "                test_df = self._load_parquet(test_name)\n",
    "                folds.append((train_df, test_df))\n",
    "\n",
    "        return folds\n",
    "\n",
    "    def load(self):\n",
    "        for version in self.versions:\n",
    "            self.folds[version] = self._load_version(version)\n",
    "\n",
    "    def get_version(self, version):\n",
    "        return self.folds[version]\n",
    "\n",
    "# -----------------------------\n",
    "# EVALUATOR (NULL-SAFE RMSE)\n",
    "# -----------------------------\n",
    "class FlightDelayEvaluator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        prediction_col=\"prediction\",\n",
    "        numeric_label_col=\"DEP_DELAY\",\n",
    "        binary_label_col=\"DEP_DEL15\",\n",
    "        severe_label_col=\"SEVERE_DEL60\",\n",
    "    ):\n",
    "        self.prediction_col = prediction_col\n",
    "        self.numeric_label_col = numeric_label_col\n",
    "        self.binary_label_col = binary_label_col\n",
    "        self.severe_label_col = severe_label_col\n",
    "\n",
    "        self.rmse_evaluator = RegressionEvaluator(\n",
    "            predictionCol=prediction_col,\n",
    "            labelCol=numeric_label_col,\n",
    "            metricName=\"rmse\"\n",
    "        )\n",
    "\n",
    "    def calculate_rmse(self, predictions_df):\n",
    "        # Drop any residual nulls before RegressionEvaluator sees them\n",
    "        clean = predictions_df.dropna(\n",
    "            subset=[self.numeric_label_col, self.prediction_col]\n",
    "        )\n",
    "        return self.rmse_evaluator.evaluate(clean)\n",
    "\n",
    "    def _calculate_classification_metrics(self, predictions_df, threshold, label_col):\n",
    "        # Null-safe for classification too\n",
    "        df = predictions_df.dropna(subset=[self.prediction_col, label_col])\n",
    "\n",
    "        pred_binary_col = f\"pred_binary_{threshold}\"\n",
    "        df = df.withColumn(\n",
    "            pred_binary_col,\n",
    "            F.when(F.col(self.prediction_col) >= threshold, 1).otherwise(0)\n",
    "        )\n",
    "\n",
    "        tp = df.filter((F.col(pred_binary_col) == 1) & (F.col(label_col) == 1)).count()\n",
    "        fp = df.filter((F.col(pred_binary_col) == 1) & (F.col(label_col) == 0)).count()\n",
    "        tn = df.filter((F.col(pred_binary_col) == 0) & (F.col(label_col) == 0)).count()\n",
    "        fn = df.filter((F.col(pred_binary_col) == 0) & (F.col(label_col) == 1)).count()\n",
    "\n",
    "        total = tp + fp + tn + fn\n",
    "        precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0.0\n",
    "        accuracy = (tp + tn) / total if total else 0.0\n",
    "\n",
    "        return dict(tp=tp, fp=fp, tn=tn, fn=fn,\n",
    "                    precision=precision, recall=recall, f1=f1, accuracy=accuracy)\n",
    "\n",
    "    def calculate_otpa_metrics(self, predictions_df):\n",
    "        return self._calculate_classification_metrics(\n",
    "            predictions_df, threshold=15, label_col=self.binary_label_col\n",
    "        )[\"accuracy\"]\n",
    "\n",
    "    def calculate_sddr_metrics(self, predictions_df):\n",
    "        return self._calculate_classification_metrics(\n",
    "            predictions_df, threshold=60, label_col=self.severe_label_col\n",
    "        )[\"recall\"]\n",
    "\n",
    "    def evaluate(self, predictions_df):\n",
    "        return {\n",
    "            \"rmse\": self.calculate_rmse(predictions_df),\n",
    "            \"otpa\": self.calculate_otpa_metrics(predictions_df),\n",
    "            \"sddr\": self.calculate_sddr_metrics(predictions_df),\n",
    "        }\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# CROSS-VALIDATOR (NO PARAMS)\n",
    "# -----------------------------\n",
    "class FlightDelayCV:\n",
    "    def __init__(self, estimator, dataloader, version):\n",
    "        self.estimator = estimator\n",
    "        self.version = version\n",
    "\n",
    "        if dataloader:\n",
    "            self.data_loader = dataloader\n",
    "        else:\n",
    "            self.data_loader = FlightDelayDataLoader()\n",
    "            self.data_loader.load()\n",
    "\n",
    "        self.evaluator = FlightDelayEvaluator()\n",
    "        self.folds = self.data_loader.get_version(version)\n",
    "\n",
    "        self.metrics = []\n",
    "        self.models = []\n",
    "        self.test_metric = None\n",
    "        self.test_model = None\n",
    "\n",
    "    def fit(self):\n",
    "        # CV folds only (exclude last test fold)\n",
    "        for train_df, val_df in self.folds[:-1]:\n",
    "            model = self.estimator.fit(train_df)\n",
    "            preds = model.transform(val_df)\n",
    "\n",
    "            metric = self.evaluator.evaluate(preds)\n",
    "            self.metrics.append(metric)\n",
    "            self.models.append(model)\n",
    "\n",
    "        m = pd.DataFrame(self.metrics)\n",
    "        m.loc[\"mean\"] = m.mean()\n",
    "        m.loc[\"std\"] = m.std()\n",
    "        return m\n",
    "\n",
    "    def evaluate(self):\n",
    "        train_df, test_df = self.folds[-1]\n",
    "        self.test_model = self.estimator.fit(train_df)\n",
    "        preds = self.test_model.transform(test_df)\n",
    "        self.test_metric = self.evaluator.evaluate(preds)\n",
    "        return self.test_metric"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Cross Validator Module",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
